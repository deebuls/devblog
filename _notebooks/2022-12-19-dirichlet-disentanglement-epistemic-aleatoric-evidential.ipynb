{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNv1pSN+Q4lDQmxhFHziHZ9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deebuls/devblog/blob/master/_notebooks/2022-12-19-dirichlet-disentanglement-epistemic-aleatoric-evidential.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# \"Dis-entaglement of Epistemic and Aleatoric uncertainty for Dirichlet Distribution\"\n",
        "> Analysis\n",
        "\n",
        "- toc: true\n",
        "- branch: master\n",
        "- comments: false\n",
        "- author: Deebul Nair\n",
        "- categories: [statistics, uncertainty]"
      ],
      "metadata": {
        "id": "hu03m_irY8TR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to separate epistemic and aleatoric uncertaity from Dirichlet distirbution\n",
        "\n",
        "Also studing the implications of it and proposing the applications of the solution. \n",
        "\n",
        "* Formula for [1] .\n",
        "* theory in [2] \n",
        "\n",
        "\n",
        "ToDo : complete the section with info \n",
        "\n",
        "[1] Separation of Aleatoric and Epistemic Uncertainty in Deterministic Deep Neural Networks\n",
        "Denis Huseljic, Bernhard Sick, Marek Herde, Daniel Kottke\n",
        "\n",
        "[2] Deep Deterministic Uncertainty: A Simple Baseline\n",
        "Jishnu Mukhoti"
      ],
      "metadata": {
        "id": "P8bxWEn4NN0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math \n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "GE97NVWANOLA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " prior = 1\n",
        " n_classes = 5\n",
        " def predict_epistemic( alpha):\n",
        "    \"\"\"Predicts the uncertainty of a sample. (K / alpha_0)\"\"\"\n",
        "    return n_classes * prior / alpha.sum(-1, keepdim=True)\n",
        "\n",
        "def predict_aleatoric( alpha):\n",
        "    \"\"\"Predicts the uncertainty of a sample. (K / alpha_0)\"\"\"\n",
        "   \n",
        "    proba_in = (alpha / alpha.sum(-1, keepdim=True)).clamp_(1e-8, 1-1e-8)\n",
        "    entropy = - torch.sum((proba_in * proba_in.log()), dim=-1)\n",
        "    normalized_entropy = entropy / np.log(n_classes)\n",
        "    return normalized_entropy"
      ],
      "metadata": {
        "id": "qG_2X7RcNOYn"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ones = torch.ones(n_classes)\n",
        "print (predict_epistemic(ones), predict_aleatoric(ones))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x78Sxt-iPE5L",
        "outputId": "6356e0a9-6542-425d-efe7-9e4f62198320"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.]) tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones / 1.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUAg4aM9Q4ju",
        "outputId": "05e518f4-7d84-4f06-c23a-c3225393cb29"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6250, 0.6250, 0.6250, 0.6250, 0.6250])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## When alpha of 1 output keeps increasing \n",
        "\n",
        "* **Observation** : Both uncertainty reduces \n",
        "* **Impact** : When the model puts all confidence on 1 output it shows that the model is confident \n",
        "\n",
        "The maximum aleatoric and epistemic uncertitny is both 1"
      ],
      "metadata": {
        "id": "VvVEavHnS1_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [1, 10, 50, 10000 ]:\n",
        "  x = torch.ones(n_classes)\n",
        "  x[0] = i\n",
        "  print (x)\n",
        "  print (\"Epistemic UE : {}, Aleatoric UE : {}\".format(predict_epistemic(x),  predict_aleatoric(x)))\n",
        "  print (\"------------\",)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVOT6IHUPoAS",
        "outputId": "6544aa7e-b378-47c3-c411-4263442675eb"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "Epistemic UE : tensor([1.]), Aleatoric UE : 1.0\n",
            "------------\n",
            "tensor([10.,  1.,  1.,  1.,  1.])\n",
            "Epistemic UE : tensor([0.3571]), Aleatoric UE : 0.6178266406059265\n",
            "------------\n",
            "tensor([50.,  1.,  1.,  1.,  1.])\n",
            "Epistemic UE : tensor([0.0926]), Aleatoric UE : 0.2278686910867691\n",
            "------------\n",
            "tensor([1.0000e+04, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00])\n",
            "Epistemic UE : tensor([0.0005]), Aleatoric UE : 0.002536643762141466\n",
            "------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## When all alpha  output keeps increasing \n",
        "\n",
        "* **Observation** : Epistemic reduces aleatoric is high  \n",
        "* **Impact** : When the model puts all confidence on multiple output basically eans that the model is not sure between which .While since some alpha has increased says that its a seen data and theroefore low aleatoric uncertainty\n",
        "\n",
        "The maximum aleatoric and epistemic uncertainty is both 1"
      ],
      "metadata": {
        "id": "48OIK4AXUU61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [1, 10, 50, 10000 ]:\n",
        "  x = torch.ones(n_classes)*i\n",
        "  print (x)\n",
        "  print (\"Epistemic UE : {}, Aleatoric UE : {}\".format(predict_epistemic(x),  predict_aleatoric(x)))\n",
        "  print (\"------------\",)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sc03F57gQOX5",
        "outputId": "50f87f59-39d4-4f65-da8f-6e763ed33e8a"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "Epistemic UE : tensor([1.]), Aleatoric UE : 1.0\n",
            "------------\n",
            "tensor([10., 10., 10., 10., 10.])\n",
            "Epistemic UE : tensor([0.1000]), Aleatoric UE : 1.0\n",
            "------------\n",
            "tensor([50., 50., 50., 50., 50.])\n",
            "Epistemic UE : tensor([0.0200]), Aleatoric UE : 1.0\n",
            "------------\n",
            "tensor([10000., 10000., 10000., 10000., 10000.])\n",
            "Epistemic UE : tensor([1.0000e-04]), Aleatoric UE : 1.0\n",
            "------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wl9FFMV2R72L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Impact of prior \n",
        "\n",
        "prior = 50\n",
        "\n",
        "The highest epistmeic uncertainty increases from 1 to the prior value"
      ],
      "metadata": {
        "id": "EwZiqkQecWJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#hide \n",
        "\n",
        "prior = 50 \n",
        "\n",
        "for i in [1, 10, 50, 10000 ]:\n",
        "  x = torch.ones(n_classes)\n",
        "  x[0] = i\n",
        "  print (x)\n",
        "  print (\"Epistemic UE : {}, Aleatoric UE : {}\".format(predict_epistemic(x),  predict_aleatoric(x)))\n",
        "  print (\"------------\",)\n",
        "\n",
        "for i in [1, 10, 50, 10000 ]:\n",
        "  x = torch.ones(n_classes)*i\n",
        "  print (x)\n",
        "  print (\"Epistemic UE : {}, Aleatoric UE : {}\".format(predict_epistemic(x),  predict_aleatoric(x)))\n",
        "  print (\"------------\",)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnXLjeHicaKU",
        "outputId": "d19b805d-9637-4ad1-a112-0d381cbecf3e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "Epistemic UE : tensor([50.]), Aleatoric UE : 1.0\n",
            "------------\n",
            "tensor([10.,  1.,  1.,  1.,  1.])\n",
            "Epistemic UE : tensor([17.8571]), Aleatoric UE : 0.6178266406059265\n",
            "------------\n",
            "tensor([50.,  1.,  1.,  1.,  1.])\n",
            "Epistemic UE : tensor([4.6296]), Aleatoric UE : 0.2278686910867691\n",
            "------------\n",
            "tensor([1.0000e+04, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00])\n",
            "Epistemic UE : tensor([0.0250]), Aleatoric UE : 0.002536643762141466\n",
            "------------\n",
            "tensor([1., 1., 1., 1., 1.])\n",
            "Epistemic UE : tensor([50.]), Aleatoric UE : 1.0\n",
            "------------\n",
            "tensor([10., 10., 10., 10., 10.])\n",
            "Epistemic UE : tensor([5.]), Aleatoric UE : 1.0\n",
            "------------\n",
            "tensor([50., 50., 50., 50., 50.])\n",
            "Epistemic UE : tensor([1.]), Aleatoric UE : 1.0\n",
            "------------\n",
            "tensor([10000., 10000., 10000., 10000., 10000.])\n",
            "Epistemic UE : tensor([0.0050]), Aleatoric UE : 1.0\n",
            "------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusions\n",
        "\n",
        "* Dirichlet distirbution can be dis-entagled with aleatoric and epistemic uncertainty.\n",
        "* When all alpha is 1 - both uncertainty are also 1 impling that the network doesnt know anything\n",
        "* If only 1 alpha is higher then both uncertainty is high\n",
        "* The higher the alpha the lower both the uncertainty\n",
        "* If multiple alpha is higher then only aleatoric is high epistemic stays low. Impling that since the some alpha was increased the network has seen the input and its not sure which amongst the outputs are correct.\n",
        "\n",
        "\n",
        "### Use Case\n",
        "#### 1. For identifying OOD data\n",
        "1. For the training dataset measure the epistmic uncertainty of the correct predictions. It should be less than 1 and near to zero\n",
        "2. During prediction if epistimeic Ue is higher than the training max then that data should be considered OOD and handled appropriately\n",
        "\n",
        "#### 2. For handling indomain uncertain data\n",
        "1. If the epistemic unertainty is is range but he aleatoric is high we can use these in embodied situation to collect the data(image) from different view and either fuse and make decision. Example if blur image - then differ to predict but dont flag as OOD just wit for nxt better data\n",
        "\n"
      ],
      "metadata": {
        "id": "Do7L7cwzUznc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-B7KokyyYrfE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}