<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Likelihood</h1><p class="page-description">To understand Likelihood of distributions</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-03-20T00:00:00-05:00" itemprop="datePublished">
        Mar 20, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Deebul Nair</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      2 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/devblog/categories/#probability">probability</a>
        &nbsp;
      
        <a class="category-tags-link" href="/devblog/categories/#python">python</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/deebuls/devblog/tree/master/_notebooks/2020-03-20-probability-likelihood.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/devblog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/deebuls/devblog/master?filepath=_notebooks%2F2020-03-20-probability-likelihood.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/devblog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/deebuls/devblog/blob/master/_notebooks/2020-03-20-probability-likelihood.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/devblog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-03-20-probability-likelihood.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="What-is-Likelihood?">What is Likelihood?<a class="anchor-link" href="#What-is-Likelihood?"> </a></h1><p>Likelihood and probablity seems to be same word in the layman domain, but in the stats domain they are different.</p>
<p>In the stats domain the likelihood or likelihood function is a <strong>measurement</strong>. It measures the distance between a <strong>statistical model</strong> and the <strong>input data</strong>.</p>
<p>What is a statistical model?</p>
<blockquote><p>The diferent probability distributions available. For example, Gausian, gama, beta distribution, exponential for continuous data while Bernoulli, Dirichlet, multinomila distributions for discrete data.</p>
</blockquote>
<p>How are statistical models represented?</p>
<blockquote><p>By their parameters. For example for gaussian distribution the parameters are $\mu$ and $\sigma$ .</p>
</blockquote>
<p>How do we select the statictical model?</p>
<blockquote><p>Depends on  many factors. This is the main decision to be made while designing a statistical model based learning. The different factors include:<em> what is the data type: Continuous or discrete?</em> Is it symmetrical or asymetrical?</p>
<ul>
<li>Domain of the data, binary, real, etc</li>
<li>Does it decay or increase?</li>
<li>. . . etc</li>
</ul>
</blockquote>
<p>A complete knowledge about the type data and the type of distribution is required to make the appropriate decision.</p>
<h2 id="Good-blog-on-likelihood-with-scipy.stats">Good blog on likelihood with scipy.stats<a class="anchor-link" href="#Good-blog-on-likelihood-with-scipy.stats"> </a></h2><ul>
<li><a href="https://www.kaggle.com/code/tentotheminus9/so-you-have-a-diagnostic-test-result/notebook">https://www.kaggle.com/code/tentotheminus9/so-you-have-a-diagnostic-test-result/notebook</a> </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Common-Probability-distribution">Common Probability distribution<a class="anchor-link" href="#Common-Probability-distribution"> </a></h2><table>
<thead><tr>
<th>Data Type</th>
<th>Domain</th>
<th>Distribution</th>
<th>Python (numpy.random)</th>
<th>Parameters</th>
</tr>
</thead>
<tbody>
<tr>
<td>univariate, discrete, <br />binary</td>
<td>$$ x\in\{0,1\} $$</td>
<td>Bernoulli</td>
<td>binomial(1, p)</td>
<td>$$ p\in[0,1]$$</td>
</tr>
<tr>
<td>univariate, discrete, <br /> multivalued</td>
<td>$$ x \in \{ 1,2, \dots, K\}$$</td>
<td>multinomial</td>
<td>multinomial(n, pvals)</td>
<td>$$pvals = [p_1, \dots , p_k] $$ <br /> $$ \sum_{i=1}^{K} p_i = 1 $$</td>
</tr>
<tr>
<td>univariate, continuous, <br /> unbounded</td>
<td>$$ x \in \mathbb{R} $$</td>
<td>normal</td>
<td>normal(mu, sigma)</td>
<td>$$ \mu \in \mathbb{R} $$ <br /> $$ \sigma \in \mathbb{R}$$</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Lets make some distributions and find the likelihood to some data</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">number_of_samples</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span>
<span class="c1">#parameters ; sample data from distribution (continuous data)</span>
<span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span> <span class="mf">0.1</span>     <span class="p">;</span> <span class="n">univariate_gaussian_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">number_of_samples</span><span class="p">)</span>
<span class="n">mean</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">];</span> 
<span class="n">cov</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">]];</span> <span class="n">multivariate_gaussian_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">number_of_samples</span><span class="p">)</span>

<span class="c1">#parameters ; sample data from distribution (discreta data)</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">0.8</span>                 <span class="p">;</span> <span class="n">bernoulli_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">number_of_samples</span><span class="p">)</span>
<span class="n">pvals</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]</span> <span class="p">;</span> <span class="n">multinomial_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">number_of_samples</span><span class="p">,</span> <span class="n">pvals</span><span class="p">)</span>
<span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span>    <span class="p">;</span> <span class="n">beta_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">number_of_samples</span><span class="p">)</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">90</span><span class="p">]</span>   <span class="p">;</span> <span class="n">dirchilet_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">dirichlet</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">number_of_samples</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Goal-of-Likelihood">Goal of Likelihood<a class="anchor-link" href="#Goal-of-Likelihood"> </a></h2><p>The goal of likelihood would be given the samples as shown above (beta_samples, dirichlet_samples etc) find the parameters of the corresponding distribution ((alpha, beta), alphas respectively)</p>
<h3 id="Lets-look-into-this-process-in-the-comming-post">Lets look into this process in the comming post<a class="anchor-link" href="#Lets-look-into-this-process-in-the-comming-post"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#hide</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="deebuls/devblog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/devblog/probability/python/2020/03/20/probability-likelihood.html" hidden></a>
</article>