<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Quantization of Pytorch Models | Deebul Nair</title>
<meta name="generator" content="Jekyll v4.0.1" />
<meta property="og:title" content="Quantization of Pytorch Models" />
<meta name="author" content="Mohan Raj, Deebul Nair" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Different types of quantization" />
<meta property="og:description" content="Different types of quantization" />
<link rel="canonical" href="https://deebuls.github.io/devblog/pytorch/dnn/2023/01/17/Quantize-DNN-Model-Pytorch.html" />
<meta property="og:url" content="https://deebuls.github.io/devblog/pytorch/dnn/2023/01/17/Quantize-DNN-Model-Pytorch.html" />
<meta property="og:site_name" content="Deebul Nair" />
<meta property="og:image" content="https://developer-blogs.nvidia.com/wp-content/uploads/2021/07/qat-training-precision.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-01-17T00:00:00-06:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Mohan Raj, Deebul Nair"},"description":"Different types of quantization","@type":"BlogPosting","headline":"Quantization of Pytorch Models","dateModified":"2023-01-17T00:00:00-06:00","url":"https://deebuls.github.io/devblog/pytorch/dnn/2023/01/17/Quantize-DNN-Model-Pytorch.html","datePublished":"2023-01-17T00:00:00-06:00","image":"https://developer-blogs.nvidia.com/wp-content/uploads/2021/07/qat-training-precision.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://deebuls.github.io/devblog/pytorch/dnn/2023/01/17/Quantize-DNN-Model-Pytorch.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/devblog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://deebuls.github.io/devblog/feed.xml" title="Deebul Nair" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-167307341-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/devblog/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Quantization of Pytorch Models | Deebul Nair</title>
<meta name="generator" content="Jekyll v4.0.1" />
<meta property="og:title" content="Quantization of Pytorch Models" />
<meta name="author" content="Mohan Raj, Deebul Nair" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Different types of quantization" />
<meta property="og:description" content="Different types of quantization" />
<link rel="canonical" href="https://deebuls.github.io/devblog/pytorch/dnn/2023/01/17/Quantize-DNN-Model-Pytorch.html" />
<meta property="og:url" content="https://deebuls.github.io/devblog/pytorch/dnn/2023/01/17/Quantize-DNN-Model-Pytorch.html" />
<meta property="og:site_name" content="Deebul Nair" />
<meta property="og:image" content="https://developer-blogs.nvidia.com/wp-content/uploads/2021/07/qat-training-precision.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-01-17T00:00:00-06:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Mohan Raj, Deebul Nair"},"description":"Different types of quantization","@type":"BlogPosting","headline":"Quantization of Pytorch Models","dateModified":"2023-01-17T00:00:00-06:00","url":"https://deebuls.github.io/devblog/pytorch/dnn/2023/01/17/Quantize-DNN-Model-Pytorch.html","datePublished":"2023-01-17T00:00:00-06:00","image":"https://developer-blogs.nvidia.com/wp-content/uploads/2021/07/qat-training-precision.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://deebuls.github.io/devblog/pytorch/dnn/2023/01/17/Quantize-DNN-Model-Pytorch.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://deebuls.github.io/devblog/feed.xml" title="Deebul Nair" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-167307341-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>


    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/devblog/">Deebul Nair</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/devblog/about/">About Me</a><a class="page-link" href="/devblog/search/">Search</a><a class="page-link" href="/devblog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Quantization of Pytorch Models</h1><p class="page-description">Different types of quantization</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2023-01-17T00:00:00-06:00" itemprop="datePublished">
        Jan 17, 2023
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Mohan Raj, Deebul Nair</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      15 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/devblog/categories/#pytorch">pytorch</a>
        &nbsp;
      
        <a class="category-tags-link" href="/devblog/categories/#DNN">DNN</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/deebuls/devblog/tree/master/_notebooks/2023-01-17-Quantize-DNN-Model-Pytorch.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/devblog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/deebuls/devblog/master?filepath=_notebooks%2F2023-01-17-Quantize-DNN-Model-Pytorch.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/devblog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/deebuls/devblog/blob/master/_notebooks/2023-01-17-Quantize-DNN-Model-Pytorch.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/devblog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Quantization-of-Pytorch-Models">Quantization of Pytorch Models </a>
<ul>
<li class="toc-entry toc-h2"><a href="#What-is-quantization">What is quantization </a></li>
<li class="toc-entry toc-h2"><a href="#Types-of-quantization">Types of quantization </a></li>
<li class="toc-entry toc-h2"><a href="#PyTorch-Quantisation-approach">PyTorch Quantisation approach </a></li>
<li class="toc-entry toc-h2"><a href="#ONNX-Quantisation-approach">ONNX Quantisation approach </a></li>
<li class="toc-entry toc-h2"><a href="#API">API </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#PyTorch-Model">PyTorch Model </a>
<ul>
<li class="toc-entry toc-h2"><a href="#1.-PyTorch-Quantization-(QAT)">1. PyTorch Quantization (QAT) </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#2.-PyTorch-to-ONNX">2. PyTorch to ONNX </a></li>
<li class="toc-entry toc-h1"><a href="#3.-ONNX-Quantization-(Dynamic)">3. ONNX Quantization (Dynamic) </a>
<ul>
<li class="toc-entry toc-h2"><a href="#4.-ONNX-to-Blob">4. ONNX to Blob </a></li>
<li class="toc-entry toc-h2"><a href="#5.-ONNX-to-TF">5. ONNX to TF </a></li>
<li class="toc-entry toc-h2"><a href="#6.-TF-to-TFLite">6. TF to TFLite </a></li>
<li class="toc-entry toc-h2"><a href="#7.-TFLite-to-EdgeTPU-TFLite">7. TFLite to EdgeTPU TFLite </a></li>
<li class="toc-entry toc-h2"><a href="#PyTorch-Quantization-(PTQ---Dynamic/Weight-only)">PyTorch Quantization (PTQ - Dynamic/Weight only) </a></li>
<li class="toc-entry toc-h2"><a href="#PyTorch-Quantization-(PTQ---Static)">PyTorch Quantization (PTQ - Static) </a></li>
<li class="toc-entry toc-h2"><a href="#Test---QAT-IRIS">Test - QAT IRIS </a></li>
<li class="toc-entry toc-h2"><a href="#Test---Blob-Converter">Test - Blob Converter </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2023-01-17-Quantize-DNN-Model-Pytorch.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://colab.research.google.com/github/deebuls/devblog/blob/master/_notebooks/2023-01-17-Quantize-DNN-Model-Pytorch.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Quantization-of-Pytorch-Models">
<a class="anchor" href="#Quantization-of-Pytorch-Models" aria-hidden="true"><span class="octicon octicon-link"></span></a>Quantization of Pytorch Models<a class="anchor-link" href="#Quantization-of-Pytorch-Models"> </a>
</h1>
<h2 id="What-is-quantization">
<a class="anchor" href="#What-is-quantization" aria-hidden="true"><span class="octicon octicon-link"></span></a>What is quantization<a class="anchor-link" href="#What-is-quantization"> </a>
</h2>
<ul>
<li>Quantization describes methods for carrying out calculations and storing tensors at smaller bit width than floating point precision. The default size of floating point numbers are 32 bits.</li>
<li>For instance, quantizing the deep learning model means, converting the 32-bit floating point numbers (of weights &amp; activation outputs) to 8-bit integers.</li>
</ul>
<h2 id="Types-of-quantization">
<a class="anchor" href="#Types-of-quantization" aria-hidden="true"><span class="octicon octicon-link"></span></a>Types of quantization<a class="anchor-link" href="#Types-of-quantization"> </a>
</h2>
<ul>
<li>Post Training Quantization (PTQ)<ol>
<li>Static</li>
<li>Dynamic/Weight only</li>
</ol>
</li>
<li>Quantization Aware Training (QAT)<ol>
<li>Static</li>
</ol>
</li>
</ul>
<table>
<thead>
<tr>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr>
<td>Model gets smaller</td>
<td>Potential for little degradation in accuracy</td>
</tr>
<tr>
<td>Reduced memory usage during inferencing</td>
<td></td>
</tr>
<tr>
<td>Improves hardware accelerator latency</td>
<td></td>
</tr>
<tr>
<td>Reduces inference latency</td>
<td></td>
</tr>
<tr>
<td>Deployment on Edge AI devices with limited memory</td>
<td></td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="PyTorch-Quantisation-approach">
<a class="anchor" href="#PyTorch-Quantisation-approach" aria-hidden="true"><span class="octicon octicon-link"></span></a>PyTorch Quantisation approach<a class="anchor-link" href="#PyTorch-Quantisation-approach"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_svg output_subarea output_execute_result">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="542pt" height="696pt" viewbox="0.00 0.00 541.50 696.00">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 692)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-692 537.5,-692 537.5,4 -4,4"></polygon>
<!-- PyTorch\nQuantisation Aware Training\nTorch model -->
<g id="node1" class="node">
<title>PyTorch\nQuantisation Aware Training\nTorch model</title>
<polygon fill="none" stroke="black" points="173,-680.5 4,-680.5 0,-676.5 0,-627.5 169,-627.5 173,-631.5 173,-680.5"></polygon>
<polyline fill="none" stroke="black" points="169,-676.5 0,-676.5 "></polyline>
<polyline fill="none" stroke="black" points="169,-676.5 169,-627.5 "></polyline>
<polyline fill="none" stroke="black" points="169,-676.5 173,-680.5 "></polyline>
<text text-anchor="middle" x="86.5" y="-665.3" font-family="Times,serif" font-size="14.00">PyTorch</text>
<text text-anchor="middle" x="86.5" y="-650.3" font-family="Times,serif" font-size="14.00">Quantisation Aware Training</text>
<text text-anchor="middle" x="86.5" y="-635.3" font-family="Times,serif" font-size="14.00">Torch model</text>
</g>
<!-- ONNX model -->
<g id="node4" class="node">
<title>ONNX model</title>
<polygon fill="none" stroke="black" points="319.5,-569 225.5,-569 225.5,-475 319.5,-475 319.5,-569"></polygon>
<text text-anchor="middle" x="272.5" y="-518.3" font-family="Times,serif" font-size="14.00">ONNX model</text>
</g>
<!-- PyTorch\nQuantisation Aware Training\nTorch model&#45;&gt;ONNX model -->
<g id="edge1" class="edge">
<title>PyTorch\nQuantisation Aware Training\nTorch model-&gt;ONNX model</title>
<path fill="none" stroke="black" d="M123.25,-627.32C149.96,-608.65 186.58,-583.05 216.87,-561.88"></path>
<polygon fill="black" stroke="black" points="219.03,-564.64 225.23,-556.04 215.02,-558.9 219.03,-564.64"></polygon>
<text text-anchor="middle" x="208" y="-590.8" font-family="Times,serif" font-size="14.00">Torch API</text>
</g>
<!-- PyTorch\nPost Training Quantisation\n(Dynamic/Weight only)\nTorch model -->
<g id="node2" class="node">
<title>PyTorch\nPost Training Quantisation\n(Dynamic/Weight only)\nTorch model</title>
<polygon fill="none" stroke="black" points="353.5,-688 195.5,-688 191.5,-684 191.5,-620 349.5,-620 353.5,-624 353.5,-688"></polygon>
<polyline fill="none" stroke="black" points="349.5,-684 191.5,-684 "></polyline>
<polyline fill="none" stroke="black" points="349.5,-684 349.5,-620 "></polyline>
<polyline fill="none" stroke="black" points="349.5,-684 353.5,-688 "></polyline>
<text text-anchor="middle" x="272.5" y="-672.8" font-family="Times,serif" font-size="14.00">PyTorch</text>
<text text-anchor="middle" x="272.5" y="-657.8" font-family="Times,serif" font-size="14.00">Post Training Quantisation</text>
<text text-anchor="middle" x="272.5" y="-642.8" font-family="Times,serif" font-size="14.00">(Dynamic/Weight only)</text>
<text text-anchor="middle" x="272.5" y="-627.8" font-family="Times,serif" font-size="14.00">Torch model</text>
</g>
<!-- PyTorch\nPost Training Quantisation\n(Dynamic/Weight only)\nTorch model&#45;&gt;ONNX model -->
<g id="edge2" class="edge">
<title>PyTorch\nPost Training Quantisation\n(Dynamic/Weight only)\nTorch model-&gt;ONNX model</title>
<path fill="none" stroke="black" d="M272.5,-619.86C272.5,-607.63 272.5,-593.4 272.5,-579.68"></path>
<polygon fill="black" stroke="black" points="276,-579.32 272.5,-569.32 269,-579.32 276,-579.32"></polygon>
<text text-anchor="middle" x="301" y="-590.8" font-family="Times,serif" font-size="14.00">Torch API</text>
</g>
<!-- PyTorch\nPost Training Quantisation\n(Static)\nTorch model -->
<g id="node3" class="node">
<title>PyTorch\nPost Training Quantisation\n(Static)\nTorch model</title>
<polygon fill="none" stroke="black" points="533.5,-688 375.5,-688 371.5,-684 371.5,-620 529.5,-620 533.5,-624 533.5,-688"></polygon>
<polyline fill="none" stroke="black" points="529.5,-684 371.5,-684 "></polyline>
<polyline fill="none" stroke="black" points="529.5,-684 529.5,-620 "></polyline>
<polyline fill="none" stroke="black" points="529.5,-684 533.5,-688 "></polyline>
<text text-anchor="middle" x="452.5" y="-672.8" font-family="Times,serif" font-size="14.00">PyTorch</text>
<text text-anchor="middle" x="452.5" y="-657.8" font-family="Times,serif" font-size="14.00">Post Training Quantisation</text>
<text text-anchor="middle" x="452.5" y="-642.8" font-family="Times,serif" font-size="14.00">(Static)</text>
<text text-anchor="middle" x="452.5" y="-627.8" font-family="Times,serif" font-size="14.00">Torch model</text>
</g>
<!-- PyTorch\nPost Training Quantisation\n(Static)\nTorch model&#45;&gt;ONNX model -->
<g id="edge3" class="edge">
<title>PyTorch\nPost Training Quantisation\n(Static)\nTorch model-&gt;ONNX model</title>
<path fill="none" stroke="black" d="M406.61,-619.86C382.66,-602.56 353.16,-581.25 327.93,-563.04"></path>
<polygon fill="black" stroke="black" points="329.71,-560 319.56,-556.99 325.62,-565.68 329.71,-560"></polygon>
<text text-anchor="middle" x="408" y="-590.8" font-family="Times,serif" font-size="14.00">Torch API</text>
</g>
<!-- Blob model -->
<g id="node5" class="node">
<title>Blob model</title>
<polygon fill="none" stroke="black" points="249,-424 168,-424 168,-343 249,-343 249,-424"></polygon>
<text text-anchor="middle" x="208.5" y="-379.8" font-family="Times,serif" font-size="14.00">Blob model</text>
</g>
<!-- ONNX model&#45;&gt;Blob model -->
<g id="edge4" class="edge">
<title>ONNX model-&gt;Blob model</title>
<path fill="none" stroke="black" d="M225.21,-481.81C218.84,-474.27 213.23,-465.92 209.5,-457 206.57,-449.97 204.96,-442.22 204.22,-434.47"></path>
<polygon fill="black" stroke="black" points="207.71,-434.17 203.71,-424.36 200.72,-434.52 207.71,-434.17"></polygon>
<text text-anchor="middle" x="262.5" y="-445.8" font-family="Times,serif" font-size="14.00">Blob converter API</text>
</g>
<!-- TF model -->
<g id="node6" class="node">
<title>TF model</title>
<polygon fill="none" stroke="black" points="373,-419 302,-419 302,-348 373,-348 373,-419"></polygon>
<text text-anchor="middle" x="337.5" y="-379.8" font-family="Times,serif" font-size="14.00">TF model</text>
</g>
<!-- ONNX model&#45;&gt;TF model -->
<g id="edge5" class="edge">
<title>ONNX model-&gt;TF model</title>
<path fill="none" stroke="black" d="M305.86,-474.76C309.38,-468.93 312.69,-462.93 315.5,-457 319.69,-448.18 323.29,-438.38 326.31,-428.91"></path>
<polygon fill="black" stroke="black" points="329.69,-429.8 329.23,-419.22 322.99,-427.78 329.69,-429.8"></polygon>
<text text-anchor="middle" x="353.5" y="-445.8" font-family="Times,serif" font-size="14.00">ONNX API</text>
</g>
<!-- TFLite model -->
<g id="node7" class="node">
<title>TFLite model</title>
<polygon fill="none" stroke="black" points="383.5,-292 291.5,-292 291.5,-200 383.5,-200 383.5,-292"></polygon>
<text text-anchor="middle" x="337.5" y="-242.3" font-family="Times,serif" font-size="14.00">TFLite model</text>
</g>
<!-- TF model&#45;&gt;TFLite model -->
<g id="edge6" class="edge">
<title>TF model-&gt;TFLite model</title>
<path fill="none" stroke="black" d="M337.5,-347.96C337.5,-334.2 337.5,-318.01 337.5,-302.67"></path>
<polygon fill="black" stroke="black" points="341,-302.23 337.5,-292.23 334,-302.23 341,-302.23"></polygon>
<text text-anchor="middle" x="382.5" y="-313.8" font-family="Times,serif" font-size="14.00">TensorFlow API</text>
</g>
<!-- EdgeTPU TFLite model -->
<g id="node8" class="node">
<title>EdgeTPU TFLite model</title>
<polygon fill="none" stroke="black" points="412,-149 263,-149 263,0 412,0 412,-149"></polygon>
<text text-anchor="middle" x="337.5" y="-70.8" font-family="Times,serif" font-size="14.00">EdgeTPU TFLite model</text>
</g>
<!-- TFLite model&#45;&gt;EdgeTPU TFLite model -->
<g id="edge7" class="edge">
<title>TFLite model-&gt;EdgeTPU TFLite model</title>
<path fill="none" stroke="black" d="M337.5,-199.58C337.5,-187.11 337.5,-173.18 337.5,-159.29"></path>
<polygon fill="black" stroke="black" points="341,-159.2 337.5,-149.2 334,-159.2 341,-159.2"></polygon>
<text text-anchor="middle" x="382.5" y="-170.8" font-family="Times,serif" font-size="14.00">TensorFlow API</text>
</g>
</g>
</svg>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="ONNX-Quantisation-approach">
<a class="anchor" href="#ONNX-Quantisation-approach" aria-hidden="true"><span class="octicon octicon-link"></span></a>ONNX Quantisation approach<a class="anchor-link" href="#ONNX-Quantisation-approach"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_svg output_subarea output_execute_result">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="268pt" height="826pt" viewbox="0.00 0.00 267.50 826.00">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 822)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-822 263.5,-822 263.5,4 -4,4"></polygon>
<!-- PyTorch\nStandard Training\nTorch model -->
<g id="node1" class="node">
<title>PyTorch\nStandard Training\nTorch model</title>
<polygon fill="none" stroke="black" points="161.5,-818 51.5,-818 47.5,-814 47.5,-765 157.5,-765 161.5,-769 161.5,-818"></polygon>
<polyline fill="none" stroke="black" points="157.5,-814 47.5,-814 "></polyline>
<polyline fill="none" stroke="black" points="157.5,-814 157.5,-765 "></polyline>
<polyline fill="none" stroke="black" points="157.5,-814 161.5,-818 "></polyline>
<text text-anchor="middle" x="104.5" y="-802.8" font-family="Times,serif" font-size="14.00">PyTorch</text>
<text text-anchor="middle" x="104.5" y="-787.8" font-family="Times,serif" font-size="14.00">Standard Training</text>
<text text-anchor="middle" x="104.5" y="-772.8" font-family="Times,serif" font-size="14.00">Torch model</text>
</g>
<!-- ONNX model -->
<g id="node2" class="node">
<title>ONNX model</title>
<polygon fill="none" stroke="black" points="151.5,-714 57.5,-714 57.5,-620 151.5,-620 151.5,-714"></polygon>
<text text-anchor="middle" x="104.5" y="-663.3" font-family="Times,serif" font-size="14.00">ONNX model</text>
</g>
<!-- PyTorch\nStandard Training\nTorch model&#45;&gt;ONNX model -->
<g id="edge1" class="edge">
<title>PyTorch\nStandard Training\nTorch model-&gt;ONNX model</title>
<path fill="none" stroke="black" d="M104.5,-764.82C104.5,-753.08 104.5,-738.67 104.5,-724.58"></path>
<polygon fill="black" stroke="black" points="108,-724.43 104.5,-714.43 101,-724.43 108,-724.43"></polygon>
<text text-anchor="middle" x="133" y="-735.8" font-family="Times,serif" font-size="14.00">Torch API</text>
</g>
<!-- Quantised\nONNX model -->
<g id="node3" class="node">
<title>Quantised\nONNX model</title>
<polygon fill="none" stroke="black" points="151.5,-569 57.5,-569 57.5,-475 151.5,-475 151.5,-569"></polygon>
<text text-anchor="middle" x="104.5" y="-525.8" font-family="Times,serif" font-size="14.00">Quantised</text>
<text text-anchor="middle" x="104.5" y="-510.8" font-family="Times,serif" font-size="14.00">ONNX model</text>
</g>
<!-- ONNX model&#45;&gt;Quantised\nONNX model -->
<g id="edge2" class="edge">
<title>ONNX model-&gt;Quantised\nONNX model</title>
<path fill="none" stroke="black" d="M104.5,-619.97C104.5,-607.08 104.5,-592.93 104.5,-579.52"></path>
<polygon fill="black" stroke="black" points="108,-579.44 104.5,-569.44 101,-579.44 108,-579.44"></polygon>
<text text-anchor="middle" x="136.5" y="-590.8" font-family="Times,serif" font-size="14.00">ONNX API</text>
</g>
<!-- Blob model -->
<g id="node4" class="node">
<title>Blob model</title>
<polygon fill="none" stroke="black" points="81,-424 0,-424 0,-343 81,-343 81,-424"></polygon>
<text text-anchor="middle" x="40.5" y="-379.8" font-family="Times,serif" font-size="14.00">Blob model</text>
</g>
<!-- Quantised\nONNX model&#45;&gt;Blob model -->
<g id="edge3" class="edge">
<title>Quantised\nONNX model-&gt;Blob model</title>
<path fill="none" stroke="black" d="M57.21,-481.81C50.84,-474.27 45.23,-465.92 41.5,-457 38.57,-449.97 36.96,-442.22 36.22,-434.47"></path>
<polygon fill="black" stroke="black" points="39.71,-434.17 35.71,-424.36 32.72,-434.52 39.71,-434.17"></polygon>
<text text-anchor="middle" x="94.5" y="-445.8" font-family="Times,serif" font-size="14.00">Blob converter API</text>
</g>
<!-- TF model -->
<g id="node5" class="node">
<title>TF model</title>
<polygon fill="none" stroke="black" points="205,-419 134,-419 134,-348 205,-348 205,-419"></polygon>
<text text-anchor="middle" x="169.5" y="-379.8" font-family="Times,serif" font-size="14.00">TF model</text>
</g>
<!-- Quantised\nONNX model&#45;&gt;TF model -->
<g id="edge4" class="edge">
<title>Quantised\nONNX model-&gt;TF model</title>
<path fill="none" stroke="black" d="M137.86,-474.76C141.38,-468.93 144.69,-462.93 147.5,-457 151.69,-448.18 155.29,-438.38 158.31,-428.91"></path>
<polygon fill="black" stroke="black" points="161.69,-429.8 161.23,-419.22 154.99,-427.78 161.69,-429.8"></polygon>
<text text-anchor="middle" x="184.5" y="-445.8" font-family="Times,serif" font-size="14.00">ONNX API</text>
</g>
<!-- TFLite model -->
<g id="node6" class="node">
<title>TFLite model</title>
<polygon fill="none" stroke="black" points="215.5,-292 123.5,-292 123.5,-200 215.5,-200 215.5,-292"></polygon>
<text text-anchor="middle" x="169.5" y="-242.3" font-family="Times,serif" font-size="14.00">TFLite model</text>
</g>
<!-- TF model&#45;&gt;TFLite model -->
<g id="edge5" class="edge">
<title>TF model-&gt;TFLite model</title>
<path fill="none" stroke="black" d="M169.5,-347.96C169.5,-334.2 169.5,-318.01 169.5,-302.67"></path>
<polygon fill="black" stroke="black" points="173,-302.23 169.5,-292.23 166,-302.23 173,-302.23"></polygon>
<text text-anchor="middle" x="214.5" y="-313.8" font-family="Times,serif" font-size="14.00">TensorFlow API</text>
</g>
<!-- EdgeTPU TFLite model -->
<g id="node7" class="node">
<title>EdgeTPU TFLite model</title>
<polygon fill="none" stroke="black" points="244,-149 95,-149 95,0 244,0 244,-149"></polygon>
<text text-anchor="middle" x="169.5" y="-70.8" font-family="Times,serif" font-size="14.00">EdgeTPU TFLite model</text>
</g>
<!-- TFLite model&#45;&gt;EdgeTPU TFLite model -->
<g id="edge6" class="edge">
<title>TFLite model-&gt;EdgeTPU TFLite model</title>
<path fill="none" stroke="black" d="M169.5,-199.58C169.5,-187.11 169.5,-173.18 169.5,-159.29"></path>
<polygon fill="black" stroke="black" points="173,-159.2 169.5,-149.2 166,-159.2 173,-159.2"></polygon>
<text text-anchor="middle" x="214.5" y="-170.8" font-family="Times,serif" font-size="14.00">TensorFlow API</text>
</g>
</g>
</svg>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="API">
<a class="anchor" href="#API" aria-hidden="true"><span class="octicon octicon-link"></span></a>API<a class="anchor-link" href="#API"> </a>
</h2>
<ol>
<li>PyTorch Quantization (QAT)<ul>
<li><a href="https://pytorch.org/tutorials/advanced/static_quantization_tutorial.html">https://pytorch.org/tutorials/advanced/static_quantization_tutorial.html</a></li>
<li>import torch</li>
<li>from torchvision.models import MobileNetV2<ul>
<li>model = MobileNetV2()</li>
</ul>
</li>
<li>Fuse relu &amp; Conv2d</li>
<li>Insert Stubs to model <ul>
<li>model = nn.Sequential(torch.quantization.QuantStub(), model, torch.quantization.DeQuantStub())</li>
</ul>
</li>
<li>Prepare model<ul>
<li>m.train()</li>
<li>backend = "fbgemm"</li>
<li>model.qconfig = torch.quantization.get_default_qconfig(backend)</li>
<li>torch.quantization.prepare_qat(model, inplace=True)</li>
</ul>
</li>
<li>Run standard training loop</li>
<li>Convert<ul>
<li>m.eval()</li>
<li>model_quantized = torch.quantization.convert(model, inplace=True)</li>
<li>torch.save(model_quantized, model_file_path)</li>
</ul>
</li>
</ul>
</li>
</ol>
<ol>
<li>PyTorch -&gt; ONNX<ul>
<li><a href="https://pytorch.org/docs/stable/onnx.html">https://pytorch.org/docs/stable/onnx.html</a></li>
<li>import torch</li>
<li>torch.onnx.export(model, sample_input, onnx_model_path, opset_version=12, input_names=['input'], output_names=['output'])</li>
</ul>
</li>
</ol>
<ol>
<li>ONNX Qunatization (Dynamic)<ul>
<li><a href="https://onnxruntime.ai/docs/performance/quantization.html">https://onnxruntime.ai/docs/performance/quantization.html</a></li>
<li>import onnx</li>
<li>from onnxruntime.quantization import quantize_dynamic, QuantType</li>
<li>quantized_model = quantize_dynamic(model_path, quantised_model_path)</li>
</ul>
</li>
</ol>
<ol>
<li>ONNX -&gt; Blob<ul>
<li><a href="https://docs.luxonis.com/en/latest/pages/tutorials/creating-custom-nn-models/">https://docs.luxonis.com/en/latest/pages/tutorials/creating-custom-nn-models/</a></li>
<li>import blobconverter</li>
<li>onnx_model = onnx.load("./results/networks/test1.onnx")
model_simpified, check = simplify(onnx_model)
onnx.save(model_simpified, "./results/networks/test_sim1.onnx")</li>
<li>blobconverter.from_onnx(model=onnx_model_path, data_type="FP16", shaves=6, use_cache=False, output_dir=blob_model_path, optimizer_params=[])</li>
</ul>
</li>
</ol>
<ol>
<li>ONNX -&gt; TF<ul>
<li><a href="https://github.com/onnx/onnx-tensorflow/blob/main/example/onnx_to_tf.py">https://github.com/onnx/onnx-tensorflow/blob/main/example/onnx_to_tf.py</a></li>
<li>import onnx</li>
<li>from onnx_tf.backend import prepare</li>
<li>onnx_model = onnx.load(onnx_model_path)</li>
<li>tf_rep = prepare(onnx_model)</li>
<li>tf_rep.export_graph(tf_model_path)</li>
</ul>
</li>
</ol>
<ol>
<li>TF -&gt; TFLite<ul>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter">https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter</a></li>
<li>import tensorflow as tf</li>
<li>converter = tf.lite.TFLiteConverter.from_saved_model(tf_model_path)</li>
<li>tflite_model = converter.convert()</li>
<li>with open(tflite_model_path, 'wb') as f: f.write(tflite_model)</li>
</ul>
</li>
</ol>
<ol>
<li>
<p>TFLite -&gt; EdgeTPU TFLite</p>
<ul>
<li><a href="https://coral.ai/docs/edgetpu/compiler/">https://coral.ai/docs/edgetpu/compiler/</a></li>
<li>curl <a href="https://packages.cloud.google.com/apt/doc/apt-key.gpg">https://packages.cloud.google.com/apt/doc/apt-key.gpg</a> | sudo apt-key add -</li>
<li>echo "deb <a href="https://packages.cloud.google.com/apt">https://packages.cloud.google.com/apt</a> coral-edgetpu-stable main" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list</li>
<li>sudo apt-get update</li>
<li>sudo apt-get install edgetpu-compiler</li>
<li>edgetpu_compiler [options] tflite_model_path</li>
</ul>
</li>
<li>
<p>PyTorch Quantization (PTQ - Dynamic/Weight only)</p>
<ul>
<li><a href="https://pytorch.org/blog/quantization-in-practice/">https://pytorch.org/blog/quantization-in-practice/</a></li>
</ul>
</li>
<li>PyTorch Quantization (PTQ - Static)<ul>
<li><a href="https://pytorch.org/blog/quantization-in-practice/">https://pytorch.org/blog/quantization-in-practice/</a></li>
</ul>
</li>
</ol>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>rm -rf /tmp/MobileNet*
<span class="o">!</span>ls -lh /tmp/MobileNet*
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>ls: cannot access '/tmp/MobileNet*': No such file or directory
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">torch_model_path</span> <span class="o">=</span> <span class="s2">"/tmp/MobileNetV2.pt"</span>
<span class="n">torch_QAT_quant_path</span> <span class="o">=</span> <span class="s2">"/tmp/MobileNetV2_TorchQATQuant.pt"</span>
<span class="n">onnx_model_path</span> <span class="o">=</span> <span class="s2">"/tmp/MobileNetV2.onnx"</span>
<span class="n">onnx_quant_model_path</span> <span class="o">=</span> <span class="s2">"/tmp/MobileNetV2_OnnxQuant.onnx"</span>
<span class="n">onnx_sim_model_path</span> <span class="o">=</span> <span class="s2">"/tmp/MobileNetV2_OnnxSim.onnx"</span>
<span class="n">blob_model_path</span> <span class="o">=</span> <span class="s2">"/tmp/MobileNetV2.blob"</span>
<span class="n">tf_model_path</span> <span class="o">=</span> <span class="s2">"/tmp/MobileNetV2.tf"</span>
<span class="n">tflite_model_path</span> <span class="o">=</span> <span class="s2">"/tmp/MobileNetV2.tflite"</span>
<span class="n">edgetpu_tflite_model_path</span> <span class="o">=</span> <span class="s2">"/tmp/MobileNetV2_edgetpu.tflite"</span>
<span class="n">torch_PTQ_Weight_Eager_path</span> <span class="o">=</span> <span class="s2">"/tmp/MobileNet_V2_Torch_PTQ_Quant_W_EG.pt"</span>
<span class="n">torch_PTQ_Weight_FX_path</span> <span class="o">=</span> <span class="s2">"/tmp/MobileNet_V2_Torch_PTQ_Quant_W_FX.pt"</span>
<span class="n">torch_PTQ_Static_Eager_path</span> <span class="o">=</span> <span class="s2">"/tmp/MobileNet_V2_Torch_PTQ_Quant_S_EG.pt"</span>
<span class="n">torch_PTQ_Static_FX_path</span> <span class="o">=</span> <span class="s2">"/tmp/MobileNet_V2_Torch_PTQ_Quant_S_FX.pt"</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="PyTorch-Model">
<a class="anchor" href="#PyTorch-Model" aria-hidden="true"><span class="octicon octicon-link"></span></a>PyTorch Model<a class="anchor-link" href="#PyTorch-Model"> </a>
</h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">torchvision.models</span> <span class="kn">import</span> <span class="n">MobileNetV2</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MobileNetV2</span><span class="p">()</span>

<span class="n">data_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s2">"./data"</span><span class="p">)</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span><span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)),</span> <span class="n">transforms</span><span class="o">.</span><span class="n">RandomErasing</span><span class="p">()])</span>
<span class="n">trainset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
<span class="n">train_sub_len</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainset</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="n">train_subset</span><span class="p">,</span> <span class="n">val_subset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">random_split</span><span class="p">(</span><span class="n">trainset</span><span class="p">,</span> <span class="p">[</span><span class="n">train_sub_len</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainset</span><span class="p">)</span> <span class="o">-</span> <span class="n">train_sub_len</span><span class="p">])</span>
<span class="n">trainloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_subset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">trainloader</span><span class="p">:</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Files already downloaded and verified
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">torch_model_path</span><span class="p">)</span>
<span class="o">!</span>ls -lh /tmp/MobileNet*
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>-rw-r--r-- 1 root root 14M Jan 20 14:20 /tmp/MobileNetV2.pt
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1.-PyTorch-Quantization-(QAT)">
<a class="anchor" href="#1.-PyTorch-Quantization-(QAT)" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. PyTorch Quantization (QAT)<a class="anchor-link" href="#1.-PyTorch-Quantization-(QAT)"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">torchvision.models</span> <span class="kn">import</span> <span class="n">MobileNetV2</span>

<span class="n">data_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s2">"./data"</span><span class="p">)</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span><span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)),</span> <span class="n">transforms</span><span class="o">.</span><span class="n">RandomErasing</span><span class="p">()])</span>
<span class="n">trainset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
<span class="n">train_sub_len</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainset</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="n">train_subset</span><span class="p">,</span> <span class="n">val_subset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">random_split</span><span class="p">(</span><span class="n">trainset</span><span class="p">,</span> <span class="p">[</span><span class="n">train_sub_len</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainset</span><span class="p">)</span> <span class="o">-</span> <span class="n">train_sub_len</span><span class="p">])</span>
<span class="n">trainloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_subset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">MobileNetV2</span><span class="p">()</span>

<span class="sd">"""Fuse"""</span>
<span class="c1"># pair_of_modules_to_fuze = []</span>
<span class="c1"># for name, layer in model.named_modules():</span>
<span class="c1">#     if isinstance(layer, torch.nn.Linear):</span>
<span class="c1">#         pair_of_modules_to_fuze.append([name.split('.')[-1]])</span>
<span class="c1">#     elif isinstance(layer, torch.nn.ReLU) and len(pair_of_modules_to_fuze) &gt; 0:</span>
<span class="c1">#         pair_of_modules_to_fuze[-1].append(name.split('.')[-1])</span>
<span class="c1"># pair_of_modules_to_fuze = list(filter(lambda x: len(x) == 2, pair_of_modules_to_fuze))</span>
<span class="c1"># torch.quantization.fuse_modules(model.modules(), pair_of_modules_to_fuze, inplace=True)</span>


<span class="sd">"""Insert stubs"""</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">QuantStub</span><span class="p">(),</span> 
                  <span class="n">model</span><span class="p">,</span> 
                  <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">DeQuantStub</span><span class="p">())</span>


<span class="sd">"""Prepare"""</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">qconfig</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">get_default_qconfig</span><span class="p">(</span><span class="s2">"fbgemm"</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">prepare_qat</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="sd">"""Training Loop"""</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>


<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">trainloader</span><span class="p">:</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>


<span class="sd">"""Convert"""</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">model_quantized</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model_quantized</span><span class="p">,</span> <span class="n">torch_QAT_quant_path</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Files already downloaded and verified
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.8/dist-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.
  warnings.warn(
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>ls -lh /tmp/MobileNet*
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.pt
-rw-r--r-- 1 root root 4.1M Jan 20 14:20 /tmp/MobileNetV2_TorchQATQuant.pt
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="2.-PyTorch-to-ONNX">
<a class="anchor" href="#2.-PyTorch-to-ONNX" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. PyTorch to ONNX<a class="anchor-link" href="#2.-PyTorch-to-ONNX"> </a>
</h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">torch_model_path</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span>               
                  <span class="n">images</span><span class="p">,</span>                         
                  <span class="n">onnx_model_path</span><span class="p">,</span>   
                  <span class="n">export_params</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>             
                  <span class="n">do_constant_folding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  
                  <span class="n">input_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'input'</span><span class="p">],</span>   
                  <span class="n">output_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'output'</span><span class="p">],</span> 
                  <span class="n">dynamic_axes</span><span class="o">=</span><span class="p">{</span><span class="s1">'input'</span> <span class="p">:</span> <span class="p">{</span><span class="mi">0</span> <span class="p">:</span> <span class="s1">'batch_size'</span><span class="p">},</span>   
                                <span class="s1">'output'</span> <span class="p">:</span> <span class="p">{</span><span class="mi">0</span> <span class="p">:</span> <span class="s1">'batch_size'</span><span class="p">}})</span>

<span class="o">!</span>ls -lh /tmp/MobileNet*
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.onnx
-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.pt
-rw-r--r-- 1 root root 4.1M Jan 20 14:20 /tmp/MobileNetV2_TorchQATQuant.pt
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="3.-ONNX-Quantization-(Dynamic)">
<a class="anchor" href="#3.-ONNX-Quantization-(Dynamic)" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. ONNX Quantization (Dynamic)<a class="anchor-link" href="#3.-ONNX-Quantization-(Dynamic)"> </a>
</h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install onnx -q
<span class="o">!</span>pip install onnxruntime -q
<span class="kn">from</span> <span class="nn">onnxruntime.quantization</span> <span class="kn">import</span> <span class="n">quantize_dynamic</span><span class="p">,</span> <span class="n">QuantType</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">13.5/13.5 MB</span> <span class="ansi-red-fg">108.5 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">1.0/1.0 MB</span> <span class="ansi-red-fg">66.6 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
<span class="ansi-red-fg">ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
tensorflow 2.9.2 requires protobuf&lt;3.20,&gt;=3.9.2, but you have protobuf 3.20.3 which is incompatible.
tensorboard 2.9.1 requires protobuf&lt;3.20,&gt;=3.9.2, but you have protobuf 3.20.3 which is incompatible.</span><span class="ansi-red-fg">
</span><span class="ansi-red-fg">     </span><span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">4.5/4.5 MB</span> <span class="ansi-red-fg">89.5 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">46.0/46.0 KB</span> <span class="ansi-red-fg">4.9 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">86.8/86.8 KB</span> <span class="ansi-red-fg">9.5 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">quantized_model</span> <span class="o">=</span> <span class="n">quantize_dynamic</span><span class="p">(</span><span class="n">onnx_model_path</span><span class="p">,</span> <span class="n">onnx_quant_model_path</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4.-ONNX-to-Blob">
<a class="anchor" href="#4.-ONNX-to-Blob" aria-hidden="true"><span class="octicon octicon-link"></span></a>4. ONNX to Blob<a class="anchor-link" href="#4.-ONNX-to-Blob"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install onnxsim -q

<span class="o">!</span>pip install <span class="nv">Flask</span><span class="o">==</span><span class="m">2</span>.1.0 <span class="nv">PyYAML</span><span class="o">==</span><span class="m">5</span>.4.1 <span class="nv">boto3</span><span class="o">==</span><span class="m">1</span>.17.39 <span class="nv">gunicorn</span><span class="o">==</span><span class="m">20</span>.1.0 sentry-sdk -q
<span class="o">!</span>pip install blobconverter -q
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">2.0/2.0 MB</span> <span class="ansi-red-fg">66.8 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">238.9/238.9 KB</span> <span class="ansi-red-fg">21.2 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">84.5/84.5 KB</span> <span class="ansi-red-fg">9.4 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">95.2/95.2 KB</span> <span class="ansi-red-fg">9.6 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">662.4/662.4 KB</span> <span class="ansi-red-fg">29.8 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">131.4/131.4 KB</span> <span class="ansi-red-fg">14.9 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">79.5/79.5 KB</span> <span class="ansi-red-fg">9.5 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">177.4/177.4 KB</span> <span class="ansi-red-fg">15.3 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">232.7/232.7 KB</span> <span class="ansi-red-fg">21.5 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">96.6/96.6 KB</span> <span class="ansi-red-fg">11.3 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">133.1/133.1 KB</span> <span class="ansi-red-fg">15.1 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">73.4/73.4 KB</span> <span class="ansi-red-fg">7.3 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">7.7/7.7 MB</span> <span class="ansi-red-fg">77.3 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">140.6/140.6 KB</span> <span class="ansi-red-fg">14.0 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
<span class="ansi-red-fg">ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
tensorboard 2.9.1 requires protobuf&lt;3.20,&gt;=3.9.2, but you have protobuf 3.20.3 which is incompatible.
notebook 5.7.16 requires jinja2&lt;=3.0.0, but you have jinja2 3.1.2 which is incompatible.</span><span class="ansi-red-fg">
</span></pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">from</span> <span class="nn">onnxsim</span> <span class="kn">import</span> <span class="n">simplify</span>
<span class="kn">import</span> <span class="nn">blobconverter</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_simpified</span><span class="p">,</span> <span class="n">check</span> <span class="o">=</span> <span class="n">simplify</span><span class="p">(</span><span class="n">onnx_model_path</span><span class="p">)</span>
<span class="n">onnx</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model_simpified</span><span class="p">,</span> <span class="n">onnx_sim_model_path</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># blobconverter.from_onnx(</span>
<span class="c1">#     model=onnx_sim_model_path,</span>
<span class="c1">#     data_type="FP16",</span>
<span class="c1">#     shaves=6,</span>
<span class="c1">#     use_cache=False,</span>
<span class="c1">#     output_dir=blob_model_path,</span>
<span class="c1">#     optimizer_params=[])</span>

<span class="o">!</span>ls -lh /tmp/MobileNet*
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.onnx
-rw-r--r-- 1 root root 3.6M Jan 20 14:20 /tmp/MobileNetV2_OnnxQuant.onnx
-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2_OnnxSim.onnx
-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.pt
-rw-r--r-- 1 root root 4.1M Jan 20 14:20 /tmp/MobileNetV2_TorchQATQuant.pt
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="5.-ONNX-to-TF">
<a class="anchor" href="#5.-ONNX-to-TF" aria-hidden="true"><span class="octicon octicon-link"></span></a>5. ONNX to TF<a class="anchor-link" href="#5.-ONNX-to-TF"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install onnx-tf -q
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">226.1/226.1 KB</span> <span class="ansi-red-fg">16.3 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">1.1/1.1 MB</span> <span class="ansi-red-fg">53.7 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">onnx_tf.backend</span> <span class="kn">import</span> <span class="n">prepare</span>
<span class="kn">import</span> <span class="nn">tensorflow_probability</span>
<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">onnx_model_path</span><span class="p">)</span>
<span class="n">tf_rep</span> <span class="o">=</span> <span class="n">prepare</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
<span class="n">tf_rep</span><span class="o">.</span><span class="n">export_graph</span><span class="p">(</span><span class="n">tf_model_path</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>ls -lh /tmp/MobileNet*
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.onnx
-rw-r--r-- 1 root root 3.6M Jan 20 14:20 /tmp/MobileNetV2_OnnxQuant.onnx
-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2_OnnxSim.onnx
-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.pt
-rw-r--r-- 1 root root 4.1M Jan 20 14:20 /tmp/MobileNetV2_TorchQATQuant.pt

/tmp/MobileNetV2.tf:
total 14M
drwxr-xr-x 2 root root 4.0K Jan 20 14:21 assets
-rw-r--r-- 1 root root  14M Jan 20 14:21 saved_model.pb
drwxr-xr-x 2 root root 4.0K Jan 20 14:21 variables
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="6.-TF-to-TFLite">
<a class="anchor" href="#6.-TF-to-TFLite" aria-hidden="true"><span class="octicon octicon-link"></span></a>6. TF to TFLite<a class="anchor-link" href="#6.-TF-to-TFLite"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># def fake_dataset_generator(shape, n_iter):</span>
<span class="c1">#     def dataset():</span>
<span class="c1">#         for _ in range(n_iter):</span>
<span class="c1">#             data = np.random.randn(*shape)</span>
<span class="c1">#             data *= (1 / 255)</span>
<span class="c1">#             batch = np.expand_dims(data, axis=0)</span>
<span class="c1">#             yield [batch.astype(np.float32)]</span>
<span class="c1">#     return dataset</span>
<span class="c1"># datagen = fake_dataset_generator((192, 192, 3), 10)</span>

<span class="n">converter</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">lite</span><span class="o">.</span><span class="n">TFLiteConverter</span><span class="o">.</span><span class="n">from_saved_model</span><span class="p">(</span><span class="n">tf_model_path</span><span class="p">)</span>
<span class="c1"># converter.representative_dataset = datagen</span>
<span class="c1"># converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]</span>
<span class="c1"># converter.inference_input_type = tf.uint8</span>
<span class="c1"># converter.inference_output_type = tf.uint8</span>
<span class="c1"># converter.optimizations = [tf.lite.Optimize.DEFAULT]</span>
<span class="n">tflite_model</span> <span class="o">=</span> <span class="n">converter</span><span class="o">.</span><span class="n">convert</span><span class="p">()</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">tflite_model_path</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span> 
  <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">tflite_model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>ls -lh /tmp/MobileNet*
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.onnx
-rw-r--r-- 1 root root 3.6M Jan 20 14:20 /tmp/MobileNetV2_OnnxQuant.onnx
-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2_OnnxSim.onnx
-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.pt
-rw-r--r-- 1 root root  14M Jan 20 14:22 /tmp/MobileNetV2.tflite
-rw-r--r-- 1 root root 4.1M Jan 20 14:20 /tmp/MobileNetV2_TorchQATQuant.pt

/tmp/MobileNetV2.tf:
total 14M
drwxr-xr-x 2 root root 4.0K Jan 20 14:21 assets
-rw-r--r-- 1 root root  14M Jan 20 14:21 saved_model.pb
drwxr-xr-x 2 root root 4.0K Jan 20 14:21 variables
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="7.-TFLite-to-EdgeTPU-TFLite">
<a class="anchor" href="#7.-TFLite-to-EdgeTPU-TFLite" aria-hidden="true"><span class="octicon octicon-link"></span></a>7. TFLite to EdgeTPU TFLite<a class="anchor-link" href="#7.-TFLite-to-EdgeTPU-TFLite"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>curl https://packages.cloud.google.com/apt/doc/apt-key.gpg <span class="p">|</span> sudo apt-key add -
<span class="o">!</span><span class="nb">echo</span> <span class="s2">"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main"</span> <span class="p">|</span> sudo tee /etc/apt/sources.list.d/coral-edgetpu.list
<span class="o">!</span>sudo apt-get update
<span class="o">!</span>sudo apt-get install edgetpu-compiler
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  1210  100  1210    0     0  60500      0 --:--:-- --:--:-- --:--:-- 60500
OK
deb https://packages.cloud.google.com/apt coral-edgetpu-stable main
Get:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]
Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease
Get:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]
Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]
Get:5 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]
Get:6 https://packages.cloud.google.com/apt coral-edgetpu-stable InRelease [6,332 B]
Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease
Get:8 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]
Hit:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease
Hit:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release
Get:11 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 Packages [2,317 B]
Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease
Get:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2,909 kB]
Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease
Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease
Get:17 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [982 kB]
Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,374 kB]
Get:19 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1,879 kB]
Get:20 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,284 kB]
Get:21 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,436 kB]
Get:22 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,003 kB]
Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,125 kB]
Fetched 15.4 MB in 2s (7,459 kB/s)
Reading package lists... Done
Reading package lists... Done
Building dependency tree       
Reading state information... Done
The following NEW packages will be installed:
  edgetpu-compiler
0 upgraded, 1 newly installed, 0 to remove and 30 not upgraded.
Need to get 7,913 kB of archives.
After this operation, 31.2 MB of additional disk space will be used.
Get:1 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 edgetpu-compiler amd64 16.0 [7,913 kB]
Fetched 7,913 kB in 1s (14.9 MB/s)
debconf: unable to initialize frontend: Dialog
debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, &lt;&gt; line 1.)
debconf: falling back to frontend: Readline
debconf: unable to initialize frontend: Readline
debconf: (This frontend requires a controlling tty.)
debconf: falling back to frontend: Teletype
dpkg-preconfigure: unable to re-open stdin: 
Selecting previously unselected package edgetpu-compiler.
(Reading database ... 129504 files and directories currently installed.)
Preparing to unpack .../edgetpu-compiler_16.0_amd64.deb ...
Unpacking edgetpu-compiler (16.0) ...
Setting up edgetpu-compiler (16.0) ...
Processing triggers for libc-bin (2.31-0ubuntu9.9) ...
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#https://github.com/google-coral/edgetpu/issues/453</span>
<span class="o">!</span>edgetpu_compiler <span class="s2">"/tmp/MobileNetV2.tflite"</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Edge TPU Compiler version 16.0.384591198
Started a compilation timeout timer of 180 seconds.
ERROR: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.
Compilation failed: Model failed in Tflite interpreter. Please ensure model can be loaded/run in Tflite interpreter.
Compilation child process completed within timeout period.
Compilation failed! 
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>ls -lh /tmp/MobileNet*
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.onnx
-rw-r--r-- 1 root root 3.6M Jan 20 14:20 /tmp/MobileNetV2_OnnxQuant.onnx
-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2_OnnxSim.onnx
-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.pt
-rw-r--r-- 1 root root  14M Jan 20 14:22 /tmp/MobileNetV2.tflite
-rw-r--r-- 1 root root 4.1M Jan 20 14:20 /tmp/MobileNetV2_TorchQATQuant.pt

/tmp/MobileNetV2.tf:
total 14M
drwxr-xr-x 2 root root 4.0K Jan 20 14:21 assets
-rw-r--r-- 1 root root  14M Jan 20 14:21 saved_model.pb
drwxr-xr-x 2 root root 4.0K Jan 20 14:21 variables
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="PyTorch-Quantization-(PTQ---Dynamic/Weight-only)">
<a class="anchor" href="#PyTorch-Quantization-(PTQ---Dynamic/Weight-only)" aria-hidden="true"><span class="octicon octicon-link"></span></a>PyTorch Quantization (PTQ - Dynamic/Weight only)<a class="anchor-link" href="#PyTorch-Quantization-(PTQ---Dynamic/Weight-only)"> </a>
</h2>
<p><a href="https://pytorch.org/blog/quantization-in-practice/">https://pytorch.org/blog/quantization-in-practice/</a></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">MobileNetV2</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1">## EAGER MODE</span>
<span class="kn">from</span> <span class="nn">torch.quantization</span> <span class="kn">import</span> <span class="n">quantize_dynamic</span>
<span class="n">model_quantized</span> <span class="o">=</span> <span class="n">quantize_dynamic</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">qconfig_spec</span><span class="o">=</span><span class="p">{</span><span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">},</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">qint8</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model_quantized</span><span class="p">,</span> <span class="n">torch_PTQ_Weight_Eager_path</span><span class="p">)</span>

<span class="c1">## FX MODE</span>
<span class="kn">from</span> <span class="nn">torch.quantization</span> <span class="kn">import</span> <span class="n">quantize_fx</span>
<span class="n">qconfig_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">""</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">default_dynamic_qconfig</span><span class="p">}</span> 
<span class="n">example_inputs</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">trainloader</span><span class="p">)</span>
<span class="n">img</span><span class="p">,</span> <span class="n">lab</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">example_inputs</span><span class="p">)</span>
<span class="n">model_prepared</span> <span class="o">=</span> <span class="n">quantize_fx</span><span class="o">.</span><span class="n">prepare_fx</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">qconfig_dict</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>
<span class="n">model_quantized</span> <span class="o">=</span> <span class="n">quantize_fx</span><span class="o">.</span><span class="n">convert_fx</span><span class="p">(</span><span class="n">model_prepared</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model_quantized</span><span class="p">,</span> <span class="n">torch_PTQ_Weight_FX_path</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.8/dist-packages/torch/ao/quantization/fx/prepare.py:1530: UserWarning: Passing a QConfig dictionary to prepare is deprecated and will not be supported in a future version. Please pass in a QConfigMapping instead.
  warnings.warn(
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>ls -lh /tmp/MobileNet*
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.onnx
-rw-r--r-- 1 root root 3.6M Jan 20 14:20 /tmp/MobileNetV2_OnnxQuant.onnx
-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2_OnnxSim.onnx
-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.pt
-rw-r--r-- 1 root root  14M Jan 20 14:22 /tmp/MobileNetV2.tflite
-rw-r--r-- 1 root root  10M Jan 20 14:22 /tmp/MobileNet_V2_Torch_PTQ_Quant_W_EG.pt
-rw-r--r-- 1 root root 9.8M Jan 20 14:22 /tmp/MobileNet_V2_Torch_PTQ_Quant_W_FX.pt
-rw-r--r-- 1 root root 4.1M Jan 20 14:20 /tmp/MobileNetV2_TorchQATQuant.pt

/tmp/MobileNetV2.tf:
total 14M
drwxr-xr-x 2 root root 4.0K Jan 20 14:21 assets
-rw-r--r-- 1 root root  14M Jan 20 14:21 saved_model.pb
drwxr-xr-x 2 root root 4.0K Jan 20 14:21 variables
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="PyTorch-Quantization-(PTQ---Static)">
<a class="anchor" href="#PyTorch-Quantization-(PTQ---Static)" aria-hidden="true"><span class="octicon octicon-link"></span></a>PyTorch Quantization (PTQ - Static)<a class="anchor-link" href="#PyTorch-Quantization-(PTQ---Static)"> </a>
</h2>
<p><a href="https://pytorch.org/blog/quantization-in-practice/">https://pytorch.org/blog/quantization-in-practice/</a></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">copy</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">MobileNetV2</span><span class="p">()</span>

<span class="c1">## EAGER MODE</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">m</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># torch.quantization.fuse_modules(m, ['0','1'], inplace=True) </span>
<span class="c1"># torch.quantization.fuse_modules(m, ['2','3'], inplace=True) </span>

<span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">QuantStub</span><span class="p">(),</span> 
                  <span class="n">m</span><span class="p">,</span> 
                  <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">DeQuantStub</span><span class="p">())</span>

<span class="n">m</span><span class="o">.</span><span class="n">qconfig</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">get_default_qconfig</span><span class="p">(</span><span class="s2">"fbgemm"</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">example_inputs</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">trainloader</span><span class="p">)</span>
<span class="n">img</span><span class="p">,</span> <span class="n">lab</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">example_inputs</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
  <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">m</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">model_quantized</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model_quantized</span><span class="p">,</span> <span class="n">torch_PTQ_Static_Eager_path</span><span class="p">)</span>


<span class="c1">## FX MODE</span>
<span class="kn">from</span> <span class="nn">torch.quantization</span> <span class="kn">import</span> <span class="n">quantize_fx</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">m</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">qconfig_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">""</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">get_default_qconfig</span><span class="p">(</span><span class="s2">"fbgemm"</span><span class="p">)}</span>
<span class="n">model_prepared</span> <span class="o">=</span> <span class="n">quantize_fx</span><span class="o">.</span><span class="n">prepare_fx</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">qconfig_dict</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
  <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">model_prepared</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">model_quantized</span> <span class="o">=</span> <span class="n">quantize_fx</span><span class="o">.</span><span class="n">convert_fx</span><span class="p">(</span><span class="n">model_prepared</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model_quantized</span><span class="p">,</span> <span class="n">torch_PTQ_Static_FX_path</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.8/dist-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.
  warnings.warn(
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>ls -lh /tmp/MobileNet*
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.onnx
-rw-r--r-- 1 root root 3.6M Jan 20 14:20 /tmp/MobileNetV2_OnnxQuant.onnx
-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2_OnnxSim.onnx
-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.pt
-rw-r--r-- 1 root root  14M Jan 20 14:22 /tmp/MobileNetV2.tflite
-rw-r--r-- 1 root root 4.1M Jan 20 14:22 /tmp/MobileNet_V2_Torch_PTQ_Quant_S_EG.pt
-rw-r--r-- 1 root root 3.8M Jan 20 14:22 /tmp/MobileNet_V2_Torch_PTQ_Quant_S_FX.pt
-rw-r--r-- 1 root root  10M Jan 20 14:22 /tmp/MobileNet_V2_Torch_PTQ_Quant_W_EG.pt
-rw-r--r-- 1 root root 9.8M Jan 20 14:22 /tmp/MobileNet_V2_Torch_PTQ_Quant_W_FX.pt
-rw-r--r-- 1 root root 4.1M Jan 20 14:20 /tmp/MobileNetV2_TorchQATQuant.pt

/tmp/MobileNetV2.tf:
total 14M
drwxr-xr-x 2 root root 4.0K Jan 20 14:21 assets
-rw-r--r-- 1 root root  14M Jan 20 14:21 saved_model.pb
drwxr-xr-x 2 root root 4.0K Jan 20 14:21 variables
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://pytorch.org/docs/stable/generated/torch.quantization.quantize_fx.prepare_fx.html">https://pytorch.org/docs/stable/generated/torch.quantization.quantize_fx.prepare_fx.html</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Test---QAT-IRIS">
<a class="anchor" href="#Test---QAT-IRIS" aria-hidden="true"><span class="octicon octicon-link"></span></a>Test - QAT IRIS<a class="anchor-link" href="#Test---QAT-IRIS"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
<span class="kn">from</span> <span class="nn">torch.quantization</span> <span class="kn">import</span> <span class="n">QuantStub</span><span class="p">,</span> <span class="n">DeQuantStub</span>

<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_X</span><span class="p">,</span> <span class="n">test_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">test_y</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">train_X</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
<span class="n">test_X</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
<span class="n">train_y</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">train_y</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
<span class="n">test_y</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">test_y</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>


<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quant</span> <span class="o">=</span> <span class="n">QuantStub</span><span class="p">()</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">dequant</span> <span class="o">=</span> <span class="n">DeQuantStub</span><span class="p">()</span> 

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">quant</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dequant</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">X</span>

<span class="n">m</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>

<span class="n">m</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">backend</span> <span class="o">=</span> <span class="s2">"fbgemm"</span>
<span class="n">m</span><span class="o">.</span><span class="n">qconfig</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">get_default_qconfig</span><span class="p">(</span><span class="n">backend</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">prepare_qat</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>


<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    
<span class="n">m</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">model_quantized</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model_quantized</span><span class="p">,</span> <span class="s1">'/tmp/Test_QAT_iris.pt'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.8/dist-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.
  warnings.warn(
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Test---Blob-Converter">
<a class="anchor" href="#Test---Blob-Converter" aria-hidden="true"><span class="octicon octicon-link"></span></a>Test - Blob Converter<a class="anchor-link" href="#Test---Blob-Converter"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">CatImgs</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img1</span><span class="p">,</span> <span class="n">img2</span><span class="p">,</span> <span class="n">img3</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">img1</span><span class="p">,</span> <span class="n">img2</span><span class="p">,</span> <span class="n">img3</span><span class="p">),</span> <span class="mi">3</span><span class="p">)</span>


<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">300</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span>
    <span class="n">CatImgs</span><span class="p">(),</span>
    <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">),</span>
    <span class="s2">"/tmp/Test_Blob_Onnx.onnx"</span><span class="p">,</span>
    <span class="n">opset_version</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
    <span class="n">do_constant_folding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">from</span> <span class="nn">onnxsim</span> <span class="kn">import</span> <span class="n">simplify</span>

<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"/tmp/Test_Blob_Onnx.onnx"</span><span class="p">)</span>
<span class="n">model_simpified</span><span class="p">,</span> <span class="n">check</span> <span class="o">=</span> <span class="n">simplify</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
<span class="n">onnx</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model_simpified</span><span class="p">,</span> <span class="s2">"/tmp/Test_Blob_OnnxSim.onnx"</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">blobconverter</span>

<span class="n">blobconverter</span><span class="o">.</span><span class="n">from_onnx</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">"/tmp/Test_Blob_OnnxSim.onnx"</span><span class="p">,</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="s2">"/tmp/Test_Blob.blob"</span><span class="p">,</span>
    <span class="n">data_type</span><span class="o">=</span><span class="s2">"FP16"</span><span class="p">,</span>
    <span class="n">shaves</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
    <span class="n">use_cache</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">optimizer_params</span><span class="o">=</span><span class="p">[]</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Downloading /tmp/Test_Blob.blob/Test_Blob_OnnxSim_openvino_2021.4_6shave.blob...
[==================================================]
Done
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>PosixPath('/tmp/Test_Blob.blob/Test_Blob_OnnxSim_openvino_2021.4_6shave.blob')</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>ls -lh /tmp/MobileNet* <span class="p">&amp;</span> ls -lh /tmp/Test*
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>-rw-r--r-- 1 root root  283 Jan 20 14:22 /tmp/Test_Blob_Onnx.onnx
-rw-r--r-- 1 root root  285 Jan 20 14:22 /tmp/Test_Blob_OnnxSim.onnx
-rw-r--r-- 1 root root  21K Jan 20 14:22 /tmp/Test_QAT_iris.pt

/tmp/Test_Blob.blob:
-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.onnx
-rw-r--r-- 1 root root 3.6M Jan 20 14:20 /tmp/MobileNetV2_OnnxQuant.onnx
-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2_OnnxSim.onnx
-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.pt
-rw-r--r-- 1 root root  14M Jan 20 14:22 /tmp/MobileNetV2.tflite
-rw-r--r-- 1 root root 4.1M Jan 20 14:22 /tmp/MobileNet_V2_Torch_PTQ_Quant_S_EG.pt
-rw-r--r-- 1 root root 3.8M Jan 20 14:22 /tmp/MobileNet_V2_Torch_PTQ_Quant_S_FX.pt
-rw-r--r-- 1 root root  10M Jan 20 14:22 /tmp/MobileNet_V2_Torch_PTQ_Quant_W_EG.pt
-rw-r--r-- 1 root root 9.8M Jan 20 14:22 /tmp/MobileNet_V2_Torch_PTQ_Quant_W_FX.pt
-rw-r--r-- 1 root root 4.1M Jan 20 14:20 /tmp/MobileNetV2_TorchQATQuant.pt

/tmp/MobileNetV2.tf:
total 4.0K
-rw-r--r-- 1 root root 1.0K Jan 20 14:22 Test_Blob_OnnxSim_openvino_2021.4_6shave.blob
total 14M
drwxr-xr-x 2 root root 4.0K Jan 20 14:21 assets
-rw-r--r-- 1 root root  14M Jan 20 14:21 saved_model.pb
drwxr-xr-x 2 root root 4.0K Jan 20 14:21 variables
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>TODO</strong></p>
<ol>
<li>Fix Blob converter for MobileNet \</li>
<li>Fix Compile TFLite to EdgeTPU TFLite \</li>
</ol>

</div>
</div>
</div>
</div>



  </div><a class="u-url" href="/devblog/pytorch/dnn/2023/01/17/Quantize-DNN-Model-Pytorch.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/devblog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="https://deebuls.github.io/devblog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/devblog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Learning about learnings</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://github.com/deebuls" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/devblog/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://twitter.com/deebuls" target="_blank" title="twitter">
    <svg class="svg-icon grey">
      <use xlink:href="/devblog/assets/minima-social-icons.svg#twitter"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

</html>
