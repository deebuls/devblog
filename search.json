[
  {
    "objectID": "posts/notebooks/2023-06-16-fomo.html",
    "href": "posts/notebooks/2023-06-16-fomo.html",
    "title": "FOMO - Embedded Image Segmentation Pytorch Model",
    "section": "",
    "text": "Faster Objects More Objects aka FOMO\nPytorch implementation\nFOMO introduced by Edge Impulse is actually rebranded architecture callen bnn which was intially developed by Mat Palm and explained in the blog. The tensorflow code was made available in github.\nThe architecture diagram of FOMO/BNN is describe sa shown below :\nHere I try to convert the above diagram into a pytorch model. Hoep it helps anyone looking to deploy the FOMO model in real world."
  },
  {
    "objectID": "posts/notebooks/2023-06-16-fomo.html#model-description-as-per-mat-palm",
    "href": "posts/notebooks/2023-06-16-fomo.html#model-description-as-per-mat-palm",
    "title": "FOMO - Embedded Image Segmentation Pytorch Model",
    "section": "Model Description as per Mat Palm",
    "text": "Model Description as per Mat Palm\nthe model the architecture of the network is a very vanilla u-net.\n\na fully convolutional network trained on half resolution patches but run\n against full resolution images encoding is a sequence of 4 3x3 convolutions\n  with stride 2 decoding is a sequence of nearest neighbours resizes + 3x3\n  convolution (stride 1) + skip connection from the encoders final layer is a\n  1x1 convolution (stride 1) with sigmoid activation (i.e. binary bee / no bee\n   choice per pixel) after some emperical experiments i chose to only decode\n   back to half the resolution of the input. it was good enough.\n\ni did the decoding using a nearest neighbour resize instead of a deconvolution\npretty much out of habit.\n\nimport torch\nimport torch.nn as nn\n\n\n#ToDo Questions\n# how is the padding working should it be the paper is same but we are doing zero\n# upsampling what mode should it be\n\nclass FOMO(torch.nn.Module):\n    def __init__(self):\n        super(FOMO, self).__init__()\n\n        #Reduction\n        #3x3 conv stride 2  with 4 out channel\n        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=4, kernel_size=3, stride=2, padding=(1,1))\n        #3x3 conv stride 2 with 8 out channel\n        self.conv2 = torch.nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, stride=2, padding=(1,1))\n        #3x3 conv stride 2 with 16 out channel\n        self.conv3 = torch.nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=2, padding=(1,1))\n        #3x3 conv stride 2 with 32 out channel\n        self.conv4 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=(1,1))\n        #3x3 conv stride 1 with 16 out channel\n        self.conv5 = torch.nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding='same')\n\n        self.upsample = torch.nn.Upsample(scale_factor=2, mode='bilinear')\n\n        #Increasing\n        self.conv6 = torch.nn.Conv2d(in_channels=32, out_channels=8, kernel_size=3, stride=1, padding='same')\n        self.conv7 = torch.nn.Conv2d(in_channels=16, out_channels=4, kernel_size=3, stride=1, padding='same')\n        self.conv8 = torch.nn.Conv2d(in_channels=8, out_channels=1, kernel_size=1, stride=1, padding='same')\n\n\n\n\n\n    def forward(self, x):\n\n        #Downsample\n        out1 = self.conv1(x)\n        out2 = self.conv2(out1)\n        out3 = self.conv3(out2)\n\n        output = self.conv4(out3)\n\n        output = self.upsample(output)\n        output = self.conv5(output)\n        output = torch.concat(( output, out3), dim=1)\n        output = self.upsample(output)\n        output = self.conv6(output)\n        output = torch.concat(( output, out2), dim=1)\n        output = self.upsample(output)\n        output = self.conv7(output)\n        output = torch.concat(( output, out1), dim=1)\n        output = self.conv8(output)\n\n        return output\n\n\n\n\nmodel = FOMO()\nprint (model)\n\nFOMO(\n  (conv1): Conv2d(3, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n  (conv3): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n  (conv4): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n  (conv5): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n  (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n  (conv6): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n  (conv7): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=same)\n  (conv8): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1), padding=same)\n)\n\n\n\nx = torch.randn(1, 3, 512, 384)\ny = model(x)\nprint (y.shape)\n\ntorch.Size([1, 1, 256, 192])\n\n\n\n%timeit y=model(x)\n\n19.8 ms ± 2.77 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)"
  },
  {
    "objectID": "posts/notebooks/2023-06-16-fomo.html#todo-train-on-a-dataset",
    "href": "posts/notebooks/2023-06-16-fomo.html#todo-train-on-a-dataset",
    "title": "FOMO - Embedded Image Segmentation Pytorch Model",
    "section": "ToDo train on a dataset",
    "text": "ToDo train on a dataset"
  },
  {
    "objectID": "posts/notebooks/2023-03-01-derivative-loss-functions.html#linear-regression",
    "href": "posts/notebooks/2023-03-01-derivative-loss-functions.html#linear-regression",
    "title": "Derivative of different Deep Neural Networks loss functions",
    "section": "Linear Regression",
    "text": "Linear Regression\n\\[\n  \\begin{align*}\n  &\\text{Linear Equation}: &&z = Xw + b \\\\[1.5ex]\n  &\\text{Activation Function}: &&\\text{None} \\\\[1.5ex]\n  &\\text{Prediction}: &&\\hat{y} = z \\\\[0.5ex]\n  &\\text{Loss Function}: &&\\mathcal{L} = \\frac{1}{2}(\\hat{y} - y)^2\n  \\end{align*}\n\\]\nWe are interested in calculating the derivative of the loss with respect to (z). Throughout this post, we will do this by applying the chain rule: \\[\n\\frac{\\partial \\mathcal{L}}{\\partial z} = \\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} \\frac{\\partial \\hat{y}}{\\partial z}\n\\] First we will calculate the partial derivative of the loss with respect to our prediction: \\[\n\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} = \\hat{y} - y\n\\]\nNext, although silly, we calculate the partial derivative of our prediction with respect to the linear equation. Of course since the linear equation is our prediction (since we’re doing linear regression), the partial derivative is just 1: \\[\n\\frac{\\partial \\hat{y}}{\\partial z} = 1\n\\] When we combine them together, the derivative of the loss with respect to the linear equation is: \\[\n\\frac{\\partial \\mathcal{L}}{\\partial z} = \\hat{y} - y\n\\]"
  },
  {
    "objectID": "posts/notebooks/2023-03-01-derivative-loss-functions.html#logistic-regression-binary-cross-entropy-with-logits",
    "href": "posts/notebooks/2023-03-01-derivative-loss-functions.html#logistic-regression-binary-cross-entropy-with-logits",
    "title": "Derivative of different Deep Neural Networks loss functions",
    "section": "Logistic Regression / Binary cross entropy with logits",
    "text": "Logistic Regression / Binary cross entropy with logits\n\\[\n\\begin{align*}\n&\\text{Linear Equation}: &&z = Xw + b \\\\[0.5ex]\n&\\text{Activation Function}: &&\\sigma(z) = \\frac{1}{1 + e^{-z}} \\\\[0.5ex]\n&\\text{Prediction}: &&\\hat{y} = \\sigma(z) \\\\[1.5ex]\n&\\text{Loss Function}: &&\\mathcal{L} = -(y\\log\\hat{y} + (1-y)\\log(1-\\hat{y})) \\end{align*}\n\\]\nThe partial derivative of the loss with respect to our prediction is pretty simple to calculate:\n\\[\n\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} = -\\frac{y}{\\hat{y}} + \\frac{1-y}{1-\\hat{y}}\n\\]\nNext we will calculate the derivative of our prediction with respect to the linear equation. We can use a little algebra to move things around and get a nice expression for the derivative: \\[\n\\begin{align*}\n\\frac{\\partial \\hat{y}}{\\partial z} &= \\frac{\\partial}{\\partial z}\\left[\\frac{1}{1 + e^{-z}}\\right] \\\\[0.75ex] &= \\frac{e^{-z}}{(1 + e^{-z})^2} \\\\[0.75ex] &= \\frac{1 + e^{-z} - 1}{(1 + e^{-z})^2} \\\\[0.75ex] &= \\frac{1 + e^{-z}}{(1 + e^{-z})^2} - \\frac{1}{(1 + e^{-z})^2} \\\\[0.75ex] &= \\frac{1}{1 + e^{-z}} - \\frac{1}{(1 + e^{-z})^2} \\\\[0.75ex] &= \\frac{1}{1 + e^{-z}} \\left(1 - \\frac{1}{1 + e^{-z}}\\right) \\\\[0.75ex] &= \\hat{y}(1 - \\hat{y})\n\\end{align*}\n\\]\nIsn’t that awesome?! Anyways, enough of my love for math, let’s move on. Now we’ll combine the two partial derivatives to get our final expression for the derivative of the loss with respect to the linear equation.\n\\[\n\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial z} &= \\left(-\\frac{y}{\\hat{y}} + \\frac{1-y}{1-\\hat{y}}\\right)\\hat{y}(1 - \\hat{y}) \\\\[0.75ex] &= -\\frac{y}{\\hat{y}}\\hat{y}(1 - \\hat{y}) + \\frac{1-y}{1-\\hat{y}}\\hat{y}(1 - \\hat{y}) \\\\[0.75ex] &= -y(1 - \\hat{y}) + (1-y)\\hat{y} \\\\[0.75ex] &= -y + y\\hat{y} + \\hat{y} - y\\hat{y} \\\\[0.75ex] &= \\hat{y} - y \\end{align*}\n\\]"
  },
  {
    "objectID": "posts/notebooks/2023-03-01-derivative-loss-functions.html#softmax-nll",
    "href": "posts/notebooks/2023-03-01-derivative-loss-functions.html#softmax-nll",
    "title": "Derivative of different Deep Neural Networks loss functions",
    "section": "Softmax NLL",
    "text": "Softmax NLL\n[\\[\\begin{align*} &\\text{Linear Equation}: &&z = Xw + b \\\\[0.5ex] &\\text{Activation Function}: &&\\varphi(z_i) = \\frac{e^{z_i}}{\\sum_n e^{z_n}} \\\\[0.5ex] &\\text{Prediction}: &&\\hat{y_i} = \\varphi(z_i) \\\\[1.5ex] &\\text{Loss Function}: &&\\mathcal{L} = -\\sum_i y_i\\log\\hat{y_i} \\end{align*}\\]]\nLet’s calculate the first partial derivative of the loss with respect to our prediction: \\[\n\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y_i}} = -\\sum_i \\frac{y_i}{\\hat{y_i}}\n\\]\nThat was pretty easy! Now let’s tackle the monster… the partial derivative of our prediction with respect to the linear equation: \\[\n\\frac{\\partial \\hat{y_i}}{\\partial z_j} = \\frac{\\sum_n e^{z_n} \\frac{\\partial}{\\partial z_j}[e^{z_i}] - e^{z_i} \\frac{\\partial}{\\partial z_j}\\left[\\sum_n e^{z_n}\\right]}{\\left(\\sum_n e^{z_n}\\right)^2}\n\\]\nIt is important to realize that we need to break this down into two parts. The first is when \\(i = j\\) and the second is when \\(i \\neq j\\). \\[\nif (i = j):\n\\begin{align*}\n\\frac{\\partial \\hat{y_i}}{\\partial z_j} &= \\frac{e^{z_j}\\sum_n e^{z_n} - e^{z_j}e^{z_j}}{\\left(\\sum_n e^{z_n}\\right)^2} \\\\[0.75ex]\n&= \\frac{e^{z_j}\\sum_n e^{z_n}}{\\left(\\sum_n e^{z_n}\\right)^2} - \\frac{e^{z_j}e^{z_j}}{\\left(\\sum_n e^{z_n}\\right)^2} \\\\[0.75ex]\n&= \\frac{e^{z_j}}{\\sum_n e^{z_n}} - \\frac{e^{z_j}e^{z_j}}{\\left(\\sum_n e^{z_n}\\right)^2} \\\\[0.75ex]\n&= \\frac{e^{z_j}}{\\sum_n e^{z_n}} - \\frac{e^{z_j}}{\\sum_n e^{z_n}} \\frac{e^{z_j}}{\\sum_n e^{z_n}} \\\\[0.75ex]\n&= \\frac{e^{z_j}}{\\sum_n e^{z_n}} \\left(1 - \\frac{e^{z_j}}{\\sum_n e^{z_n}}\\right) \\\\[0.75ex] &= \\hat{y_j}(1 - \\hat{y_j}) \\end{align*}\n\\]\n\\[\nif (i \\neq j):\n\\begin{align*} \\frac{\\partial \\hat{y_i}}{\\partial z_j} &= \\frac{0 - e^{z_i}e^{z_j}}{\\left(\\sum_n e^{z_n}\\right)^2} \\\\[0.75ex] &= - \\frac{e^{z_i}}{\\sum_n e^{z_n}} \\frac{e^{z_j}}{\\sum_n e^{z_n}} \\\\[0.75ex] &= - \\hat{y_i}\\hat{y_j} \\end{align*}\n\\]\nWe can therefore combine them as follows: \\[\n\\frac{\\partial \\mathcal{L}}{\\partial z_j} = - \\hat{y_j}(1 - \\hat{y_j})\\frac{y_j}{\\hat{y_j}} - \\sum_{i \\neq j} \\frac{y_i}{\\hat{y_i}}(-\\hat{y}_i\\hat{y_j})\n\\]\nThe left side of the equation is where \\(i = j\\), while the right side is where \\(i \\neq j\\). You will notice that we can cancel out a few terms, so the equation now becomes: \\[\n\\frac{\\partial \\mathcal{L}}{\\partial z_j} = - y_j(1 - \\hat{y_j}) + \\sum_{i \\neq j} y_i\\hat{y_j}\n\\]\nThese next few steps trip some people out, so pay close attention. The first thing we’re going to do is change the subscript on the left side from \\(y_i\\) to \\(y_j\\) since \\(i = j\\) for that part of the equation: \\[\n\\frac{\\partial \\mathcal{L}}{\\partial z_j} = - y_j(1 - \\hat{y_j}) + \\sum_{i \\neq j} y_i\\hat{y_j}\n\\]\nNext, we are going to multiply out the left side of the equation to get:\n\\[\n\\frac{\\partial \\mathcal{L}}{\\partial z_j} = - y_j + y_j\\hat{y_j} + \\sum_{i \\neq j} y_i\\hat{y_j}\n\\]\nWe will then factor out \\(\\hat{y_j}\\) to get: \\[\n\\frac{\\partial \\mathcal{L}}{\\partial z_j} = - y_j + \\hat{y_j}\\left(y_j + \\sum_{i \\neq j} y_i\\right)\n\\]\nThis is where the magic happens. We realize that inside the bracket \\(y_j\\) can become \\(y_i\\) since it is from the left side of the equation. Since y is a one-hot encoded vector: \\(y_j + \\sum_{i \\neq j} y_i = 1\\)\nSo our final partial derivative equals: \\[\n\\frac{\\partial \\mathcal{L}}{\\partial z_j} = \\hat{y_j} - y_j = \\hat{y} - y\n\\]"
  },
  {
    "objectID": "posts/notebooks/2023-03-01-derivative-loss-functions.html#l2-loss-with-sigmoid",
    "href": "posts/notebooks/2023-03-01-derivative-loss-functions.html#l2-loss-with-sigmoid",
    "title": "Derivative of different Deep Neural Networks loss functions",
    "section": "L2 loss with sigmoid",
    "text": "L2 loss with sigmoid\n\\[\n\\begin{align*}\n&\\text{Linear Equation}: &&z = Xw + b \\\\[0.5ex]\n&\\text{Activation Function}: &&\\sigma(z) = \\frac{1}{1 + e^{-z}} \\\\[0.5ex]\n&\\text{Prediction}: &&\\hat{y} = \\sigma(z) \\\\[1.5ex]\n&\\text{Loss Function}: &&\\mathcal{L} = \\frac{1}{2}(\\hat{y} - y)^2 \\end{align*}\n\\]\nFirst we will calculate the partial derivative of the loss with respect to our prediction: \\[\n\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} = \\hat{y} - y\n\\]\nNext we will calculate the derivative of our prediction with respect to the linear equation. We can use a little algebra to move things around and get a nice expression for the derivative: \\[\n\\begin{align*}\n\\frac{\\partial \\hat{y}}{\\partial z} &= \\frac{\\partial}{\\partial z}\\left[\\frac{1}{1 + e^{-z}}\\right] \\\\[0.75ex]\n&= \\hat{y}(1 - \\hat{y})\n\\end{align*}\n\\]\nNow we’ll combine the two partial derivatives to get our final expression for the derivative of the loss with respect to the linear equation.\n\\[\n\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial z} &= \\left(\\hat{y} - y \\right) \\hat{y}(1 - \\hat{y}) \\\\[0.75ex]\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/notebooks/2023-03-01-derivative-loss-functions.html#sigmoid-bce",
    "href": "posts/notebooks/2023-03-01-derivative-loss-functions.html#sigmoid-bce",
    "title": "Derivative of different Deep Neural Networks loss functions",
    "section": "Sigmoid BCE",
    "text": "Sigmoid BCE\n\nsigmoid = 1 / (1 + sym.exp(-z))\nsigmoid\n\n1/(1 + exp(-z))\n\n\n\nloss = -(y * sym.log(y_hat) + (1 - y)*sym.log(1 - y_hat))\nloss\n\n-y*log(y_hat) - (1 - y)*log(1 - y_hat)\n\n\n\nsym.diff(loss, y_hat)\n\n-y/y_hat - (y - 1)/(1 - y_hat)\n\n\n\nsym.diff(sigmoid, z)\n\nexp(-z)/(1 + exp(-z))**2"
  },
  {
    "objectID": "posts/notebooks/2023-03-01-derivative-loss-functions.html#softmax",
    "href": "posts/notebooks/2023-03-01-derivative-loss-functions.html#softmax",
    "title": "Derivative of different Deep Neural Networks loss functions",
    "section": "Softmax",
    "text": "Softmax\n\nsoftmax = sym.exp(z)"
  },
  {
    "objectID": "posts/notebooks/2020-03-20-probability-likelihood.html",
    "href": "posts/notebooks/2020-03-20-probability-likelihood.html",
    "title": "Likelihood",
    "section": "",
    "text": "Likelihood and probablity seems to be same word in the layman domain, but in the stats domain they are different.\nIn the stats domain the likelihood or likelihood function is a measurement. It measures the distance between a statistical model and the input data.\nWhat is a statistical model? &gt; The diferent probability distributions available. For example, Gausian, gama, beta distribution, exponential for continuous data while Bernoulli, Dirichlet, multinomila distributions for discrete data.\nHow are statistical models represented? &gt; By their parameters. For example for gaussian distribution the parameters are \\(\\mu\\) and \\(\\sigma\\) .\nHow do we select the statictical model? &gt; Depends on many factors. This is the main decision to be made while designing a statistical model based learning. The different factors include: * what is the data type: Continuous or discrete? * Is it symmetrical or asymetrical? * Domain of the data, binary, real, etc * Does it decay or increase? * . . . etc\nA complete knowledge about the type data and the type of distribution is required to make the appropriate decision.\n\n\n\nhttps://www.kaggle.com/code/tentotheminus9/so-you-have-a-diagnostic-test-result/notebook\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Type\nDomain\nDistribution\nPython (numpy.random)\nParameters\n\n\n\n\nunivariate, discrete, binary\n\\[ x\\in\\{0,1\\} \\]\nBernoulli\nbinomial(1, p)\n\\[ p\\in[0,1]\\]\n\n\nunivariate, discrete,  multivalued\n\\[ x \\in \\{ 1,2, \\dots, K\\}\\]\nmultinomial\nmultinomial(n, pvals)\n\\[pvals = [p_1, \\dots , p_k] \\]  \\[ \\sum_{i=1}^{K} p_i = 1 \\]\n\n\nunivariate, continuous,  unbounded\n\\[ x \\in \\mathbb{R} \\]\nnormal\nnormal(mu, sigma)\n\\[ \\mu \\in \\mathbb{R} \\]  \\[ \\sigma \\in \\mathbb{R}\\]\n\n\n\n\n#Lets make some distributions and find the likelihood to some data\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnumber_of_samples = 20;\n#parameters ; sample data from distribution (continuous data)\nmu, sigma = 12, 0.1     ; univariate_gaussian_samples = np.random.normal(mu, sigma, number_of_samples)\nmean = [0, 0]; \ncov = [[1, 0], [0, 100]]; multivariate_gaussian_samples = np.random.multivariate_normal(mean, cov, number_of_samples)\n\n#parameters ; sample data from distribution (discreta data)\np = 0.8                 ; bernoulli_samples = np.random.binomial(1, p, number_of_samples)\npvals = [0.2, 0.6, 0.2] ; multinomial_samples = np.random.multinomial(number_of_samples, pvals)\nalpha, beta = 10, 20    ; beta_samples = np.random.beta(alpha, beta, number_of_samples)\nalpha = [10,20,10,90]   ; dirchilet_samples = np.random.dirichlet(alpha, number_of_samples)\n\n\n\n\nThe goal of likelihood would be given the samples as shown above (beta_samples, dirichlet_samples etc) find the parameters of the corresponding distribution ((alpha, beta), alphas respectively)\n\n\n#hide ### Bernoulli Distribution Let \\(x\\) be the count of data points with value 1 and \\(y\\) be the count of data points with value 0. \\[ Pr(x) = \\lambda^{x}(1 - \\lambda^{y}) \\]"
  },
  {
    "objectID": "posts/notebooks/2020-03-20-probability-likelihood.html#good-blog-on-likelihood-with-scipy.stats",
    "href": "posts/notebooks/2020-03-20-probability-likelihood.html#good-blog-on-likelihood-with-scipy.stats",
    "title": "Likelihood",
    "section": "",
    "text": "https://www.kaggle.com/code/tentotheminus9/so-you-have-a-diagnostic-test-result/notebook"
  },
  {
    "objectID": "posts/notebooks/2020-03-20-probability-likelihood.html#common-probability-distribution",
    "href": "posts/notebooks/2020-03-20-probability-likelihood.html#common-probability-distribution",
    "title": "Likelihood",
    "section": "",
    "text": "Data Type\nDomain\nDistribution\nPython (numpy.random)\nParameters\n\n\n\n\nunivariate, discrete, binary\n\\[ x\\in\\{0,1\\} \\]\nBernoulli\nbinomial(1, p)\n\\[ p\\in[0,1]\\]\n\n\nunivariate, discrete,  multivalued\n\\[ x \\in \\{ 1,2, \\dots, K\\}\\]\nmultinomial\nmultinomial(n, pvals)\n\\[pvals = [p_1, \\dots , p_k] \\]  \\[ \\sum_{i=1}^{K} p_i = 1 \\]\n\n\nunivariate, continuous,  unbounded\n\\[ x \\in \\mathbb{R} \\]\nnormal\nnormal(mu, sigma)\n\\[ \\mu \\in \\mathbb{R} \\]  \\[ \\sigma \\in \\mathbb{R}\\]\n\n\n\n\n#Lets make some distributions and find the likelihood to some data\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnumber_of_samples = 20;\n#parameters ; sample data from distribution (continuous data)\nmu, sigma = 12, 0.1     ; univariate_gaussian_samples = np.random.normal(mu, sigma, number_of_samples)\nmean = [0, 0]; \ncov = [[1, 0], [0, 100]]; multivariate_gaussian_samples = np.random.multivariate_normal(mean, cov, number_of_samples)\n\n#parameters ; sample data from distribution (discreta data)\np = 0.8                 ; bernoulli_samples = np.random.binomial(1, p, number_of_samples)\npvals = [0.2, 0.6, 0.2] ; multinomial_samples = np.random.multinomial(number_of_samples, pvals)\nalpha, beta = 10, 20    ; beta_samples = np.random.beta(alpha, beta, number_of_samples)\nalpha = [10,20,10,90]   ; dirchilet_samples = np.random.dirichlet(alpha, number_of_samples)"
  },
  {
    "objectID": "posts/notebooks/2020-03-20-probability-likelihood.html#goal-of-likelihood",
    "href": "posts/notebooks/2020-03-20-probability-likelihood.html#goal-of-likelihood",
    "title": "Likelihood",
    "section": "",
    "text": "The goal of likelihood would be given the samples as shown above (beta_samples, dirichlet_samples etc) find the parameters of the corresponding distribution ((alpha, beta), alphas respectively)\n\n\n#hide ### Bernoulli Distribution Let \\(x\\) be the count of data points with value 1 and \\(y\\) be the count of data points with value 0. \\[ Pr(x) = \\lambda^{x}(1 - \\lambda^{y}) \\]"
  },
  {
    "objectID": "posts/notebooks/2023-01-22-generalized-normal-distirbution-uncertainty-regression-ouliers.html#pytorch-loss-implementation",
    "href": "posts/notebooks/2023-01-22-generalized-normal-distirbution-uncertainty-regression-ouliers.html#pytorch-loss-implementation",
    "title": "Generalized Gaussian Distribution: Uncertainty Estimation for Regression with Outlier(Noisy) Labels",
    "section": "Pytorch loss implementation",
    "text": "Pytorch loss implementation\nBelow is the pytorch loss implementation of the Generalized Normal loss function.\n\nPDF of Generalized Normal Function\n\\[pdf = \\frac{\\beta e^{- \\left(\\frac{\\left|{diff}\\right|}{\\alpha}\\right)^{\\beta}}}{2 \\alpha \\Gamma\\left(\\frac{1}{\\beta}\\right)}\n\\]\n\n\nNegative Log Likelihood of the PDF\n\\[nll =  - log(pdf) \\] \\[nll = - \\log{\\left(\\frac{\\beta e^{- \\left(\\frac{\\left|{diff}\\right|}{\\alpha}\\right)^{\\beta}}}{2 \\alpha \\Gamma\\left(\\frac{1}{\\beta}\\right)} \\right)}\n\\]\nSimplifying it, we get the loss as\n\\[ loss = \\left(\\frac{\\left|{diff}\\right|}{\\alpha}\\right)^{\\beta} - \\log{\\left(\\beta \\right)} + \\log{\\left(2 \\alpha \\Gamma\\left(\\frac{1}{\\beta}\\right) \\right)}\n\\]\n\ndef GeneralGaussianNLLLoss(input, target, alpha, beta, eps=1e-06, reduction='none'): \n  \n  # Inputs and targets much have same shape\n  input = input.view(input.size(0), -1)\n  target = target.view(target.size(0), -1)\n  if input.size() != target.size():\n      raise ValueError(\"input and target must have same size\")\n\n  # Second dim of scale must match that of input or be equal to 1\n  alpha = alpha.view(input.size(0), -1)\n  if alpha.size(1) != input.size(1) and alpha.size(1) != 1:\n      raise ValueError(\"alpha is of incorrect size\")\n\n# Second dim of scale must match that of input or be equal to 1\n  beta = beta.view(input.size(0), -1)\n  if beta.size(1) != beta.size(1) and beta.size(1) != 1:\n      raise ValueError(\"beta is of incorrect size\")\n\n\n  # Check validity of reduction mode\n  if reduction != 'none' and reduction != 'mean' and reduction != 'sum':\n      raise ValueError(reduction + \" is not valid\")\n\n  # Entries of var must be non-negative\n  if torch.any(alpha &lt; 0):\n      raise ValueError(\"alpha has negative entry/entries\")\n  # Entries of var must be non-negative\n  if torch.any(beta &lt; 0):\n      raise ValueError(\"beta has negative entry/entries\")\n\n  # Clamp for stability\n  alpha = alpha.clone()\n  beta = beta.clone()\n  with torch.no_grad():\n      alpha.clamp_(min=eps)\n      beta.clamp_(min=eps)\n\n  # Calculate loss (without constant)\n  #loss = (torch.log(2*scale) + torch.abs(input - target) / scale).view(input.size(0), -1).sum(dim=1)\n  loss = (torch.abs(input - target)/alpha)**beta - torch.log(beta) + torch.log(2 * alpha ) + torch.lgamma(1/beta)\n\n\n  # Apply reduction\n  if reduction == 'mean':\n      return loss.mean()\n  elif reduction == 'sum':\n      return loss.sum()\n  else:\n      return loss"
  },
  {
    "objectID": "posts/notebooks/2023-01-22-generalized-normal-distirbution-uncertainty-regression-ouliers.html#toy-dataset-with-noise",
    "href": "posts/notebooks/2023-01-22-generalized-normal-distirbution-uncertainty-regression-ouliers.html#toy-dataset-with-noise",
    "title": "Generalized Gaussian Distribution: Uncertainty Estimation for Regression with Outlier(Noisy) Labels",
    "section": "Toy Dataset with Noise",
    "text": "Toy Dataset with Noise"
  },
  {
    "objectID": "posts/notebooks/2023-01-22-generalized-normal-distirbution-uncertainty-regression-ouliers.html#pytorch-model-for-training",
    "href": "posts/notebooks/2023-01-22-generalized-normal-distirbution-uncertainty-regression-ouliers.html#pytorch-model-for-training",
    "title": "Generalized Gaussian Distribution: Uncertainty Estimation for Regression with Outlier(Noisy) Labels",
    "section": "Pytorch Model for Training",
    "text": "Pytorch Model for Training\n\nFor MSE loss the output shape is 1\nFor Gaussian loss the output shape is 2. (output and variance)\nFor Generalized loss function the output shape is 3. (output, alpha, beta)\n\n\n# this is one way to define a network\nclass Net(torch.nn.Module):\n    def __init__(self, n_feature, n_hidden, n_output):\n        super(Net, self).__init__()\n        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n\n    def forward(self, x):\n        x = F.relu(self.hidden(x))      # activation function for hidden layer\n        x = self.predict(x)             # linear output\n        return x\n\n# this is one way to define a network\nclass GaussianNet(torch.nn.Module):\n    def __init__(self, n_feature, n_hidden, n_output):\n        super(GaussianNet, self).__init__()\n        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n        self.variance = torch.nn.Linear(n_hidden, 1)   # variance layer\n\n    def forward(self, x):\n        x = F.relu(self.hidden(x))      # activation function for hidden layer\n        out = self.predict(x)             # linear output\n        var = F.softplus(self.variance(x))\n\n        return out, var\n\nclass GeneralGaussianNet(torch.nn.Module):\n    def __init__(self, n_feature, n_hidden, n_output):\n        super(GeneralGaussianNet, self).__init__()\n        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n        self.alpha = torch.nn.Linear(n_hidden, 1)   # variance layer\n        self.beta = torch.nn.Linear(n_hidden, 1)   # variance layer\n        \n        #torch.nn.init.xavier_uniform_(self.variance.weight)\n        #torch.nn.init.normal_(self.variance.weight, mean=1.0)\n        #torch.nn.init.normal_(self.variance.bias, mean=0.0)\n\n    def forward(self, x):\n        x = F.relu(self.hidden(x))      # activation function for hidden layer\n        out = self.predict(x)             # linear output\n        alpha = F.softplus(self.alpha(x))\n        beta = F.softplus(self.beta(x))\n\n        return out, alpha, beta\n\n\nmse_loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n# Fit a linear regression using mean squared error.\nregression_mse = Net(n_feature=1, n_hidden=10, n_output=1)     # RegressionModel() \nparams_mse = regression_mse.parameters()\noptimizer_mse = torch.optim.Adam(params_mse, lr = 0.001) \n\n\ngaussian_loss_func = torch.nn.GaussianNLLLoss( reduction='none')\n# Fit a linear regression using mean squared error.\nregression_gaussian = GaussianNet(n_feature=1, n_hidden=10, n_output=1)     # RegressionModel() \nparams_gaussian = regression_gaussian.parameters()\noptimizer_gaussian = torch.optim.Adam(params_gaussian, lr = 0.001) \n\n\ngeneralized_loss_func = GeneralGaussianNLLLoss\n# Fit a linear regression using mean squared error.\nregression_generalized = GeneralGaussianNet(n_feature=1, n_hidden=10, n_output=1)     # RegressionModel() \nparams_generalized = regression_generalized.parameters()\noptimizer_generalized = torch.optim.Adam(params_generalized, lr = 0.001)"
  },
  {
    "objectID": "posts/notebooks/2023-01-22-generalized-normal-distirbution-uncertainty-regression-ouliers.html#training-and-output",
    "href": "posts/notebooks/2023-01-22-generalized-normal-distirbution-uncertainty-regression-ouliers.html#training-and-output",
    "title": "Generalized Gaussian Distribution: Uncertainty Estimation for Regression with Outlier(Noisy) Labels",
    "section": "Training and Output",
    "text": "Training and Output\nHere you can see:\n\nGeneralized Normal distribution has the best fit.\nNot only that the distribution has the best uncertainty estimation, avoiding the outliers.\nThe loss plot you can see, how the loss for normal and generalized the outliers are separated from the inlier data\n\n\n\ntensor(0.0331, grad_fn=&lt;MeanBackward0&gt;) tensor(-1.2061, grad_fn=&lt;MeanBackward0&gt;) tensor(-1.3674, grad_fn=&lt;MeanBackward0&gt;)"
  },
  {
    "objectID": "posts/notebooks/2023-01-22-generalized-normal-distirbution-uncertainty-regression-ouliers.html#appendix",
    "href": "posts/notebooks/2023-01-22-generalized-normal-distirbution-uncertainty-regression-ouliers.html#appendix",
    "title": "Generalized Gaussian Distribution: Uncertainty Estimation for Regression with Outlier(Noisy) Labels",
    "section": "Appendix",
    "text": "Appendix\n\nalpha, beta, diff = sym.symbols('alpha, beta, diff')\npdf =  ( beta / (2 * alpha * sym.gamma(1 / beta)) ) * sym.exp(-((sym.Abs(diff)/alpha)**beta))\nnll_pdf = -1* sym.log(pdf)\n\n\npdf\n\n\n\n\n\nprint_latex(pdf)\n\n\\frac{\\beta e^{- \\left(\\frac{\\left|{diff}\\right|}{\\alpha}\\right)^{\\beta}}}{2 \\alpha \\Gamma\\left(\\frac{1}{\\beta}\\right)}\n\n\n\nnll_pdf\n\n\n\n\n\nprint_latex(nll_pdf)\n\n- \\log{\\left(\\frac{\\beta e^{- \\left(\\frac{\\left|{diff}\\right|}{\\alpha}\\right)^{\\beta}}}{2 \\alpha \\Gamma\\left(\\frac{1}{\\beta}\\right)} \\right)}\n\n\n\nnll_pdf.simplify()\n\n\n\n\n\nnll_pdf.subs([(beta,0.5), (diff,0),(alpha, 1.0)])\n\n\n\n\n\nnll_pdf = 1 * (sym.Abs(diff)/alpha)**beta + sym.log(2 * alpha) * sym.log(sym.gamma(1 / beta)) - sym.log(beta)\nnll_pdf\n\n\n\n\n\nnll_pdf.subs([(beta,0.5), (diff,0),(alpha, 1.0)])\n\n\n\n\n\nprint_latex(nll_pdf)\n\n\\left(\\frac{\\left|{diff}\\right|}{\\alpha}\\right)^{\\beta} - \\log{\\left(\\beta \\right)} + \\log{\\left(2 \\alpha \\Gamma\\left(\\frac{1}{\\beta}\\right) \\right)}\n\n\n\\[ \\left(\\frac{\\left|{diff}\\right|}{\\alpha}\\right)^{\\beta} - \\log{\\left(\\beta \\right)} + \\log{\\left(2 \\alpha \\Gamma\\left(\\frac{1}{\\beta}\\right) \\right)}\n\\]\n\nalphas = [1.5, 2.0]\nbetas = [ 0.1, 0.5, 1.0, 2.0, 8.0]\n\nplot_exponential_power_distribution(alphas, betas, nll_pdf, plot_ylim=(0,3))\n\n\n\n\n\nGeneralized log loss function\n\nNoisy labels in classification can be addressed\n\nWith increaes in base the los reduces .\nWhen base is 1 the\n\n\nx_values, base = sym.symbols('x_value, base')\n\nnegative_log = -1*sym.log(x_values, base) - (1/base)\nxlim = 1e-21  \np1 = symplot.plot(negative_log.subs([(base, 2)]), (x_values,-1,1), show=False, line_color='darkgreen')\np1[0].label = ''\nfor i, b in enumerate([0.1, 1, 3, 5, 10]):\n    p = symplot.plot(negative_log.subs([(base, b)]), (x_values,-1,1), show=False, line_color=color[i%len(color)])\n    p1.append(p[0])\n\np1.show()\n\n\n\n\n\nnegative_log.subs([(base,1), (x_values,0)])"
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#power-analysis",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#power-analysis",
    "title": "Introduction To Statistical Testing",
    "section": "Power Analysis",
    "text": "Power Analysis\nReferences: [1] Guy Hoffman and Xuan Zhao. 2020. A Primer for Conducting Experiments in Human–Robot Interaction. J. Hum.-Robot Interact. 10, 1, Article 6 (March 2021), 31 pages. https://doi.org/10.1145/3412374"
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#multi-robot-grasp-planning-for-sequential-assembly-operations-dogar-et-al-2015",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#multi-robot-grasp-planning-for-sequential-assembly-operations-dogar-et-al-2015",
    "title": "Introduction To Statistical Testing",
    "section": "1. Multi-Robot Grasp Planning for Sequential Assembly Operations (Dogar et al 2015)",
    "text": "1. Multi-Robot Grasp Planning for Sequential Assembly Operations (Dogar et al 2015)\nIn this paper, the authors use multiple mobile manipulators to construct a flat-packed chair with or without re-grasps (i.e. putting down the piece and picking it up in a different way).\nThe hypothesis can be more or less expressed like this:\n\nOur algorithm calculates a good enough manipulation solution with few re-grasps faster than a naive algorithm can calculate the same problem optimally (i.e. with no re-grasps).\n\n\nBad Hypothesis\nFor the sake of demonstration, here is an example of what a less specific hypothesis might look like, one which does not define variables. It is completely unspecific as to what “quickly” means:\n\nOur algorithm can calculate a solution quickly.\n\nAnother problem might arise if the hypothesis does not include testability. For example, this hypothesis would not be testable, because you could never test all of the other algorithms:\n\nOur algorithm calculates a solution better than all of the other planning algorithms."
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#example-2-grasping-without-squeezing-shear-adhesion-gripper-with-fibrillar-thin-film-hawkes-et-al-2015",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#example-2-grasping-without-squeezing-shear-adhesion-gripper-with-fibrillar-thin-film-hawkes-et-al-2015",
    "title": "Introduction To Statistical Testing",
    "section": "Example 2: Grasping without Squeezing: Shear Adhesion Gripper with Fibrillar Thin Film (Hawkes et al 2015)",
    "text": "Example 2: Grasping without Squeezing: Shear Adhesion Gripper with Fibrillar Thin Film (Hawkes et al 2015)\nIt presents a new type of gripper which, as the authors explain, does not use normal forces to pick up objects as most robotic grippers do. Instead, the gripper uses shear forces which are applied to the manipulated object via a flexible film.\n\nIf a gripper uses shear adhesion forces then it will be a viable option for robotic grasping of objects with a large radius of curvature."
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#experiment-1-weight-gain",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#experiment-1-weight-gain",
    "title": "Introduction To Statistical Testing",
    "section": "Experiment 1 : Weight Gain",
    "text": "Experiment 1 : Weight Gain\n\nReferences:\n\nMoore, D. S., McCabe, G. P., and Craig, B. A. (2012). Introduction to the Practice of Statistics (7th ed.). New York: Freeman.\nLevine, J. A., Eberhardt, N. L., and Jensen, M. D. (1999) Role of nonexcercise activity thermogenesis in resistance to fat gain in humans. Science, 283:212-214.\n\n\n\nDescription:\n“Weight Gain”, provides weights of 16 participants before and after an eight-week period of excessive calorie intake (Moore et al., 2012, p. 425).\n\n\nHypothesis:\nWe will test the hypothesis that 1000 excess calorie intake per day over 8 weeks results in 16 pounds (approximately 7.2 kilograms) weight increase.\n\n\nVariables:\nWeight Before - Weight in pounds (lb) measured before eight weeks of excessive calorie intake.\nWeight After - Weight in pounds (lb) measured after eight weeks of excessive calorie intake.\nDifference - Weight After - Weight Before.\n\nweight_gain_data = pd.read_csv('https://raw.githubusercontent.com/jasp-stats/jasp-desktop/4527546659fdbd0849261f22ec84e9db76adc49d/Resources/Data%20Sets/Data%20Library/2.%20T-Tests/Weight%20Gain.csv')\nweight_gain_data.head()\n\n\n\n\n\n\n\n\nWeight Before\nWeight After\nDifference\n\n\n\n\n0\n122.54\n135.74\n13.20\n\n\n1\n120.78\n129.36\n8.58\n\n\n2\n131.12\n145.20\n14.08\n\n\n3\n137.06\n145.64\n8.58\n\n\n4\n163.24\n173.80\n10.56"
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#description-1",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#description-1",
    "title": "Introduction To Statistical Testing",
    "section": "Description:",
    "text": "Description:\n“Response to Eye Color”, provides post-advertisement attitudes towards a brand expressed by four different groups - each group saw the same advertisement except for the aspect that was manipulated: the eye-color of the model."
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#hypothesis-1",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#hypothesis-1",
    "title": "Introduction To Statistical Testing",
    "section": "Hypothesis:",
    "text": "Hypothesis:\nThe null hypothesis that the attitudes are the same regardless of the eye-color of the model"
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#variables-1",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#variables-1",
    "title": "Introduction To Statistical Testing",
    "section": "Variables:",
    "text": "Variables:\nGroup - Experimental conditions (`Blue' = Model with blue eyes, `Brown' = Model with brown eyes, `Green'= Model with green eyes, `Down' = Model's eye color cannot be seen).\nSubj - Participant number.\nScore - An average of 10 survey questions about attitudes towards the brand (7-point Likert scale). Higher averages correspond to more positive attitudes."
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#data",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#data",
    "title": "Introduction To Statistical Testing",
    "section": "Data",
    "text": "Data\n\neye_color_data = pd.read_csv('https://raw.githubusercontent.com/jasp-stats/jasp-desktop/4527546659fdbd0849261f22ec84e9db76adc49d/Resources/Data%20Sets/Data%20Library/3.%20ANOVA/Response%20to%20Eye%20Color.csv')\neye_color_data.head()\n\n\n\n\n\n\n\n\nGroup\nSubj\nScore\n\n\n\n\n0\nBlue\n1\n1.3\n\n\n1\nBlue\n2\n1.0\n\n\n2\nBlue\n3\n7.0\n\n\n3\nBlue\n4\n4.2\n\n\n4\nBlue\n5\n5.4"
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#references-1",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#references-1",
    "title": "Introduction To Statistical Testing",
    "section": "References:",
    "text": "References:\nMoore, D. S., McCabe, G. P., and Craig, B. A. (2012). Introduction to the Practice of Statistics (7th ed.). New York: Freeman.\nSimpson, P. M., Sturges, D. L., and Tanguma, J. (2008). The eyes have it, or do they? The effects of model eye color and eye gaze on consumer as response. The Journal of Applied Business and Economics, 8: 60-72."
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#reference",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#reference",
    "title": "Introduction To Statistical Testing",
    "section": "Reference",
    "text": "Reference\nWillerman L, Schultz R, Rutledge JN, Bigler ED. In vivo brain size and intelligence. Intelligence. 1991 Apr 1;15(2):223-8."
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#description-2",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#description-2",
    "title": "Introduction To Statistical Testing",
    "section": "Description",
    "text": "Description\nIn this study by Willerman et al. (1991) the researchers use Magnetic Resonance Imaging (MRI) to determine the brain size of the subjects. The researchers take into account gender and body size to draw conclusions about the connection between brain size and intelligence."
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#hypothesis-2",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#hypothesis-2",
    "title": "Introduction To Statistical Testing",
    "section": "Hypothesis",
    "text": "Hypothesis\nAre the size and weight of your brain indicators of your mental capacity?"
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#variable-names",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#variable-names",
    "title": "Introduction To Statistical Testing",
    "section": "Variable Names:",
    "text": "Variable Names:\n\nGender: Male or Female\nFSIQ: Full Scale IQ scores based on the four Wechsler (1981) subtests\nVIQ: Verbal IQ scores based on the four Wechsler (1981) subtests\nPIQ: Performance IQ scores based on the four Wechsler (1981) subtests\nWeight: body weight in pounds\nHeight: height in inches\nMRI_Count: total pixel Count from the 18 MRI scans\n\n\nbrain_data = pd.read_csv('https://scipy-lectures.org/_downloads/brain_size.csv', sep=';', na_values=\".\")\nbrain_data.head()\n\n\n\n\n\n\n\n\nUnnamed: 0\nGender\nFSIQ\nVIQ\nPIQ\nWeight\nHeight\nMRI_Count\n\n\n\n\n0\n1\nFemale\n133\n132\n124\n118.0\n64.5\n816932\n\n\n1\n2\nMale\n140\n150\n124\nNaN\n72.5\n1001121\n\n\n2\n3\nMale\n139\n123\n150\n143.0\n73.3\n1038437\n\n\n3\n4\nMale\n133\n129\n128\n172.0\n68.8\n965353\n\n\n4\n5\nFemale\n137\n132\n134\n147.0\n65.0\n951545\n\n\n\n\n\n\n\n# Statistical Testing"
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#plotting",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#plotting",
    "title": "Introduction To Statistical Testing",
    "section": "Plotting",
    "text": "Plotting\n\nTry plotting the data to get a complete picture\n\n\nMatejka, J., & Fitzmaurice, G.W. (2017). Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing. Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems."
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#a-typical-situation",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#a-typical-situation",
    "title": "Introduction To Statistical Testing",
    "section": "A typical situation:",
    "text": "A typical situation:\n\nExisting technique A\nYou developed a new technique B\nKey question: Is B better than A?"
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#define-a-performance-measure-e.g.",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#define-a-performance-measure-e.g.",
    "title": "Introduction To Statistical Testing",
    "section": "1. Define a performance measure, e.g.",
    "text": "1. Define a performance measure, e.g.\n\nRun-time\nError\nAccuracy\nRobustness (success rate, MTBF, …)"
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#collect-data-d",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#collect-data-d",
    "title": "Introduction To Statistical Testing",
    "section": "2. Collect data d",
    "text": "2. Collect data d\n\nRun both techniques on the data d\nHow to compare the obtained results \\(A(d), B(d)\\)?"
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#scenario",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#scenario",
    "title": "Introduction To Statistical Testing",
    "section": "Scenario",
    "text": "Scenario\n\nA, B are two HRI techniques\nScore is the audience response time\nData d is a given map, start and goal pose"
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#example",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#example",
    "title": "Introduction To Statistical Testing",
    "section": "Example",
    "text": "Example\n\nA(d) = 0.5 s\nB(d) = 0.6 s What does that mean?"
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#example-1",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#example-1",
    "title": "Introduction To Statistical Testing",
    "section": "Example",
    "text": "Example\n\nA(d) = 0.5 s, 0.4 s, 0.6 s, 0.4 s\nB(d) = 0.4 s, 0.3 s, 0.6 s, 0.5 s"
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#mean-of-the-planning-time-is",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#mean-of-the-planning-time-is",
    "title": "Introduction To Statistical Testing",
    "section": "Mean of the planning time is",
    "text": "Mean of the planning time is\n\n\\(μ_A\\) = 1.9 s/4 = 0.475 s\n\\(μ_B\\) = 1.8 s/4 = 0.45 s\n\nIs B really better than A?"
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#one-sample-location-test",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#one-sample-location-test",
    "title": "Introduction To Statistical Testing",
    "section": "One sample location test",
    "text": "One sample location test\nResearch is normally carried out in sample populations, but how close does the sample reflect the whole population? The parametric one-sample t-test determines whether the sample mean is statistically different from a known or hypothesized population mean. The null hypothesis (Ho) tested is that the sample mean is equal to the population mean.\n\nGiven a µ and σ of a population\nTest if a sample (from the population) has a significantly different mean than the population\nSample of size N\n\n\\[ H_0 : \\mu = K \\] $ H_1 : K $ (two-tailored test )\n$ H_1 : &lt; K $ (one-tailored test )\n$ H_1 : &gt; K $ (one-tailored test )"
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#sample-t-test-testing-the-value-of-a-population-mean",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#sample-t-test-testing-the-value-of-a-population-mean",
    "title": "Introduction To Statistical Testing",
    "section": "1-sample t-test: testing the value of a population mean",
    "text": "1-sample t-test: testing the value of a population mean\nscipy.stats.ttest_1samp() tests if the population mean of data is likely to be equal to a given value (technically if observations are drawn from a Gaussian distributions of given population mean). It returns the T statistic, and the p-value (see the function’s help):\n\nfrom scipy import stats\nstats.ttest_1samp(brain_data['VIQ'], 0)   \n\nTtestResult(statistic=30.08809997084933, pvalue=1.3289196468727879e-28, df=39)\n\n\n\nReporting/Conclusion\nWith a p-value of 10^-28 we can claim that the population mean for the IQ (VIQ measure) is not 0."
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#comments",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#comments",
    "title": "Introduction To Statistical Testing",
    "section": "Comments",
    "text": "Comments\n\nThe t-Test is quite robust under non-Gaussian distributions\nOften a 95% or 99% confidence (=5% or 1% significance) level is used\nt-Test is one of the most frequently used tests in science"
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#assumptions",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#assumptions",
    "title": "Introduction To Statistical Testing",
    "section": "ASSUMPTIONS",
    "text": "ASSUMPTIONS\nThree assumptions are required for a binomial test to provide a valid result: * The test variable should be a dichotomous scale (such as yes/no, male/female etc.). * The sample responses should be independent * The sample size is less, but representative of the population"
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#sample-t-test-testing-for-difference-across-populations",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#sample-t-test-testing-for-difference-across-populations",
    "title": "Introduction To Statistical Testing",
    "section": "2-sample t-test: testing for difference across populations",
    "text": "2-sample t-test: testing for difference across populations\nWe have seen above that the mean VIQ in the male and female populations were different. To test if this is significant, we do a 2-sample t-test with scipy.stats.ttest_ind():\n\nfemale_viq = brain_data[brain_data['Gender'] == 'Female']['VIQ']\n\nmale_viq = brain_data[brain_data['Gender'] == 'Male']['VIQ']\n\nstats.ttest_ind(female_viq, male_viq)  \n\nTtest_indResult(statistic=-0.7726161723275012, pvalue=0.44452876778583217)"
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#paired-tests-repeated-measurements-on-the-same-individuals",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#paired-tests-repeated-measurements-on-the-same-individuals",
    "title": "Introduction To Statistical Testing",
    "section": "Paired tests: repeated measurements on the same individuals",
    "text": "Paired tests: repeated measurements on the same individuals\nPIQ, VIQ, and FSIQ give 3 measures of IQ. Let us test if FISQ and PIQ are significantly different. We can use a 2 sample test:\n\nstats.ttest_ind(brain_data['FSIQ'], brain_data['PIQ'])   \n\nTtest_indResult(statistic=0.465637596380964, pvalue=0.6427725009414841)\n\n\nThe problem with this approach is that it forgets that there are links between observations: FSIQ and PIQ are measured on the same individuals. Thus the variance due to inter-subject variability is confounding, and can be removed, using a “paired test”, or “repeated measures test”:\n\nstats.ttest_rel(brain_data['FSIQ'], brain_data['PIQ'])   \n\nTtestResult(statistic=1.7842019405859857, pvalue=0.08217263818364236, df=39)"
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#assumptions-1",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#assumptions-1",
    "title": "Introduction To Statistical Testing",
    "section": "ASSUMPTIONS",
    "text": "ASSUMPTIONS\nThe independent ANOVA makes the same assumptions as most other parametric tests. * The independent variable must be categorical and the dependent variable must be continuous. * The groups should be independent of each other. * The dependent variable should be approximately normally distributed. * There should be no significant outliers. * There should be homogeneity of variance between the groups otherwise the p-value for the F-statistic may not be reliable.\n\nThe first 2 assumptions are usually controlled through the use of appropriate research method design.\nIf the last three assumptions are violated then the non-parametric equivalent, Kruskal-Wallis should be considered instead.\n\nData : ANOVA diets.csv. * This contains A column containing the 3 diets used (A, B and C) * another column containing the absolute amount of weight loss after 8 weeks on one of 3 differentdiets. * For good practice check the descriptive statistics and the boxplots for any extreme outliers\n\ndiet_loss_data = pd.read_csv('Independent ANOVA diets.csv')\ndiet_loss_data\n\n\n\n\n\n\n\n\nDiet\nWeight loss kg\n\n\n\n\n0\nDiet A\n3.8\n\n\n1\nDiet A\n6.0\n\n\n2\nDiet A\n0.7\n\n\n3\nDiet A\n2.9\n\n\n4\nDiet A\n2.8\n\n\n...\n...\n...\n\n\n67\nDiet C\n2.8\n\n\n68\nDiet C\n4.1\n\n\n69\nDiet C\n5.3\n\n\n70\nDiet C\n9.2\n\n\n71\nDiet C\n6.1\n\n\n\n\n72 rows × 2 columns\n\n\n\n\nsns.boxplot(data=diet_loss_data, x='Diet', y='Weight loss kg')\n\n&lt;AxesSubplot:xlabel='Diet', ylabel='Weight loss kg'&gt;\n\n\n\n\n\n\nstats.f_oneway(diet_loss_data[diet_loss_data['Diet'] == 'Diet A']['Weight loss kg'],\n               diet_loss_data[diet_loss_data['Diet'] == 'Diet B']['Weight loss kg'],\n               diet_loss_data[diet_loss_data['Diet'] == 'Diet C']['Weight loss kg'])\n\nF_onewayResult(statistic=10.825519115627964, pvalue=8.145779232433143e-05)"
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#step-1-type-of-test",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#step-1-type-of-test",
    "title": "Introduction To Statistical Testing",
    "section": "Step 1 : Type of test",
    "text": "Step 1 : Type of test\n\nComparing one sample to a known or hypothesized population mean.\nTesting relationships between two or more variables\nPredicting outcomes\nTesting for differences between two independent groups\nTesting for differences between two related groups\nTesting for differences between three or more independent groups\nTesting for differences between three or more related groups\nTest for interactions between 2 or more independent variables\n…"
  },
  {
    "objectID": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#find-the-statistical-test",
    "href": "posts/notebooks/2023-06-15-Intro-To-Statistial-Testing.html#find-the-statistical-test",
    "title": "Introduction To Statistical Testing",
    "section": "Find the statistical test ?",
    "text": "Find the statistical test ?\n\nExperiment 1 : Weight Gain ?\nExperiment 2 : Response to eqye color\nExperiment 3: Brain size Inteligence"
  },
  {
    "objectID": "posts/notebooks/2022-12-19-dirichlet-disentanglement-epistemic-aleatoric-evidential.html#how-to-separate-epistemic-and-aleatoric-uncertaity-of-dirichlet-distirbution",
    "href": "posts/notebooks/2022-12-19-dirichlet-disentanglement-epistemic-aleatoric-evidential.html#how-to-separate-epistemic-and-aleatoric-uncertaity-of-dirichlet-distirbution",
    "title": "Dis-entaglement of Epistemic and Aleatoric uncertainty for Dirichlet Distribution",
    "section": "How to separate epistemic and aleatoric uncertaity of Dirichlet distirbution",
    "text": "How to separate epistemic and aleatoric uncertaity of Dirichlet distirbution\nAlso studing the implications of it and proposing the applications of the solutions.\n\nFormula for [1] .\ntheory in [2]\n\nToDo : complete the section with info\n[1] Separation of Aleatoric and Epistemic Uncertainty in Deterministic Deep Neural Networks Denis Huseljic, Bernhard Sick, Marek Herde, Daniel Kottke\n[2] Deep Deterministic Uncertainty: A Simple Baseline Jishnu Mukhoti\n\nimport math \nimport numpy as np\nimport torch\n\n\nprior = 1\nn_classes = 5\ndef predict_epistemic( alpha):\n    \"\"\"Predicts the uncertainty of a sample. (K / alpha_0)\"\"\"\n    return n_classes * prior / alpha.sum(-1, keepdim=True)\n\ndef predict_aleatoric( alpha):\n    \"\"\"Predicts the uncertainty of a sample. (K / alpha_0)\"\"\"\n   \n    proba_in = (alpha / alpha.sum(-1, keepdim=True)).clamp_(1e-8, 1-1e-8)\n    entropy = - torch.sum((proba_in * proba_in.log()), dim=-1)\n    normalized_entropy = entropy / np.log(n_classes)\n    return normalized_entropy\n\n\nones = torch.ones(n_classes)\nprint (predict_epistemic(ones), predict_aleatoric(ones))\n\ntensor([1.]) tensor(1.)"
  },
  {
    "objectID": "posts/notebooks/2022-12-19-dirichlet-disentanglement-epistemic-aleatoric-evidential.html#when-alpha-of-only-a-single-class-keeps-increasing",
    "href": "posts/notebooks/2022-12-19-dirichlet-disentanglement-epistemic-aleatoric-evidential.html#when-alpha-of-only-a-single-class-keeps-increasing",
    "title": "Dis-entaglement of Epistemic and Aleatoric uncertainty for Dirichlet Distribution",
    "section": "When alpha of only a single class keeps increasing",
    "text": "When alpha of only a single class keeps increasing\n\nObservation : Both uncertainty reduces\nImpact : When the model puts all confidence(alpha) on a single class it shows that the model is confident about the class and uncertainty reduces.\nThe maximum aleatoric and epistemic uncertitny is both 1.0\nEpistemic is always lower than Aleatoric\n\n\nfor i in [1, 10, 50, 1000 ]:\n  x = torch.ones(n_classes)\n  x[0] = i\n  print (x)\n  print (\"Epistemic UE : {}, Aleatoric UE : {}\".format(predict_epistemic(x),  predict_aleatoric(x)))\n  print (\"------------\",predict_epistemic(x) &gt; predict_aleatoric(x))\n\ntensor([1., 1., 1., 1., 1.])\nEpistemic UE : tensor([1.]), Aleatoric UE : 1.0\n------------ tensor([False])\ntensor([10.,  1.,  1.,  1.,  1.])\nEpistemic UE : tensor([0.3571]), Aleatoric UE : 0.6178266406059265\n------------ tensor([False])\ntensor([50.,  1.,  1.,  1.,  1.])\nEpistemic UE : tensor([0.0926]), Aleatoric UE : 0.2278686910867691\n------------ tensor([False])\ntensor([1000.,    1.,    1.,    1.,    1.])\nEpistemic UE : tensor([0.0050]), Aleatoric UE : 0.019580082967877388\n------------ tensor([False])"
  },
  {
    "objectID": "posts/notebooks/2022-12-19-dirichlet-disentanglement-epistemic-aleatoric-evidential.html#when-alpha-of-multiple-classes-keeps-increasing",
    "href": "posts/notebooks/2022-12-19-dirichlet-disentanglement-epistemic-aleatoric-evidential.html#when-alpha-of-multiple-classes-keeps-increasing",
    "title": "Dis-entaglement of Epistemic and Aleatoric uncertainty for Dirichlet Distribution",
    "section": "When alpha of multiple classes keeps increasing",
    "text": "When alpha of multiple classes keeps increasing\n\nObservation : Epistemic reduces aleatoric is high\n\nImpact : When the model puts all confidence(alpha) on multiple classes basically suggests that the model is not confident. While since some alpha has increased it suggests that the input is an observed data(not new) and therefore low aleatoric uncertainty\n\nThe maximum aleatoric and epistemic uncertainty is both 1\n\nfor i in [1, 10, 50, 10000 ]:\n  x = torch.ones(n_classes)*i\n  print (x)\n  print (\"Epistemic UE : {}, Aleatoric UE : {}\".format(predict_epistemic(x),  predict_aleatoric(x)))\n  print (\"------------\",)\n\ntensor([1., 1., 1., 1., 1.])\nEpistemic UE : tensor([1.]), Aleatoric UE : 1.0\n------------\ntensor([10., 10., 10., 10., 10.])\nEpistemic UE : tensor([0.1000]), Aleatoric UE : 1.0\n------------\ntensor([50., 50., 50., 50., 50.])\nEpistemic UE : tensor([0.0200]), Aleatoric UE : 1.0\n------------\ntensor([10000., 10000., 10000., 10000., 10000.])\nEpistemic UE : tensor([1.0000e-04]), Aleatoric UE : 1.0\n------------"
  },
  {
    "objectID": "posts/notebooks/2022-12-19-dirichlet-disentanglement-epistemic-aleatoric-evidential.html#impact-of-prior",
    "href": "posts/notebooks/2022-12-19-dirichlet-disentanglement-epistemic-aleatoric-evidential.html#impact-of-prior",
    "title": "Dis-entaglement of Epistemic and Aleatoric uncertainty for Dirichlet Distribution",
    "section": "Impact of prior",
    "text": "Impact of prior\nprior = 50\nThe highest epistmeic uncertainty increases from 1 to the prior value"
  },
  {
    "objectID": "posts/notebooks/2022-12-19-dirichlet-disentanglement-epistemic-aleatoric-evidential.html#conclusions",
    "href": "posts/notebooks/2022-12-19-dirichlet-disentanglement-epistemic-aleatoric-evidential.html#conclusions",
    "title": "Dis-entaglement of Epistemic and Aleatoric uncertainty for Dirichlet Distribution",
    "section": "Conclusions",
    "text": "Conclusions\n\nDirichlet distirbution can be dis-entagled into aleatoric and epistemic uncertainty.\nWhen all alpha is 1 - both uncertainty are also 1 impling that the network doesnt know anything\nIf only one output class alpha is higher then both uncertainty is low\nThe higher the alpha the lower both the uncertainty\nIf multiple alpha is higher then only aleatoric is high epistemic stays low. Impling that since the some alpha was increased the network has seen the input and its not sure which amongst the outputs is correct.\n\n\nUse Case\n\n1. For identifying OOD data\n\nFor the training dataset measure the epistemic uncertainty of the correct predictions. It should be less than 1 and near to zero\nDuring prediction if epistemic uncertainty is higher than the training max then that data should be considered OOD and handled appropriately\n\n\n\n2. For handling in-domain uncertain data\n\nIf the epistemic unertainty is is range but if the aleatoric is high we can use these in embodied situation to collect additional data(image) from different view, fuse and make decision. Example if blur image - then differ to predict but dont flag as OOD, maybe in next image the information will be clear."
  },
  {
    "objectID": "posts/notebooks/2023-02-14-cauchy-distribution-boxcox-gaussian.html#using-boxcox-transformation",
    "href": "posts/notebooks/2023-02-14-cauchy-distribution-boxcox-gaussian.html#using-boxcox-transformation",
    "title": "Approximating Cauchy with Gaussian: Boxcox transformation",
    "section": "Using Boxcox transformation",
    "text": "Using Boxcox transformation\n\nPlot the wikipedia cauchy distribution\nUse boxcox and convert data to corresponding gaussian distribution\nBoxcox requires data to be positive so we use an alternative method yeojohnson. Unlike boxcox, yeojohnson does not require the input data to be positive.\n\nFor an application in uncertainty quantification we wanted to compare a Gaussian distribution with a Cauchy distribution."
  },
  {
    "objectID": "posts/notebooks/2023-02-14-cauchy-distribution-boxcox-gaussian.html#solution",
    "href": "posts/notebooks/2023-02-14-cauchy-distribution-boxcox-gaussian.html#solution",
    "title": "Approximating Cauchy with Gaussian: Boxcox transformation",
    "section": "Solution",
    "text": "Solution\n\ntransform the cauchy distribution data to gaussian distirbuted data\nget the 95% conditional intervals\ntransform the conditional intervals back to the cauchy data space."
  },
  {
    "objectID": "posts/notebooks/2023-02-14-cauchy-distribution-boxcox-gaussian.html#conclusion",
    "href": "posts/notebooks/2023-02-14-cauchy-distribution-boxcox-gaussian.html#conclusion",
    "title": "Approximating Cauchy with Gaussian: Boxcox transformation",
    "section": "Conclusion",
    "text": "Conclusion\n\nIts transformation using the data and estimating the loc with boxcox (power transformations) to gaussian and back is not good for long tailed distirbutions like cauchy.\nI am not sure what is wrong in the method below. Do message me in github if you find a way to do it.\n\nI written another blog on how to compare cauchy and gaussian using interval score .\n\nimport scipy.stats as stats\nimport numpy as np\nfrom scipy.stats import cauchy\nimport matplotlib.pyplot as plt\nimport seaborn as sns"
  },
  {
    "objectID": "posts/notebooks/2023-02-14-cauchy-distribution-boxcox-gaussian.html#create-3-cacuhy-distirbution-with-mean-10-and-scale-0.5-1-2",
    "href": "posts/notebooks/2023-02-14-cauchy-distribution-boxcox-gaussian.html#create-3-cacuhy-distirbution-with-mean-10-and-scale-0.5-1-2",
    "title": "Approximating Cauchy with Gaussian: Boxcox transformation",
    "section": "Create 3 Cacuhy distirbution with mean 10 and scale 0.5, 1, 2",
    "text": "Create 3 Cacuhy distirbution with mean 10 and scale 0.5, 1, 2\n\nloc = 10\nrv_1 = cauchy(loc=loc, scale=0.1)\nrv_2 = cauchy(loc=loc, scale=0.01)\nrv_half = cauchy(loc=loc, scale=0.001)\n\n\nx= np.linspace(rv_1.ppf(0.1), rv_1.ppf(0.9),  100)\n\n\nfig, ax = plt.subplots(1,1,figsize=(9,9))\nax.plot(x, rv_half.pdf(x), c='r', label='0.5')\nax.plot(x, rv_1.pdf(x), c='g', label= '1')\nax.plot(x, rv_2.pdf(x), c='b', label= '2')\nax.legend()\n\n&lt;matplotlib.legend.Legend at 0x7fe00ddd0ac0&gt;\n\n\n\n\n\n\nProbplot against cauchy distribution\n\nfig, ax = plt.subplots(2,3, figsize=(15,5))\n#Plot 1 = Histogram\n#g1 = sns.histplot(data=df, x='Price_in_thousands', ax=g[0]);\n\nfor index, rv in enumerate([rv_half, rv_1, rv_2]):\n    x = rv.rvs(1000)\n    prob = stats.probplot(x, dist=stats.cauchy, plot=ax[0][index])\n    ax[0][index].set_xlabel('')\n    g1 = sns.histplot(data=x, ax=ax[1][index]);\n\n\n\n\n\n\nProbplot against normal distribution\nHere we take the same cauchy samples but pass through the probplot with distribution set to Normal.\n\nfig, ax = plt.subplots(1,3, figsize=(15,5))\nfor index, rv in enumerate([rv_half, rv_1, rv_2]):\n    x = rv.rvs(1000)\n    prob = stats.probplot(x, dist=stats.norm, plot=ax[index])\n    ax[index].set_xlabel('')\n\n\n\n\n\n## Boxcox conversion"
  },
  {
    "objectID": "posts/notebooks/2023-02-14-cauchy-distribution-boxcox-gaussian.html#boxcox-conversion",
    "href": "posts/notebooks/2023-02-14-cauchy-distribution-boxcox-gaussian.html#boxcox-conversion",
    "title": "Approximating Cauchy with Gaussian: Boxcox transformation",
    "section": "Boxcox conversion",
    "text": "Boxcox conversion\nBoxcox requires data to be positive so we use an alternative method yeojohnson. Unlike boxcox, yeojohnson does not require the input data to be positive.\nBelow plot 1. Row 1 is probability plot with cauchy distribution and cauchy data 2. Row 2 is probability ploy with gaussian distribution and cauchy data 3. Row 3 is probability plot with gaussian distirbution but transformed cauchy data\nThe likelihood we expected the method to give the maximum at the generated loc = 10  .\nAs you can see in the outputs the estimated loc are\n\n\n\ntrue loc\ntrue scale\nestimated loc\n\n\n\n\n10\n0.5\n4.79\n\n\n10\n1.0\n1.64\n\n\n10\n1.5\n1.90\n\n\n\nAs you can see the method i\n\nfig, ax = plt.subplots(3,3, figsize=(15,15))\nfor index, rv in enumerate([rv_half, rv_1, rv_2]):\n    x = rv.rvs(1000)\n\n    prob = stats.probplot(x, dist=stats.cauchy, plot=ax[0][index])\n    prob = stats.probplot(x, dist=stats.norm, plot=ax[1][index])\n    xt, lmax_mle = stats.yeojohnson(x)\n    print (\"Max likelihod yeojohnson loc {} scale {} transformed loc {}\".format(loc, (index+1)/2, lmax_mle))\n\n    lmax_pearsonr = stats.yeojohnson_normmax(x)\n    print (\"Max likelihod yeojohnson pearsonrloc {} scale {} transformed loc {}\".format(loc, (index+1)/2, lmax_pearsonr))\n\n    prob = stats.probplot(xt, dist=stats.norm, plot=ax[2][index])\n\nMax likelihod yeojohnson loc 10 scale 0.5 transformed loc 62.755818121919134\nMax likelihod yeojohnson pearsonrloc 10 scale 0.5 transformed loc 62.755818121919134\nMax likelihod yeojohnson loc 10 scale 1.0 transformed loc 1.6403900928787156\nMax likelihod yeojohnson pearsonrloc 10 scale 1.0 transformed loc 1.6403900928787156\nMax likelihod yeojohnson loc 10 scale 1.5 transformed loc 3.064545766521091\nMax likelihod yeojohnson pearsonrloc 10 scale 1.5 transformed loc 3.064545766521091\n\n\n\n\n\n\nTransforming with yeojohnson and plotting the histogram\n\nfig, ax = plt.subplots(2,3, figsize=(15,5))\n#Plot 1 = Histogram\n#g1 = sns.histplot(data=df, x='Price_in_thousands', ax=g[0]);\n\nfor index, rv in enumerate([rv_half, rv_1, rv_2]):\n    x = rv.rvs(1000)\n    xt, lmax_mle = stats.yeojohnson(x)\n    print (\"Max likelihod yeojohnson loc {} scale {} transformed loc {}\".format(loc, (index+1)/2, lmax_mle))\n    prob = stats.probplot(xt, dist=stats.cauchy, plot=ax[0][index])\n    ax[0][index].set_xlabel('')\n    g1 = sns.histplot(data=xt, ax=ax[1][index]);\n\nMax likelihod yeojohnson loc 10 scale 0.5 transformed loc -10.978024153104741\nMax likelihod yeojohnson loc 10 scale 1.0 transformed loc 0.75743891613401\nMax likelihod yeojohnson loc 10 scale 1.5 transformed loc 4.505696516705801"
  },
  {
    "objectID": "posts/notebooks/2023-02-14-cauchy-distribution-boxcox-gaussian.html#confidence-interval",
    "href": "posts/notebooks/2023-02-14-cauchy-distribution-boxcox-gaussian.html#confidence-interval",
    "title": "Approximating Cauchy with Gaussian: Boxcox transformation",
    "section": "Confidence Interval",
    "text": "Confidence Interval\nFrom a normal distribution, it becomes easier to calculate confidence intervals. If we know that 95% of our data will be within 2 standard deviations, then we can just consider what’s within those limits.\n\nConfidence Interval 95%\nFor the last estimated likelihood\n\nupper = lmax_mle + 0.2\nlower = lmax_mle - 0.2\nprint(f'The confidence interval for 95% level is between {round(lower,2)} and {upper}.')\n\nThe confidence interval for 95% level is between -13.33 and -12.92936976907712.\n\n\nHowever, we must not forget that the values are transformed. So, what now?\nThere’s another good tool from scipy that is the inverse Box-Cox operation. In order to use that, you must import from scipy.special import inv_boxcox . Then, notice that when we transformed the data, we found the optimal lambda. Now it is time to use it for the inverse operation.\n\n\n# Import the inverse Box-Cox\nfrom scipy.special import inv_boxcox\n# Apply the inversion using the lambda value found on the prior transformation\nupper_invert = inv_boxcox(upper, lmax_mle)\nlower_invert = inv_boxcox(lower, lmax_mle)\n# Print the result\nprint(f'The confidence interval for 95% level is between {round(lower_invert,2)} and { round(upper_invert,2) }.')\n\nThe confidence interval for 95% level is between 0.67 and 0.68.\n\n\n\nfor index, rv in enumerate([rv_half, rv_1, rv_2]):\n    x = rv.rvs(1000)\n    xt, lmax_mle = stats.yeojohnson(x)\n    upper = lmax_mle + 0.2\n    lower = lmax_mle - 0.2\n    # Apply the inversion using the lambda value found on the prior transformation\n    upper_invert = inv_boxcox(upper, lmax_mle)\n    lower_invert = inv_boxcox(lower, lmax_mle)\n    print(f'The confidence interval for 95% level is between {round(lower_invert,2)} and { round(upper_invert,2) }.')\n\nThe confidence interval for 95% level is between 0.62 and 0.62.\nThe confidence interval for 95% level is between 2.09 and 2.33.\nThe confidence interval for 95% level is between 0.64 and 0.92."
  },
  {
    "objectID": "posts/notebooks/2023-02-14-cauchy-distribution-boxcox-gaussian.html#comparing-interval",
    "href": "posts/notebooks/2023-02-14-cauchy-distribution-boxcox-gaussian.html#comparing-interval",
    "title": "Approximating Cauchy with Gaussian: Boxcox transformation",
    "section": "Comparing interval",
    "text": "Comparing interval\n\nrv_1.interval(alpha=0.9)\n\n(3.686248485324959, 16.31375151467504)\n\n\n\nrv_2.interval(alpha=0.9)\n\n(-2.6275030293500823, 22.62750302935008)\n\n\n\nstats.norm(loc=10, scale=0.1).interval(alpha=0.95)\n\n(9.804003601545995, 10.195996398454005)\n\n\n\nstats.cauchy(loc=10, scale=0.01).interval(alpha=0.95)\n\n(9.872937952638253, 10.127062047361747)"
  },
  {
    "objectID": "posts/notebooks/2022-02-05-proper-scoring-interval-score-crps.html",
    "href": "posts/notebooks/2022-02-05-proper-scoring-interval-score-crps.html",
    "title": "Proper Scoring Rules: Interval Score and CRPS",
    "section": "",
    "text": "We found out 95% Confidence interval is \\(Gaussian ( 2 \\sigma) == Laplace(3b)\\)"
  },
  {
    "objectID": "posts/notebooks/2022-02-05-proper-scoring-interval-score-crps.html#interval-score",
    "href": "posts/notebooks/2022-02-05-proper-scoring-interval-score-crps.html#interval-score",
    "title": "Proper Scoring Rules: Interval Score and CRPS",
    "section": "Interval Score",
    "text": "Interval Score\n\nclassical case of $(1 - ) % $ prediction interval\nwith lower and upper endpoints (predictive quatiles) at level \\(\\alpha/2\\) and $ 1 - /2$\nInterval score \\[  S_\\alpha^{int}(l, u ;x) = (u-l) + \\frac{2}{\\alpha}(l-x) \\mathbb{1} \\{x &lt; l\\}  + \\frac{2}{\\alpha} (x - u)\\mathbb{1}\\{x &gt; u\\}\\]\n\n\\(\\alpha_1= 0.02,\\alpha_2= 0.05,\\alpha_3=0.1\\) (implying nominal coverages of 98%,95%,90%)\n\nimport numpy as np\n\n\ndef interval_score(x, lower, upper, alpha=0.05):\n  assert np.all(upper&gt;=lower), \"Upper should be greater or equal to lower. Please check are you giving the upper and lower in propoer order \"\n  return (upper - lower) + (2/alpha)*(lower-x)*(x&lt;lower) + (2/alpha)*(x-upper)*(x&gt;upper)\n\n\nx = np.linspace(1.0, 12.0)\nl = 5.0\nu = 8.0\niscore = interval_score(x, l, u)\n\n\nimport matplotlib.pyplot as plt\n\n\nplt.plot(iscore)\n\n\n\n\n\nx = np.linspace(1.0, 12.0)\nl = 5.0*np.ones_like(x)\nu = 8.0*np.ones_like(x)\niscore = interval_score(x, l, u)\nplt.plot(iscore)"
  },
  {
    "objectID": "posts/notebooks/2022-02-05-proper-scoring-interval-score-crps.html#crps",
    "href": "posts/notebooks/2022-02-05-proper-scoring-interval-score-crps.html#crps",
    "title": "Proper Scoring Rules: Interval Score and CRPS",
    "section": "CRPS",
    "text": "CRPS\n\nimport scipy.stats as stats\ndef crps_gaussian(y_pred, y_std, y_true, scaled=True):\n    \"\"\"\n    Return the negatively oriented continuous ranked probability score for\n    held out data (y_true) given predictive uncertainty with mean (y_pred)\n    and standard-deviation (y_std). Each test point is given equal weight\n    in the overall score over the test set.\n    Negatively oriented means a smaller value is more desirable.\n    \"\"\"\n\n    # Flatten\n    num_pts = y_true.shape[0]\n    y_pred = y_pred.reshape(\n        num_pts,\n    )\n    y_std = y_std.reshape(\n        num_pts,\n    )\n    y_true = y_true.reshape(\n        num_pts,\n    )\n\n    # Compute crps\n    y_standardized = (y_true - y_pred) / y_std\n    term_1 = 1 / np.sqrt(np.pi)\n    term_2 = 2 * stats.norm.pdf(y_standardized, loc=0, scale=1)\n    term_3 = y_standardized * (2 * stats.norm.cdf(y_standardized, loc=0, scale=1) - 1)\n\n    crps_list = -1 * y_std * (term_1 - term_2 - term_3)\n    crps = np.sum(crps_list)\n\n    # Potentially scale so that sum becomes mean\n    if scaled:\n        crps = crps / len(crps_list)\n\n    return crps\n\n\ndata = np.random.normal(loc=1.0, scale=1.0, size=1000)\nmus = np.ones_like(data)\nsigmas = np.ones_like(data)\ncrps_gaussian(data, sigmas, mus, scaled=False)\n\n587.2681356774692"
  },
  {
    "objectID": "posts/notebooks/2023-08-21-non-linear-system-definitions.html",
    "href": "posts/notebooks/2023-08-21-non-linear-system-definitions.html",
    "title": "Non-Linear System Definitions - Application Kalman Filter",
    "section": "",
    "text": "When building kalman filter we define the system using mathematical equations like system equation, Odinary differential equation, Partial diferential equation, state-space equation, etc.\nI am collecting a set of these equations for easy access.\n\n\nIs there a meta-model domain specific language for specifing these models and the corresponsing filter\nHow to use Json-ld based DSL be used to reperesent systems and the filters\n\n\n\nCopied from [1]\nConsider the following example: A robot arm is moved by a single rotary joint. Since the robot arm is affected by gravity, the torque acting on the rotary joint depends on the current angle. The robot arm is observed by some sensor that is capable of measuring the absolute orientation. Our goal is to estimate the angle of the rotary joint.\nThe system can be modeled by\n\\[ \\theta_{k+1}=a_{k}(\\theta_{k})+w_{k} \\]\nwith system function\n\\[ a_{k}(\\theta_{k})=\\theta_{k}+\\underbrace{c_{1}\\sin (\\theta_{k})}_{\\rm gravity}+\\underbrace{c_{2}}_{\\rm velocity}, \\] where \\(\\theta_k\\) is the state and \\(w_k\\) is Wrapped Normal-distributed noise. The constants c1,c2 can be derived from a physical model of the system.\nThe measurement equation is given by\n\\[ \\hat{z}_{k}=\\theta_{k}+v_{k}, \\] where \\(z_k\\) is the orientation measurement and \\(v_k\\) is WrappdNormal-distributed noise.\n\n\n\\[ \\begin{align*}\n\\boldsymbol{\\theta }_{k} = &\\boldsymbol{\\theta }_{k-1}+d_{1} \\sin (\\boldsymbol{\\theta }_{k-1})+d_{2}+\\eta _{k-1}, \\tag{35}\\\\\n\\mathbf{y}_{k} = \\begin{bmatrix}\\sin \\left(\\theta_{k}\\right) \\\\\\cos \\left(\\theta_{k}\\right)\\end{bmatrix}+\\vartheta_{k},\\tag{36}\n\\end{align*} \\]\nwhere d1 and d2 are constants.\nThe initial true and estimated states are taken as θ0=0 and θ~0|0=π , respectively, while the initial variance is taken as P0|0=2 . We assign d1=0.1 , d2=0.15 , Q=0.1 , and R=diag(0.2,0.2) . The simulation is performed for 200 time-steps and angular RMSEs are computed by implementing 1000 Monte-Carlo simulations.\n\n[1] G. Kurz, I. Gilitschenski and U. D. Hanebeck, “Recursive nonlinear filtering for angular data based on circular distributions,” 2013 American Control Conference, Washington, DC, USA, 2013, pp. 5439-5445, doi: 10.1109/ACC.2013.6580688.\n[2]\n\n\n\n\n\nCopied from [2]\nThe second problem considered is a general multivariate nonlinear angular estimation problem [14]. In this problem, the state dynamics are of oscillatory nature, while the measurement equation is a monotone increasing function of arguments (e.g. a positive quadratic form or its positive square root). Similar, system models often appear in sonar-based bearing measurements and GPS (Global positioning system)-based information on the angle of arrival. This problem has been widely used in literature [11], [14], [44], [45] for validating the filtering performance. The state-space model of this problem can be written as [14],\n\\[ \\begin{align*} \\boldsymbol {\\theta }_{k}=&|2 \\cos (\\boldsymbol {\\theta }_{k-1})|+{\\eta _{k-1}}, \\tag{37}\\\\ \\mathbf {y}_{k}=&\\sqrt {(1+ \\boldsymbol {\\theta }_{k}^{T} \\boldsymbol {\\theta }_{k})} +\\vartheta _{k}.\\tag{38}\\end{align*} \\]\nWe consider a three-dimensional system (θk∈D3,yk∈D ) and assign the initial true and estimated states as θ0=[0,−π,π]T and θ~0|0=[−π,π,π/2]T , respectively, while initial error covariance is taken as P0|0=2In . The noise covariances are assigned as Q=diag([0.05,0.05,0.05]) and R=0.1 . The states are estimated for 200 time-steps and the results are evaluated by performing 1000 Monte-Carlo runs.\n\n\n\nExample based on [1] for Cartesian to Polar Transformation . Below is the text\nThe simple example of transforming the coordinates of a point from the Cartesian to the Polar plane is considered. We assume that the mean and standard uncertainty of the cartesian coordinates \\((x, y)\\) are known a priori and the quanti- ties are declared as uncertain objects as depicted in Fig. 2. The radial and angular coordinates \\((r, θ)\\) are computed by applying the transformation equations \\[r = \\sqrt{x^2 + y^2}\\] and \\[\\theta = arctan(y/x)\\], respectively.\n[1] Automatic Uncertainty Propagation Based on the Unscented Transform"
  },
  {
    "objectID": "posts/notebooks/2023-08-21-non-linear-system-definitions.html#single-rotatry-joint-robot-arm",
    "href": "posts/notebooks/2023-08-21-non-linear-system-definitions.html#single-rotatry-joint-robot-arm",
    "title": "Non-Linear System Definitions - Application Kalman Filter",
    "section": "",
    "text": "Copied from [1]\nConsider the following example: A robot arm is moved by a single rotary joint. Since the robot arm is affected by gravity, the torque acting on the rotary joint depends on the current angle. The robot arm is observed by some sensor that is capable of measuring the absolute orientation. Our goal is to estimate the angle of the rotary joint.\nThe system can be modeled by\n\\[ \\theta_{k+1}=a_{k}(\\theta_{k})+w_{k} \\]\nwith system function\n\\[ a_{k}(\\theta_{k})=\\theta_{k}+\\underbrace{c_{1}\\sin (\\theta_{k})}_{\\rm gravity}+\\underbrace{c_{2}}_{\\rm velocity}, \\] where \\(\\theta_k\\) is the state and \\(w_k\\) is Wrapped Normal-distributed noise. The constants c1,c2 can be derived from a physical model of the system.\nThe measurement equation is given by\n\\[ \\hat{z}_{k}=\\theta_{k}+v_{k}, \\] where \\(z_k\\) is the orientation measurement and \\(v_k\\) is WrappdNormal-distributed noise.\n\n\n\\[ \\begin{align*}\n\\boldsymbol{\\theta }_{k} = &\\boldsymbol{\\theta }_{k-1}+d_{1} \\sin (\\boldsymbol{\\theta }_{k-1})+d_{2}+\\eta _{k-1}, \\tag{35}\\\\\n\\mathbf{y}_{k} = \\begin{bmatrix}\\sin \\left(\\theta_{k}\\right) \\\\\\cos \\left(\\theta_{k}\\right)\\end{bmatrix}+\\vartheta_{k},\\tag{36}\n\\end{align*} \\]\nwhere d1 and d2 are constants.\nThe initial true and estimated states are taken as θ0=0 and θ~0|0=π , respectively, while the initial variance is taken as P0|0=2 . We assign d1=0.1 , d2=0.15 , Q=0.1 , and R=diag(0.2,0.2) . The simulation is performed for 200 time-steps and angular RMSEs are computed by implementing 1000 Monte-Carlo simulations.\n\n[1] G. Kurz, I. Gilitschenski and U. D. Hanebeck, “Recursive nonlinear filtering for angular data based on circular distributions,” 2013 American Control Conference, Washington, DC, USA, 2013, pp. 5439-5445, doi: 10.1109/ACC.2013.6580688.\n[2]"
  },
  {
    "objectID": "posts/notebooks/2023-08-21-non-linear-system-definitions.html#problem-2",
    "href": "posts/notebooks/2023-08-21-non-linear-system-definitions.html#problem-2",
    "title": "Non-Linear System Definitions - Application Kalman Filter",
    "section": "",
    "text": "Copied from [2]\nThe second problem considered is a general multivariate nonlinear angular estimation problem [14]. In this problem, the state dynamics are of oscillatory nature, while the measurement equation is a monotone increasing function of arguments (e.g. a positive quadratic form or its positive square root). Similar, system models often appear in sonar-based bearing measurements and GPS (Global positioning system)-based information on the angle of arrival. This problem has been widely used in literature [11], [14], [44], [45] for validating the filtering performance. The state-space model of this problem can be written as [14],\n\\[ \\begin{align*} \\boldsymbol {\\theta }_{k}=&|2 \\cos (\\boldsymbol {\\theta }_{k-1})|+{\\eta _{k-1}}, \\tag{37}\\\\ \\mathbf {y}_{k}=&\\sqrt {(1+ \\boldsymbol {\\theta }_{k}^{T} \\boldsymbol {\\theta }_{k})} +\\vartheta _{k}.\\tag{38}\\end{align*} \\]\nWe consider a three-dimensional system (θk∈D3,yk∈D ) and assign the initial true and estimated states as θ0=[0,−π,π]T and θ~0|0=[−π,π,π/2]T , respectively, while initial error covariance is taken as P0|0=2In . The noise covariances are assigned as Q=diag([0.05,0.05,0.05]) and R=0.1 . The states are estimated for 200 time-steps and the results are evaluated by performing 1000 Monte-Carlo runs."
  },
  {
    "objectID": "posts/notebooks/2023-08-21-non-linear-system-definitions.html#uncertainty-propagation-in-python",
    "href": "posts/notebooks/2023-08-21-non-linear-system-definitions.html#uncertainty-propagation-in-python",
    "title": "Non-Linear System Definitions - Application Kalman Filter",
    "section": "",
    "text": "Example based on [1] for Cartesian to Polar Transformation . Below is the text\nThe simple example of transforming the coordinates of a point from the Cartesian to the Polar plane is considered. We assume that the mean and standard uncertainty of the cartesian coordinates \\((x, y)\\) are known a priori and the quanti- ties are declared as uncertain objects as depicted in Fig. 2. The radial and angular coordinates \\((r, θ)\\) are computed by applying the transformation equations \\[r = \\sqrt{x^2 + y^2}\\] and \\[\\theta = arctan(y/x)\\], respectively.\n[1] Automatic Uncertainty Propagation Based on the Unscented Transform"
  },
  {
    "objectID": "posts/notebooks/2024-01-09-uncertain-data-type-python-bayes-rule-ipynb.html",
    "href": "posts/notebooks/2024-01-09-uncertain-data-type-python-bayes-rule-ipynb.html",
    "title": "Uncertain Data types - Sampling based Bayes-Laplace Rule",
    "section": "",
    "text": "Uncertain data types play a crucial role in robotics by addressing uncertainties in sensor measurements. For instance, in robotic localization, sensors may provide imprecise information about the robot’s position. The advantage lies in using probabilistic models to represent this uncertainty. Methodologies like Bayesian filtering help integrate sensor data and estimate the robot’s position more accurately. In software development for robotics, uncertainty-aware algorithms enhance navigation and mapping. Applications include autonomous vehicles, where uncertain data types improve decision-making in dynamic environments. However, challenges arise in developing efficient algorithms due to the computational demands of handling uncertainty in real-time robotic systems.\nEfforts to create uncertain data types span various programming languages, each with its approach. In C and C++, developers often implement uncertainty by using custom data structures and libraries. They leverage pointers and structures to represent uncertain values and design algorithms for uncertainty propagation. In Julia, a high-level programming language, the focus is on mathematical simplicity and performance. The language’s flexibility allows developers to design custom data types and functions tailored to uncertain data, enhancing computational efficiency. Probabilistic programming languages like Stan and Pyro offer specialized constructs for uncertain data types. These languages enable developers to express uncertainty directly in their models, simplifying the incorporation of probabilistic reasoning. Overall, efforts in uncertain data types reflect the diverse strategies employed across languages, ranging from low-level control in C and C++ to high-level expressiveness in Julia and specialized support in probabilistic programming languages.\nIn paper Uncertain they developed a datatype called Uncertain in C# language . For years I was thinking of implementing something similar in python but was missing some motivation. Recently I came accross another hardware level library developed by a company called Signaloid doing the same in C and C++ language. Since their sample code were available in github, I got a motivation to write the pending python library.\n\n\n\n\n\nLets say we have a sensor reading \\(x\\) with value 10 we want to represent it in python we will write x=10.\nNow we have additional information that the sensor reading is not accurate and the sensor reading is around 10.\nHow do you represent this uncertain information in code?\nNot only represent we would like to do matematical operations (add, subtract, power etc) with this value and still keep the uncertain information\nThere are different methodology for representation of uncertain value and different ways to do it in code.\nIn this blog we use the parametric representation method, where we model the uncertain information is modelled using any statistical Distribution (Normal, Laplace, exponential etc)\nFor the mathematical operations on these uncertain values we then use 2 methods :\n\nSampling based Monto Carlo method\nSigma points propagation\n\n\nThe names of the classes and the different methods have been inspired by the Signaloid library github\n\nimport scipy.stats as stats\nimport numpy as np\nfrom scipy.integrate import trapz\nimport sys\nEPSILON = sys.float_info.epsilon\nNUM_SAMPLES = 1000\n\n\nclass uDoubleGaussDist:\n    \"\"\"\n    Custom datatype replicating double datatype with mathematical operators.\n\n    Attributes:\n    - value (float): The value stored in the uDoubleGaussDist.\n\n    Methods:\n    - __init__(self, value: float): Initializes the uDoubleGaussDist with a specified value.\n    - __add__(self, other: 'uDoubleGaussDist') -&gt; 'uDoubleGaussDist': Defines addition operation for uDoubleGaussDist.\n    - __sub__(self, other: 'uDoubleGaussDist') -&gt; 'uDoubleGaussDist': Defines subtraction operation for uDoubleGaussDist.\n    - __mul__(self, other: 'uDoubleGaussDist') -&gt; 'uDoubleGaussDist': Defines multiplication operation for uDoubleGaussDist.\n    - __truediv__(self, other: 'uDoubleGaussDist') -&gt; 'uDoubleGaussDist': Defines true division operation for uDoubleGaussDist.\n    - __str__(self) -&gt; str: Returns the string representation of the uDoubleGaussDist.\n    \"\"\"\n\n    def __init__(self, value: float, sigma: float = 1e-6):\n        \"\"\"Initialize uDoubleGaussDist with a specified value.\"\"\"\n        self.value = float(value)\n        self.sigma = float(sigma)\n        self.distirbution = stats.norm(value, sigma)\n\n    def __add__(self, other: 'uDoubleGaussDist') -&gt; 'uDoubleGaussDist':\n        \"\"\"Define addition operation for uDoubleGaussDist.\"\"\"\n\n        self_samples = self.distirbution.rvs( size=NUM_SAMPLES, random_state=123)\n        other_samples = other.distirbution.rvs( size=NUM_SAMPLES, random_state=123)\n        loc1, scale1 = stats.norm.fit(self_samples + other_samples)\n\n        return uDoubleGaussDist(loc1, scale1)\n\n    def __sub__(self, other: 'uDoubleGaussDist') -&gt; 'uDoubleGaussDist':\n        \"\"\"Define subtraction operation for uDoubleGaussDist.\"\"\"\n        self_samples = self.distirbution.rvs( size=NUM_SAMPLES, random_state=123)\n        other_samples = other.distirbution.rvs( size=NUM_SAMPLES, random_state=123)\n        loc1, scale1 = stats.norm.fit(self_samples - other_samples)\n        return uDoubleGaussDist(loc1, scale1)\n\n    def __mul__(self, other: 'uDoubleGaussDist') -&gt; 'uDoubleGaussDist':\n        \"\"\"Define multiplication operation for uDoubleGaussDist.\"\"\"\n        self_samples = self.distirbution.rvs( size=NUM_SAMPLES, random_state=123)\n        other_samples = other.distirbution.rvs( size=NUM_SAMPLES, random_state=123)\n        loc1, scale1 = stats.norm.fit(self_samples * other_samples)\n        return uDoubleGaussDist(loc1, scale1)\n\n    def __truediv__(self, other: 'uDoubleGaussDist') -&gt; 'uDoubleGaussDist':\n        \"\"\"Define true division operation for uDoubleGaussDist.\"\"\"\n        if other.value != 0:\n            self_samples = self.distirbution.rvs( size=NUM_SAMPLES, random_state=123)\n            other_samples = other.distirbution.rvs( size=NUM_SAMPLES, random_state=123)\n            loc1, scale1 = stats.norm.fit(self_samples / other_samples)\n            return uDoubleGaussDist(loc1, scale1)\n        else:\n            raise ValueError(\"Division by zero\")\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of uDoubleGaussDist.\"\"\"\n        return str(self.value)\n\n# Example usage:\na = uDoubleGaussDist(2.5)\nb = uDoubleGaussDist(1.5)\n\nresult = a + b\nprint(result)  # Output: 4.0\n\nresult = a - b\nprint(result)  # Output: 4.0\n\n\nresult = a * b\nprint(result)  # Output: 4.0\n\n\nresult = a / b\nprint(result)  # Output: 4.0\n\n4.000000054218146\n1.0\n3.750000108437568\n1.666666654618567\n\n\n\n%timeit a+b\n\n1.61 ms ± 296 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n\n\n\n%timeit 2.5+1.5\n\n15.6 ns ± 3.94 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)\n\n\n\nsys.float_info.epsilon\n\n2.220446049250313e-16\n\n\n\n\n\n\nSampling\nfitting"
  },
  {
    "objectID": "posts/notebooks/2024-01-09-uncertain-data-type-python-bayes-rule-ipynb.html#tldr",
    "href": "posts/notebooks/2024-01-09-uncertain-data-type-python-bayes-rule-ipynb.html#tldr",
    "title": "Uncertain Data types - Sampling based Bayes-Laplace Rule",
    "section": "",
    "text": "Lets say we have a sensor reading \\(x\\) with value 10 we want to represent it in python we will write x=10.\nNow we have additional information that the sensor reading is not accurate and the sensor reading is around 10.\nHow do you represent this uncertain information in code?\nNot only represent we would like to do matematical operations (add, subtract, power etc) with this value and still keep the uncertain information\nThere are different methodology for representation of uncertain value and different ways to do it in code.\nIn this blog we use the parametric representation method, where we model the uncertain information is modelled using any statistical Distribution (Normal, Laplace, exponential etc)\nFor the mathematical operations on these uncertain values we then use 2 methods :\n\nSampling based Monto Carlo method\nSigma points propagation\n\n\nThe names of the classes and the different methods have been inspired by the Signaloid library github\n\nimport scipy.stats as stats\nimport numpy as np\nfrom scipy.integrate import trapz\nimport sys\nEPSILON = sys.float_info.epsilon\nNUM_SAMPLES = 1000\n\n\nclass uDoubleGaussDist:\n    \"\"\"\n    Custom datatype replicating double datatype with mathematical operators.\n\n    Attributes:\n    - value (float): The value stored in the uDoubleGaussDist.\n\n    Methods:\n    - __init__(self, value: float): Initializes the uDoubleGaussDist with a specified value.\n    - __add__(self, other: 'uDoubleGaussDist') -&gt; 'uDoubleGaussDist': Defines addition operation for uDoubleGaussDist.\n    - __sub__(self, other: 'uDoubleGaussDist') -&gt; 'uDoubleGaussDist': Defines subtraction operation for uDoubleGaussDist.\n    - __mul__(self, other: 'uDoubleGaussDist') -&gt; 'uDoubleGaussDist': Defines multiplication operation for uDoubleGaussDist.\n    - __truediv__(self, other: 'uDoubleGaussDist') -&gt; 'uDoubleGaussDist': Defines true division operation for uDoubleGaussDist.\n    - __str__(self) -&gt; str: Returns the string representation of the uDoubleGaussDist.\n    \"\"\"\n\n    def __init__(self, value: float, sigma: float = 1e-6):\n        \"\"\"Initialize uDoubleGaussDist with a specified value.\"\"\"\n        self.value = float(value)\n        self.sigma = float(sigma)\n        self.distirbution = stats.norm(value, sigma)\n\n    def __add__(self, other: 'uDoubleGaussDist') -&gt; 'uDoubleGaussDist':\n        \"\"\"Define addition operation for uDoubleGaussDist.\"\"\"\n\n        self_samples = self.distirbution.rvs( size=NUM_SAMPLES, random_state=123)\n        other_samples = other.distirbution.rvs( size=NUM_SAMPLES, random_state=123)\n        loc1, scale1 = stats.norm.fit(self_samples + other_samples)\n\n        return uDoubleGaussDist(loc1, scale1)\n\n    def __sub__(self, other: 'uDoubleGaussDist') -&gt; 'uDoubleGaussDist':\n        \"\"\"Define subtraction operation for uDoubleGaussDist.\"\"\"\n        self_samples = self.distirbution.rvs( size=NUM_SAMPLES, random_state=123)\n        other_samples = other.distirbution.rvs( size=NUM_SAMPLES, random_state=123)\n        loc1, scale1 = stats.norm.fit(self_samples - other_samples)\n        return uDoubleGaussDist(loc1, scale1)\n\n    def __mul__(self, other: 'uDoubleGaussDist') -&gt; 'uDoubleGaussDist':\n        \"\"\"Define multiplication operation for uDoubleGaussDist.\"\"\"\n        self_samples = self.distirbution.rvs( size=NUM_SAMPLES, random_state=123)\n        other_samples = other.distirbution.rvs( size=NUM_SAMPLES, random_state=123)\n        loc1, scale1 = stats.norm.fit(self_samples * other_samples)\n        return uDoubleGaussDist(loc1, scale1)\n\n    def __truediv__(self, other: 'uDoubleGaussDist') -&gt; 'uDoubleGaussDist':\n        \"\"\"Define true division operation for uDoubleGaussDist.\"\"\"\n        if other.value != 0:\n            self_samples = self.distirbution.rvs( size=NUM_SAMPLES, random_state=123)\n            other_samples = other.distirbution.rvs( size=NUM_SAMPLES, random_state=123)\n            loc1, scale1 = stats.norm.fit(self_samples / other_samples)\n            return uDoubleGaussDist(loc1, scale1)\n        else:\n            raise ValueError(\"Division by zero\")\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of uDoubleGaussDist.\"\"\"\n        return str(self.value)\n\n# Example usage:\na = uDoubleGaussDist(2.5)\nb = uDoubleGaussDist(1.5)\n\nresult = a + b\nprint(result)  # Output: 4.0\n\nresult = a - b\nprint(result)  # Output: 4.0\n\n\nresult = a * b\nprint(result)  # Output: 4.0\n\n\nresult = a / b\nprint(result)  # Output: 4.0\n\n4.000000054218146\n1.0\n3.750000108437568\n1.666666654618567\n\n\n\n%timeit a+b\n\n1.61 ms ± 296 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n\n\n\n%timeit 2.5+1.5\n\n15.6 ns ± 3.94 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)\n\n\n\nsys.float_info.epsilon\n\n2.220446049250313e-16\n\n\n\n\n\n\nSampling\nfitting"
  },
  {
    "objectID": "posts/notebooks/2024-01-09-uncertain-data-type-python-bayes-rule-ipynb.html#how-will-you-merge-uncertain-information-of-same-value-from-2-different-sources",
    "href": "posts/notebooks/2024-01-09-uncertain-data-type-python-bayes-rule-ipynb.html#how-will-you-merge-uncertain-information-of-same-value-from-2-different-sources",
    "title": "Uncertain Data types - Sampling based Bayes-Laplace Rule",
    "section": "How will you merge uncertain information of same value from 2 different sources ?",
    "text": "How will you merge uncertain information of same value from 2 different sources ?\n\nANSWER : Bayes Laplace Rule\n\ndef uDoubleBayesLaplace(prior: uDoubleGaussDist, evidence: uDoubleGaussDist) -&gt; uDoubleGaussDist:\n    \"\"\"\n    Perform Bayesian inference using Laplace approximation.\n\n    Parameters:\n    - prior (uDoubleGaussDist): Prior distribution.\n    - evidence (uDoubleGaussDist): Evidence distribution.\n\n    Returns:\n    - uDoubleGaussDist: Posterior distribution.\n\n    This function calculates the posterior distribution using Laplace approximation\n    based on the provided prior and evidence distributions. It generates samples\n    from the posterior distribution and returns a uDoubleGaussDist object representing\n    the posterior distribution.\n\n    Example:\n    prior = uDoubleGaussDist(2.5, 0.1)\n    evidence = uDoubleGaussDist(1.5, 0.2)\n    posterior = uDoubleBayesLaplace(prior, evidence)\n    \"\"\"\n    min_sample = min(prior.distirbution.ppf(0.01),\n                    evidence.distirbution.ppf(0.01),\n                    prior.distirbution.ppf(0.99),\n                    evidence.distirbution.ppf(0.99))\n\n    max_sample = max(prior.distirbution.ppf(0.01),\n                    evidence.distirbution.ppf(0.01),\n                    prior.distirbution.ppf(0.99),\n                    evidence.distirbution.ppf(0.99))\n    #Generate uniform samples in the x axis\n    samples = np.linspace(min_sample,max_sample, NUM_SAMPLES)\n\n    #Calculate likelihood for each sample for prior and the evidence\n    prior_pdf = prior.distirbution.pdf(samples)+EPSILON #Adding epsilon to avoid zeros for pdf\n    evidence_pdf = evidence.distirbution.pdf(samples)+EPSILON\n\n    #Multiplying the likelihoods\n    unnormalized_posterior = prior_pdf * evidence_pdf\n\n    #Normalizing the posterior by calculating the area and dividing by the area\n    area = trapz(unnormalized_posterior, samples)\n    posterior = unnormalized_posterior / area\n    print (\"Posterior mean \", samples[np.argmax(posterior)])\n\n    #generating samples from pdf\n    generated_samples = np.random.choice(samples, size=NUM_SAMPLES, p=posterior/np.sum(posterior))\n    print (\"Calculated Posterior mean \", np.mean(generated_samples))\n\n    return uDoubleGaussDist(np.mean(generated_samples), np.std(generated_samples))\n\n\nprior = uDoubleGaussDist(2.5,0.1)\nevidence = uDoubleGaussDist(1.5,0.2)\nposterior = uDoubleBayesLaplace(prior, evidence)\n\nPosterior mean  2.2992357760285844\nCalculated Posterior mean  2.3000294910807897\n\n\n\ndef plotuDoubleBayesLaplace(prior, evidence, posterior):\n\n  fig, ax = plt.subplots(1, 1)\n  min_sample = min(prior.distirbution.ppf(0.01),\n                   evidence.distirbution.ppf(0.01),\n                   prior.distirbution.ppf(0.99),\n                   evidence.distirbution.ppf(0.99))\n\n  max_sample = max(prior.distirbution.ppf(0.01),\n                   evidence.distirbution.ppf(0.01),\n                   prior.distirbution.ppf(0.99),\n                   evidence.distirbution.ppf(0.99))\n\n  samples = np.linspace(min_sample,max_sample, NUM_SAMPLES)\n  prior_pdf = prior.distirbution.pdf(samples)+EPSILON #Adding epsilon to avoid zeros for pdf\n\n  evidence_pdf = evidence.distirbution.pdf(samples)+EPSILON\n\n  posterior_pdf = posterior.distirbution.pdf(samples)+EPSILON\n\n  unnormalized_posterior = prior_pdf * evidence_pdf\n\n  area = trapz(unnormalized_posterior, samples)\n  original_posterior = unnormalized_posterior / area\n\n\n  ax.plot(samples, prior_pdf,\n        'r-', lw=2, alpha=0.6, label='prior pdf')\n\n  ax.plot(samples, evidence_pdf,\n        'b-', lw=2, alpha=0.6, label='evidence pdf')\n\n\n  ax.plot(samples,  posterior_pdf,\n        'g-', lw=2, alpha=0.6, label='posterior pdf')\n\n  ax.plot(samples,  original_posterior,\n        '-', lw=2, alpha=0.6, label='original posterior pdf')\n\n  ax.legend(loc='best', frameon=False)\n  # Save files in pdf and eps format\n  plt.savefig(\"sampling_bayes_laplace_rule.png\", dpi=150)\n\nplotuDoubleBayesLaplace(prior, evidence, posterior)\n\n\n\n\n\n\nCorner Case\nNeed things to improve.\n\nWhen the sigma is very low as 1e-6 .\n\n\nPDF values become zero at all places expect for the\n\n\nWhen the values are very far apart like 1 and 1000\n\n\n\nprior = uDoubleGaussDist(2.5)\nevidence = uDoubleGaussDist(1.5)\nposterior = uDoubleBayesLaplace(prior, evidence)\n\nplotuDoubleBayesLaplace(prior, evidence, posterior)\n\n\n\n\n\n\nprior = uDoubleGaussDist(2.5, 0.1)\nevidence = uDoubleGaussDist(1000, 0.1)\nposterior = uDoubleBayesLaplace(prior, evidence)\n\nplotuDoubleBayesLaplace(prior, evidence, posterior)"
  },
  {
    "objectID": "posts/notebooks/2024-01-09-uncertain-data-type-python-bayes-rule-ipynb.html#possible-solutions-not-working",
    "href": "posts/notebooks/2024-01-09-uncertain-data-type-python-bayes-rule-ipynb.html#possible-solutions-not-working",
    "title": "Uncertain Data types - Sampling based Bayes-Laplace Rule",
    "section": "Possible solutions (Not working)",
    "text": "Possible solutions (Not working)\n\nSample differently for both the prior and the evidence\n#TODO The estimated posterior and multiplied posterior are differnt .\n\n\nbecause of the differnt precision the sample generation process is not working\nNeed an alternative to the sample generation from pdf\n\n\ndef uDoubleBayesLaplace(prior, evidence):\n\n  samples = np.sort( np.append(np.linspace(prior.distirbution.ppf(0.01),\n                                 prior.distirbution.ppf(0.99), NUM_SAMPLES),\n                     np.linspace(evidence.distirbution.ppf(0.01),\n                                 evidence.distirbution.ppf(0.99), NUM_SAMPLES) ))\n\n  prior_pdf = prior.distirbution.pdf(samples) #Adding epsilon to avoid zeros for pdf\n\n  evidence_pdf = evidence.distirbution.pdf(samples)\n\n  unnormalized_posterior = prior_pdf * evidence_pdf\n\n  area = trapz(unnormalized_posterior, samples)\n  posterior = unnormalized_posterior / area\n  print (\"Posterior mean \", samples[np.argmax(posterior)])\n\n\n  #generating samples from pdf\n  generated_samples = np.random.choice(np.linspace(min(samples),\n                                                   max(samples),\n                                                   num=NUM_SAMPLES*2),\n                                       size=NUM_SAMPLES*2,\n                                       p=posterior/np.sum(posterior))\n  print (\"Calculated Posterior mean \", np.mean(generated_samples))\n\n\n  return uDoubleGaussDist(np.mean(generated_samples), np.std(generated_samples))\n\n\nprior = uDoubleGaussDist(2.5,0.1)\nevidence = uDoubleGaussDist(1.5,0.2)\nposterior = uDoubleBayesLaplace(prior, evidence)\n\nPosterior mean  2.299966684304196\nCalculated Posterior mean  2.041209314588317\n\n\n\ndef plotuDoubleBayesLaplace(prior, evidence, posterior):\n\n  fig, ax = plt.subplots(1, 1)\n  samples = np.sort( np.append( np.linspace(prior.distirbution.ppf(0.01),\n                                 prior.distirbution.ppf(0.99), NUM_SAMPLES),\n                     np.linspace(evidence.distirbution.ppf(0.01),\n                                 evidence.distirbution.ppf(0.99), NUM_SAMPLES) ))\n  prior_pdf = prior.distirbution.pdf(samples) #Adding epsilon to avoid zeros for pdf\n\n  evidence_pdf = evidence.distirbution.pdf(samples)\n\n  unnormalized_posterior = prior_pdf * evidence_pdf\n\n  area = trapz(unnormalized_posterior, samples)\n  original_posterior = unnormalized_posterior / area\n\n  posterior_pdf = posterior.distirbution.pdf(samples)\n\n  ax.plot(samples, prior_pdf,\n        'r-', lw=2, alpha=0.6, label='prior pdf')\n\n  ax.plot(samples, evidence_pdf,\n        'b-', lw=2, alpha=0.6, label='evidence pdf')\n\n\n  ax.plot(samples,  posterior_pdf,\n        'g-', lw=2, alpha=0.6, label='posterior pdf')\n\n  ax.plot(samples,  original_posterior,\n        'y-', lw=2, alpha=0.6, label='original posterior pdf')\n\n  ax.legend(loc='best', frameon=False)\n\nplotuDoubleBayesLaplace(prior, evidence, posterior)"
  },
  {
    "objectID": "posts/notebooks/2022-12-15-comparing-normal-laplace-cacuhy-distirbutions-interval-score.html#questions",
    "href": "posts/notebooks/2022-12-15-comparing-normal-laplace-cacuhy-distirbutions-interval-score.html#questions",
    "title": "Comparing Distributions : Normal, Laplace and Cauchy",
    "section": "Questions",
    "text": "Questions\n\nHow to compare these 3 distirbution?\nMore importantly if a particular distirbution is representing an uncertain information, then how can we measure which value is giving the best representation of the uncertainty."
  },
  {
    "objectID": "posts/notebooks/2022-12-15-comparing-normal-laplace-cacuhy-distirbutions-interval-score.html#solution",
    "href": "posts/notebooks/2022-12-15-comparing-normal-laplace-cacuhy-distirbutions-interval-score.html#solution",
    "title": "Comparing Distributions : Normal, Laplace and Cauchy",
    "section": "Solution",
    "text": "Solution\nFor comparing uncertainty different methods has been mentioned in literature. The one which we are going to use here is Interval Score, which comes under the field of Proper Scoring Rules [1].\n\nProper Scoring rules\n\nScoring rules assess the quality of probabilistic forecasts, by assigning a numerical score based on the predictive distribution and on the event or value that materializes. It is strictly proper if the maximum is unique. In prediction problems, proper scoring rules encourage the forecaster to make careful assessments and to be honest. In estimation problems, strictly proper scoring rules provide attractive loss and utility functions that can be tailored to the problem at hand [1]\n\n[1] Gneiting, Tilmann, and Adrian E. Raftery. “Strictly proper scoring rules, prediction, and estimation.” Journal of the American statistical Association 102.477 (2007): 359-378."
  },
  {
    "objectID": "posts/notebooks/2022-12-15-comparing-normal-laplace-cacuhy-distirbutions-interval-score.html#interval-score",
    "href": "posts/notebooks/2022-12-15-comparing-normal-laplace-cacuhy-distirbutions-interval-score.html#interval-score",
    "title": "Comparing Distributions : Normal, Laplace and Cauchy",
    "section": "Interval Score",
    "text": "Interval Score\n\nclassical case of $(1 - ) % $ prediction interval\nwith lower and upper endpoints (predictive quatiles) at level \\(\\alpha/2\\) and $ 1 - /2$\nInterval score \\[  S_\\alpha^{int}(l, u ;x) = (u-l) + \\frac{2}{\\alpha}(l-x) \\mathbb{1} \\{x &lt; l\\}  + \\frac{2}{\\alpha} (x - u)\\mathbb{1}\\{x &gt; u\\}\\]\n\n\\(\\alpha_1= 0.02,\\alpha_2= 0.05,\\alpha_3=0.1\\) (implying nominal coverages of 98%,95%,90%)\n\ndef interval_score(x, lower, upper, alpha=0.05):\n  assert np.all(upper&gt;=lower), \"Upper should be greater or equal to lower. Please check are you giving the upper and lower in propoer order \"\n  return (upper - lower) + (2/alpha)*(lower-x)*(x&lt;lower) + (2/alpha)*(x-upper)*(x&gt;upper)\n\n\nx = np.linspace(3.0, 10.0)\nl = 5.0\nu = 8.0\niscore = interval_score(x, l, u)\nplt.plot(x, iscore, c='b')\nl = 6.0\nu = 7.0\niscore = interval_score(x, l, u)\nplt.plot(x, iscore, c='r')\n\n\n\n\nThe way to interpret the method with respect to state-estimation algorithm can be. Let \\(x\\) be the true_value and the prediction is the range \\([5,8]\\) then the intervalscore is minimum if the true value was also inbetween \\([5,8]\\) as shown in the blue plot.\nWith the red plot you can see if you give a tigher bound then the score is further low.\nSo if the true value is inside the lower and uper limits the score is minimum also with tighter bound you get better scores"
  },
  {
    "objectID": "posts/notebooks/2022-12-15-comparing-normal-laplace-cacuhy-distirbutions-interval-score.html#using-interval-score-for-distirbutions",
    "href": "posts/notebooks/2022-12-15-comparing-normal-laplace-cacuhy-distirbutions-interval-score.html#using-interval-score-for-distirbutions",
    "title": "Comparing Distributions : Normal, Laplace and Cauchy",
    "section": "Using Interval Score for Distirbutions",
    "text": "Using Interval Score for Distirbutions\n** We need to define the intervals** .\nSo how do we calculate the intervals of different distirbutions ??\nsympy to help, it has the &gt; .interval(alpha) function\nLets calcuate the interval function of the above distirbutions\n\nprint (\" Normal Distirbution 95% interval \", normal_dist.interval(alpha=0.95))\nprint (\" Laplace Distirbution 95% interval\", laplace_dist.interval(alpha=0.95))\nprint (\" Cauchy Distirbution 95% interval\", cauchy_dist.interval(alpha=0.95))\n\n Normal Distirbution 95% interval  (9.412010804637983, 10.587989195362017)\n Laplace Distirbution 95% interval (9.400853545289202, 10.599146454710798)\n Cauchy Distirbution 95% interval (9.700426772644601, 10.299573227355399)"
  },
  {
    "objectID": "posts/notebooks/2022-12-15-comparing-normal-laplace-cacuhy-distirbutions-interval-score.html#formula",
    "href": "posts/notebooks/2022-12-15-comparing-normal-laplace-cacuhy-distirbutions-interval-score.html#formula",
    "title": "Comparing Distributions : Normal, Laplace and Cauchy",
    "section": "Formula",
    "text": "Formula\nSo now we have the lower and upper limit for each distirbution . Lets now calculate the Interval Score.\n\nl, u = normal_dist.interval(alpha=0.95)\nprint (\"Normal Distirbution :\")\nprint (\"95% interval \", normal_dist.interval(alpha=0.95))\nprint (\"Interval Score \", interval_score(10 , l, u))\nprint (\"############### \")\n\nprint (\"Laplace Distirbution\")\nl, u = laplace_dist.interval(alpha=0.95)\nprint (\"95% interval \", laplace_dist.interval(alpha=0.95))\nprint (\"Interval Score \", interval_score(10 , l, u))\n\nprint (\"############### \")\n\nprint (\"Cauchy Distirbution 95%\")\nl, u = cauchy_dist.interval(alpha=0.95)\nprint (\"95% interval \", cauchy_dist.interval(alpha=0.95))\nprint (\"Interval Score \",interval_score(10 , l, u))\n\nNormal Distirbution :\n95% interval  (9.412010804637983, 10.587989195362017)\nInterval Score  1.1759783907240333\n############### \nLaplace Distirbution\n95% interval  (9.400853545289202, 10.599146454710798)\nInterval Score  1.1982929094215962\n############### \nCauchy Distirbution 95%\n95% interval  (9.700426772644601, 10.299573227355399)\nInterval Score  0.5991464547107981\n\n\n\nHere you can see for True value \\(x = 10\\), Cauchy Distirbution (loc=10, scale=0.1) gives the minimum Interval Score of 0.6 .\nThus, with Interval Score a Proper scoring rule we can compare different distirbutions."
  },
  {
    "objectID": "posts/notebooks/2023-01-26-general-loss-function-l2.html#gradients-of-the-equation",
    "href": "posts/notebooks/2023-01-26-general-loss-function-l2.html#gradients-of-the-equation",
    "title": "General loss fuction: L1, L2, L3 …",
    "section": "Gradients of the equation",
    "text": "Gradients of the equation\n\ndiff_equation = scale * sym.Abs(diff)\ndiff_equation\n\n\n\n\n\n#hide_code\np1 = symplot.plot(diff_equation.subs([(scale,1)]), (diff,-5,5), show=False)\np1[0].label = 'slope 1.0, zero %s'% (str(diff_equation.subs([(scale,1), (diff,0)])))\ni=0\nfor s in [0.5, 1.5, 2., 5]:\n    p = symplot.plot(diff_equation.subs([(scale,s)]), (diff,-5,5), show=False, line_color=color[i%len(color)+1])\n    p[0].label =  'slope %s, zero %s'% (str(s),str(diff_equation.subs([(scale,s), (diff,0)])))\n    p1.append(p[0])\n    i = i+1\n\np1.legend = True\np1.ylim = (-0.3, 20)\np1.xlim = (-5., 5)\np1.size = (8,8)\np1.show()"
  },
  {
    "objectID": "posts/notebooks/2023-01-26-general-loss-function-l2.html#toy-dataset",
    "href": "posts/notebooks/2023-01-26-general-loss-function-l2.html#toy-dataset",
    "title": "General loss fuction: L1, L2, L3 …",
    "section": "Toy dataset",
    "text": "Toy dataset\nfitting loss function to the gnerl l2 loss .\n\n#hide_code\ndef synthetic_sine_heteroscedastic(\n    n_points: int = 10,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Return samples from \"synthetic sine\" heteroscedastic noisy function.\n    This returns a synthetic dataset which can be used to train and assess a predictive\n    uncertainty model.\n    Args:\n        n_points: The number of data points in the set.\n    Returns:\n        - Predicted output points y.\n        - Predictive uncertainties, defined using standard deviation of added noise.\n        - True output points y.\n        - True input points x.\n    \"\"\"\n    bounds = [0, 15]\n\n    x = np.linspace(bounds[0], bounds[1], n_points)\n\n    f = np.sin(x)\n    std = 0.01 + np.abs(x - 5.0) / 10.0\n    noise = np.random.normal(scale=std)\n    y = f + noise\n    return f, std, y, x\n\n_, _, y, x = synthetic_sine_heteroscedastic(1000)\nx = torch.Tensor(x)\ny = torch.Tensor(y)\nx = torch.unsqueeze(x, dim=1)\ny = torch.unsqueeze(y, dim=1)\n#| include: false\nfig, ax = plt.subplots(figsize=(5,5))\nax.scatter(x.data.numpy(),y.data.numpy())\nax.axis('equal')\nax.set_xlabel('$x$')\nax.set_ylabel('$y$')\nax.axis(\"equal\")\n\n\n\n\n\n\n\n\n# this is one way to define a network\nclass Net(torch.nn.Module):\n    def __init__(self, n_feature, n_hidden, n_output):\n        super(Net, self).__init__()\n        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n\n    def forward(self, x):\n        x = F.relu(self.hidden(x))      # activation function for hidden layer\n        x = self.predict(x)             # linear output\n        return x\n\n# this is one way to define a network\nclass GaussianNet(torch.nn.Module):\n    def __init__(self, n_feature, n_hidden, n_output):\n        super(GaussianNet, self).__init__()\n        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n        self.variance = torch.nn.Linear(n_hidden, 1)   # variance layer\n\n    def forward(self, x):\n        x = F.relu(self.hidden(x))      # activation function for hidden layer\n        out = self.predict(x)             # linear output\n        var = F.softplus(self.variance(x))\n\n        return out, var\n\nclass GeneralNet(torch.nn.Module):\n    def __init__(self, n_feature, n_hidden, n_output):\n        super(GeneralNet, self).__init__()\n        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n        self.variance = torch.nn.Linear(n_hidden, 1)   # variance layer\n\n    def forward(self, x):\n        x = F.relu(self.hidden(x))      # activation function for hidden layer\n        out = self.predict(x)             # linear output\n        var = F.softplus(self.variance(x))\n\n        return out, var\n\n\ndef variable_l2_loss(input, target, scale, eps=1e-06, reduction='none'): \n  \n  # Inputs and targets much have same shape\n  input = input.view(input.size(0), -1)\n  target = target.view(target.size(0), -1)\n  if input.size() != target.size():\n      raise ValueError(\"input and target must have same size\")\n\n  # Second scale of scale must match that of input or be equal to 1\n  scale = scale.view(input.size(0), -1)\n  if scale.size(1) != scale.size(1) and scale.size(1) != 1:\n      raise ValueError(\"scale is of incorrect size\")\n\n\n\n  # Check validity of reduction mode\n  if reduction != 'none' and reduction != 'mean' and reduction != 'sum':\n      raise ValueError(reduction + \" is not valid\")\n\n  # Entries of var must be non-negative\n  if torch.any(scale &lt; 0):\n      raise ValueError(\"scale has negative entry/entries\")\n  \n\n  # Clamp for stability\n  scale = scale.clone()\n  with torch.no_grad():\n      scale.clamp_(min=eps)\n\n  # Calculate loss (without constant)\n  #loss = (torch.log(2*scale) + torch.abs(input - target) / scale).view(input.size(0), -1).sum(dim=1)\n  #loss = (torch.abs(input - target)/alpha)**beta - torch.log(beta) + torch.log(2 * alpha ) + torch.lgamma(1/beta)\n  loss = torch.abs(input - target)**scale + (1/scale)\n\n\n  # Apply reduction\n  if reduction == 'mean':\n      return loss.mean()\n  elif reduction == 'sum':\n      return loss.sum()\n  else:\n      return loss\n\n\nmse_loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n# Fit a linear regression using mean squared error.\nregression_mse = Net(n_feature=1, n_hidden=100, n_output=1)     # RegressionModel() \nparams_mse = regression_mse.parameters()\noptimizer_mse = torch.optim.Adam(params_mse, lr = 0.01) \n\n\ngaussian_loss_func = torch.nn.GaussianNLLLoss( reduction='none')\n# Fit a linear regression using mean squared error.\nregression_gaussian = GaussianNet(n_feature=1, n_hidden=100, n_output=1)     # RegressionModel() \nparams_gaussian = regression_gaussian.parameters()\noptimizer_gaussian = torch.optim.Adam(params_gaussian, lr = 0.01) \n\n\nvariable_l2_loss_func = variable_l2_loss\n# Fit a linear regression using mean squared error.\nregression_general_l2 = GeneralNet(n_feature=1, n_hidden=100, n_output=1)     # RegressionModel() \nparams_general_l2 = regression_general_l2.parameters()\noptimizer_general_l2 = torch.optim.Adam(params_general_l2, lr = 0.001) \n\n\n\ntensor(4.7806, grad_fn=&lt;MeanBackward0&gt;) tensor(10.1017, grad_fn=&lt;MeanBackward0&gt;) tensor(2.3542, grad_fn=&lt;MeanBackward0&gt;)\ntensor(0.5944, grad_fn=&lt;MeanBackward0&gt;) tensor(0.1780, grad_fn=&lt;MeanBackward0&gt;) tensor(1.1948, grad_fn=&lt;MeanBackward0&gt;)\ntensor(0.5886, grad_fn=&lt;MeanBackward0&gt;) tensor(0.0654, grad_fn=&lt;MeanBackward0&gt;) tensor(1.0119, grad_fn=&lt;MeanBackward0&gt;)\ntensor(0.5829, grad_fn=&lt;MeanBackward0&gt;) tensor(0.0503, grad_fn=&lt;MeanBackward0&gt;) tensor(0.9445, grad_fn=&lt;MeanBackward0&gt;)\ntensor(0.5728, grad_fn=&lt;MeanBackward0&gt;) tensor(0.0434, grad_fn=&lt;MeanBackward0&gt;) tensor(0.9182, grad_fn=&lt;MeanBackward0&gt;)\ntensor(0.5582, grad_fn=&lt;MeanBackward0&gt;) tensor(0.0369, grad_fn=&lt;MeanBackward0&gt;) tensor(0.8804, grad_fn=&lt;MeanBackward0&gt;)\ntensor(0.5438, grad_fn=&lt;MeanBackward0&gt;) tensor(0.0179, grad_fn=&lt;MeanBackward0&gt;) tensor(0.8553, grad_fn=&lt;MeanBackward0&gt;)\ntensor(0.5342, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.0407, grad_fn=&lt;MeanBackward0&gt;) tensor(0.8333, grad_fn=&lt;MeanBackward0&gt;)\ntensor(0.5288, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.0420, grad_fn=&lt;MeanBackward0&gt;) tensor(0.8110, grad_fn=&lt;MeanBackward0&gt;)\ntensor(0.5260, grad_fn=&lt;MeanBackward0&gt;) tensor(0.0536, grad_fn=&lt;MeanBackward0&gt;) tensor(0.7905, grad_fn=&lt;MeanBackward0&gt;)\ntensor(0.5264, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.2751, grad_fn=&lt;MeanBackward0&gt;) tensor(0.7712, grad_fn=&lt;MeanBackward0&gt;)\ntensor(0.5363, grad_fn=&lt;MeanBackward0&gt;) tensor(0.3244, grad_fn=&lt;MeanBackward0&gt;) tensor(0.7525, grad_fn=&lt;MeanBackward0&gt;)\ntensor(0.5303, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.3814, grad_fn=&lt;MeanBackward0&gt;) tensor(0.7339, grad_fn=&lt;MeanBackward0&gt;)\ntensor(0.5411, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.2992, grad_fn=&lt;MeanBackward0&gt;) tensor(0.7150, grad_fn=&lt;MeanBackward0&gt;)\ntensor(0.5225, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.3933, grad_fn=&lt;MeanBackward0&gt;) tensor(0.6959, grad_fn=&lt;MeanBackward0&gt;)\ntensor(0.5224, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.3989, grad_fn=&lt;MeanBackward0&gt;) tensor(0.6768, grad_fn=&lt;MeanBackward0&gt;)\ntensor(0.5394, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.3629, grad_fn=&lt;MeanBackward0&gt;) tensor(0.6579, grad_fn=&lt;MeanBackward0&gt;)\ntensor(0.5221, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.4028, grad_fn=&lt;MeanBackward0&gt;) tensor(0.6395, grad_fn=&lt;MeanBackward0&gt;)\ntensor(0.5540, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.4063, grad_fn=&lt;MeanBackward0&gt;) tensor(0.6217, grad_fn=&lt;MeanBackward0&gt;)\ntensor(0.5220, grad_fn=&lt;MeanBackward0&gt;) tensor(-0.3800, grad_fn=&lt;MeanBackward0&gt;) tensor(0.6046, grad_fn=&lt;MeanBackward0&gt;)"
  },
  {
    "objectID": "posts/notebooks/2023-02-08-fibonacci-sequence-non-recursive-formula.html#generalizing-the-fibonacci-equation",
    "href": "posts/notebooks/2023-02-08-fibonacci-sequence-non-recursive-formula.html#generalizing-the-fibonacci-equation",
    "title": "Fibonacci Sequence: Non Recursive Formula",
    "section": "Generalizing the Fibonacci equation",
    "text": "Generalizing the Fibonacci equation\nWe generalize the Fibonnacci equation, by parametrizing the golden ratio and the conjugate of the golden ratio.\n\n# Generalized Fibonacci Equation\n\ng, n = sym.symbols('g, n')\n\ngolden_ratio = (1 + g**0.5 )/2\nconjugate_golden_ratio = (1 - g**0.5 )/2\nfibonacci = (sym.Pow(golden_ratio, n)  - sym.Pow(abs(conjugate_golden_ratio),n)) / (golden_ratio - conjugate_golden_ratio)\nfibonacci\n\n\n\n\n\nComparing with the exponential equation\nBased on the generalized fibonacci equation, we would like to find if we can can get an approximate of the exponential equation\n\n#symplot.plot(fibonacci.subs(g, 4), (n,0,10), show=True, line_color='darkgreen')\n\n\ngraphs= sym.plotting.plot(fibonacci.subs(g, 35), fibonacci.subs(g, 34),fibonacci.subs(g, 33), sym.exp(n),  (n,0,8), title=\"Fibonacci\", legend= True, xlabel='n', ylabel='f(x)', show=False)\n\n\nfor i, graph in enumerate(graphs):\n graph.line_color=color[i%len(color)]\n\ngraphs.show()\n\n\n\n\n\n\nComparing with the exponential equation (region [0 - 1])\n\n#symplot.plot(fibonacci.subs(g, 4), (n,0,10), show=True, line_color='darkgreen')\n\n\ngraphs= sym.plotting.plot(fibonacci.subs(g, 35), fibonacci.subs(g, 34),fibonacci.subs(g, 33), sym.exp(n),  (n,0,1), title=\"Fibonacci\", legend= True, xlabel='n', ylabel='f(x)', show=False)\n\n\nfor i, graph in enumerate(graphs):\n graph.line_color=color[i%len(color)]\n\ngraphs.show()"
  },
  {
    "objectID": "posts/notebooks/2023-02-08-fibonacci-sequence-non-recursive-formula.html#observations",
    "href": "posts/notebooks/2023-02-08-fibonacci-sequence-non-recursive-formula.html#observations",
    "title": "Fibonacci Sequence: Non Recursive Formula",
    "section": "Observations",
    "text": "Observations\n\nThe constant if less than 1 then it inverts\nIf constant is 1 then the equation is flat\nHigher the constant higher the slope\n\n\ngraphs= sym.plotting.plot(sym.exp(n), 2**n, 0.1**n,1**n,2.3**n,2.67**n,(n,0.0,1), title=\"Exponential\", legend= True, xlabel='n', ylabel='f(x)', show=False)\n\n\nfor i, graph in enumerate(graphs):\n graph.line_color=color[i%len(color)]\n\ngraphs.show()"
  },
  {
    "objectID": "posts/notebooks/2023-02-08-fibonacci-sequence-non-recursive-formula.html#converting-the-power-equation-to-loss-function",
    "href": "posts/notebooks/2023-02-08-fibonacci-sequence-non-recursive-formula.html#converting-the-power-equation-to-loss-function",
    "title": "Fibonacci Sequence: Non Recursive Formula",
    "section": "Converting the power equation to loss function",
    "text": "Converting the power equation to loss function\n\nInoder to the make the loss function, for higher slope lines the loss at zero should be lesser\nso the highest slope equation should have lowest loss\nThis is achieved by adding the inverse of the constant to the loss\n\n\\[ f(n) = constant^{n} + \\frac{1}{constant} \\]\n\nn, x = sym.symbols('n, x')\nloss = n**x + 1/n \n\n#n hasto be grater than 1 \n\ngraphs = sym.plotting.plot(loss.subs(n,1.),\n                          loss.subs(n,1.5),\n                          loss.subs(n,2.),\n                          loss.subs(n,3.),\n                          loss.subs(n,4.),\n                          loss.subs(n,10.),\n                          (x,-1,1), title=\"Power Los\", legend= True, xlabel='x', ylabel='f(x)', show=False)\n\nfor i, graph in enumerate(graphs):\n graph.line_color=color[i%len(color)]\n\ngraphs.show()"
  },
  {
    "objectID": "posts/markdown/2021-08-08-Neurips-Competition-Uncertainty.html",
    "href": "posts/markdown/2021-08-08-Neurips-Competition-Uncertainty.html",
    "title": "Neurips Competition Uncertainty Estimation",
    "section": "",
    "text": "I am participating in the Neurips Bayesian Deep Learning Competition, I will like to journal my notes here\n\n\nBroad idea is to use Evidential loss function, Dropout, TTA combination.\n\n\n\n\n8th August\n\nWorking in superconvergence\n\n13th August\n\nRoll back to pytorch-cifar and modifications\n\n14th August\n\nTraining on evidential loss reaches only 83% accuracy in 300 epochs.\nWhy is evidental loss reducing the accuracy\n\n15th August\n\nTraining with CE, AdamW, OnecylceLR? Can we improve training speed.\n\n17th August\n\nDirichlet loss function.\n\n18th August\n\nDirichlet + Mixup : best results, touched 90%\n\n\n\n\n\n\nSuper Convergence\n\ncifar10, pytorchdata, cifar training, wideresenet, 92 accuracy\n\nPytorch Cifar SOA\n\npytorch cifar10, all models,\n\nMixup\n\npytorch mixup data combining while training\n\n\n\n\n\n\n\n\nModel\ndata\ncriterion\noptim\nscheduler\nepochs\naccuracy\nlink\nNotes\n\n\n\n\nResnet18\npytorch\ncross-entropy\nSGD\nannealing-200\n200\n94\n1\n\n\n\nResnet20\npytorch\ncross-entropy\nSGD\nannealing-200\n200\n89\n1\n\n\n\nResnet20\ntf\ncross-entropy\nSGD\nannealing-200\n200\n90\n1\n\n\n\nResnet20\ntf\nEvidential\nSGD\nannealing-200\n600\n73/??/83\n1\nAdded randmErasing\n\n\nResnet20\ntf\nLabel smooting\nSGD\nannealing-200\n200\n\n??\n??\n\n\nResent20\ntf\ncross-entropy\nAdamW\n1 cycle\n30\n83\n1\n\n\n\nResnet20\ntf\ncross-entropy\nAdamW\n1 cycle\n100\n88\n1\nmax_lr = 0.01\n\n\nResnet20\ntf\ncross-entropy\nAdamW\n1 cycle\n30\n50\n1\nmax_lr=0.1\n\n\nResnet20\ntf\ncross-entropy\nAdamW\n1 cycle\n30\n80\n1\nmax_lr=0.05\n\n\nResnet20\ntf\nEvidential\nAdamW\n1 cycle\n30\n69\n1\nmax_lr=0.05\n\n\nResnet20\ntf\nEvidential\nAdamW\nannealing-200\n200\n75\n1\nmax_lr=0.01\n\n\nResnet20\ntf\ncross-entropy\nAdamW\n1 cycle\n200\n89\n1\nmax_lr = 0.05\n\n\nResnet20\ntf\ncross-entropy\nAdamW\n1 cycle\n200\n89\n1\nmax_lr = 0.05, randomErase"
  },
  {
    "objectID": "posts/markdown/2021-08-08-Neurips-Competition-Uncertainty.html#idea",
    "href": "posts/markdown/2021-08-08-Neurips-Competition-Uncertainty.html#idea",
    "title": "Neurips Competition Uncertainty Estimation",
    "section": "",
    "text": "Broad idea is to use Evidential loss function, Dropout, TTA combination."
  },
  {
    "objectID": "posts/markdown/2021-08-08-Neurips-Competition-Uncertainty.html#journal",
    "href": "posts/markdown/2021-08-08-Neurips-Competition-Uncertainty.html#journal",
    "title": "Neurips Competition Uncertainty Estimation",
    "section": "",
    "text": "8th August\n\nWorking in superconvergence\n\n13th August\n\nRoll back to pytorch-cifar and modifications\n\n14th August\n\nTraining on evidential loss reaches only 83% accuracy in 300 epochs.\nWhy is evidental loss reducing the accuracy\n\n15th August\n\nTraining with CE, AdamW, OnecylceLR? Can we improve training speed.\n\n17th August\n\nDirichlet loss function.\n\n18th August\n\nDirichlet + Mixup : best results, touched 90%"
  },
  {
    "objectID": "posts/markdown/2021-08-08-Neurips-Competition-Uncertainty.html#reference",
    "href": "posts/markdown/2021-08-08-Neurips-Competition-Uncertainty.html#reference",
    "title": "Neurips Competition Uncertainty Estimation",
    "section": "",
    "text": "Super Convergence\n\ncifar10, pytorchdata, cifar training, wideresenet, 92 accuracy\n\nPytorch Cifar SOA\n\npytorch cifar10, all models,\n\nMixup\n\npytorch mixup data combining while training"
  },
  {
    "objectID": "posts/markdown/2021-08-08-Neurips-Competition-Uncertainty.html#pytorch-cifar",
    "href": "posts/markdown/2021-08-08-Neurips-Competition-Uncertainty.html#pytorch-cifar",
    "title": "Neurips Competition Uncertainty Estimation",
    "section": "",
    "text": "Model\ndata\ncriterion\noptim\nscheduler\nepochs\naccuracy\nlink\nNotes\n\n\n\n\nResnet18\npytorch\ncross-entropy\nSGD\nannealing-200\n200\n94\n1\n\n\n\nResnet20\npytorch\ncross-entropy\nSGD\nannealing-200\n200\n89\n1\n\n\n\nResnet20\ntf\ncross-entropy\nSGD\nannealing-200\n200\n90\n1\n\n\n\nResnet20\ntf\nEvidential\nSGD\nannealing-200\n600\n73/??/83\n1\nAdded randmErasing\n\n\nResnet20\ntf\nLabel smooting\nSGD\nannealing-200\n200\n\n??\n??\n\n\nResent20\ntf\ncross-entropy\nAdamW\n1 cycle\n30\n83\n1\n\n\n\nResnet20\ntf\ncross-entropy\nAdamW\n1 cycle\n100\n88\n1\nmax_lr = 0.01\n\n\nResnet20\ntf\ncross-entropy\nAdamW\n1 cycle\n30\n50\n1\nmax_lr=0.1\n\n\nResnet20\ntf\ncross-entropy\nAdamW\n1 cycle\n30\n80\n1\nmax_lr=0.05\n\n\nResnet20\ntf\nEvidential\nAdamW\n1 cycle\n30\n69\n1\nmax_lr=0.05\n\n\nResnet20\ntf\nEvidential\nAdamW\nannealing-200\n200\n75\n1\nmax_lr=0.01\n\n\nResnet20\ntf\ncross-entropy\nAdamW\n1 cycle\n200\n89\n1\nmax_lr = 0.05\n\n\nResnet20\ntf\ncross-entropy\nAdamW\n1 cycle\n200\n89\n1\nmax_lr = 0.05, randomErase"
  },
  {
    "objectID": "posts/markdown/2022-05-13-LerningProbabilityForApplication.html",
    "href": "posts/markdown/2022-05-13-LerningProbabilityForApplication.html",
    "title": "Learning Probability for Application",
    "section": "",
    "text": "Context\nProbabilities are required for solving different problems. Which are these problems? What is the commanalities amongst them? How to use proability as a tool to understand the application of it?\n\n\nWeek 1 : Why Probability ?\n\nDeterminism vs stocastic\nHow to represent information in code when we dont know the correct answer?\n\n(Need a good example here)\n\nProbability distributions\n\n\n\nWeek 2 : Conditional Probability, Likelihod, Prior and Posterior\n\nExamples of conditional probability ?\nExamples of Prior\nWhat is likelihood ?\n\nDifference with probability ?"
  },
  {
    "objectID": "posts/markdown/2020-07-22-Learning-DNN.html",
    "href": "posts/markdown/2020-07-22-Learning-DNN.html",
    "title": "DNN Wiki",
    "section": "",
    "text": "I wanted to develop glossary/Wiki of DNN related topics and my explanation of them so that I can be sure that I know the topics. But for that I needed a list of relevant topics. DNN is an exponentially exploding field and with low signa to noise ratio. So it becomes really difficult in fooling up with the new work without having a firm understanding of what is firm knowledge. This selection of topics should help any new commer to be sure that if I know what these topics are then you can claim that you know a little about deep learning.\n\nDeep Learning vs Other Machine Learning Approaches\nThe Essential Math of Artificial Neurons\nThe Essential Math of Neural Networks\nActivation Functions\nCost/Loss Functions\nStochastic Gradient Descent\nBackpropagation\nMini-Batches\nLearning Rate\nOptimizers (e.g., Adam, Nadam)\nGlorot/He Weight Initialization\nDense Layers\nSoftmax Layers\nDropout\nData Augmentation\n\n\n\n\nhttps://aiplus.odsc.com/courses/deep-learning-with-tensorflow-2-and-pytorch-1"
  },
  {
    "objectID": "posts/markdown/2020-07-22-Learning-DNN.html#references",
    "href": "posts/markdown/2020-07-22-Learning-DNN.html#references",
    "title": "DNN Wiki",
    "section": "",
    "text": "https://aiplus.odsc.com/courses/deep-learning-with-tensorflow-2-and-pytorch-1"
  },
  {
    "objectID": "posts/markdown/2020-05-29-Explanation-DNN-Reliability.html",
    "href": "posts/markdown/2020-05-29-Explanation-DNN-Reliability.html",
    "title": "Reliability in DNN systems(WIP)",
    "section": "",
    "text": "Sub-system(DNN) and System(using DNN)\nAccording to [2] reliability is : - Failure prevention - Failure identificaiton - Reliability monitoring"
  },
  {
    "objectID": "posts/markdown/2020-05-29-Explanation-DNN-Reliability.html#reliability-modelling-framework",
    "href": "posts/markdown/2020-05-29-Explanation-DNN-Reliability.html#reliability-modelling-framework",
    "title": "Reliability in DNN systems(WIP)",
    "section": "Reliability modelling framework",
    "text": "Reliability modelling framework\n\nreliability is expressed as the probability of not failing on a randomly chosen input \\(d_r ∈ D\\). Let F be a random variable (r.v.) that represents this probability. The service reliability then can be expressed via the r.v. R = 1 − F."
  },
  {
    "objectID": "posts/markdown/2020-05-29-Explanation-DNN-Reliability.html#big-idea",
    "href": "posts/markdown/2020-05-29-Explanation-DNN-Reliability.html#big-idea",
    "title": "Reliability in DNN systems(WIP)",
    "section": "Big Idea",
    "text": "Big Idea\nThe main idea of the paper [3] is the Operational Profile , which basically separates the input data space into multiple subset. The subset can be additional to the classes in the dataset."
  },
  {
    "objectID": "posts/markdown/2021-04-13-how-to-use-uncertainty-estimate-from-dnn.html",
    "href": "posts/markdown/2021-04-13-how-to-use-uncertainty-estimate-from-dnn.html",
    "title": "Using uncertainties in DNN application",
    "section": "",
    "text": "We would like to look into two papers which have developed methodologies to use the uncertatiny estimated by the deep neural network(DNN) in their system. The goal is to find the pros and cons of these methodologies\n\n\n\nIn this paper they propose two new Safety-Related Metrics: Remaining Error Rate(RER) and Remaining Accuracy Rate(Rate). Here is definition as per the paper: &gt; A system which relies on these estimates is expected to be in functional mode if the predictions are certain and in fall-back/mitigation mode if the prediction is uncertain. However, the most critical result regarding safety are the predictions where the model is certain about its prediction but incorrect (CI). We call the ratio of the number of certain but incorrect samples to all samples the Remaining Error Rate (RER). For minimizing the overall risk, it needs to be as low as possible. Nonetheless, if a model would always give a low confidence as output, the system would constantly remain in fall-back mode and will be unable to provide the intended functionality. Therefore, the ratio of the number of certain and correct samples to all samples - we call it the Remaining Accuracy Rate (RAR) - needs to be as high as possible to stay in performance mode for most of the time.\n\n\nThe predictions from the DNN are classified into 4 sections as below (Table 1 from paper)\n\n\n\n\nCertain\nUncertain\n\n\n\n\nCorrect\nCC\nUC\n\n\nIncorrect\nCI\nUI\n\n\n\nThe definition of the metrics are :\n\\(RER = \\frac{CI}{CC+CI+UC+UI}\\) \\(RAR = \\frac{CC}{CC+CI+UC+UI}\\)\n\n\n\nIts a very simple metric.\nSimplicity of metric is a very important thing for usability of metrics.\n\n\n\n\n\nA minor issue will be on the threshold which seprates Certain vs Uncertain. Is it 99% or 90% etc. All will yield different results\nA major problem which we consider is the assumption in which the uncertatiny is being planned to be used in the system. &gt; A system which relies on these estimates is expected to be in functional mode if the predictions are certain and in fall-back/mitigation mode if the prediction is uncertain.\nThis means that the system has 2 modes\n\nA functional mode\nA fall-back/mitigation mode\n\nIs this a safe assumption with regards to deployment of DNN?\nCan an application deploying DNN have 2 modes ?\nWhat should an autonomous car in fall-back mode do ?\n\n:bangbang: | The assumption on how a system uses uncertatiny is that the system has 2 modes functional and fall-back | :-: | :- |\n\n\n\n\n\n\nIn this paper, as the title suggests they create a separate model called the Supervisor Model which will monitor the uncertainty of Deep learning and avoid any faults in the system\nWhat is a supervisor model : &gt; Network supervision can be viewed as a binary classification task: malicious samples, i.e., inputs which lead to a misclassification &gt; (for classification problems) or to severe imprecision (in regression problems) are positive samples that have to be rejected. Other samples, also called benign samples, are negative samples in the binary classification task. An uncertainty based supervisor accepts an input i as a benign sample if its uncertainty u(i) is lower than some threshold t. The choice of t is a crucial setting, as a high t will fail to reject many malicious samples (false negatives) and a low t will cause too many false alerts (false positives).\nThus the supervisor is a binary classification task to avoid beningn samples. They also define a metric S-Score which combined measures the performance of both the model and the supervisor model\nThere is lot of similarity with respect to the above paper here also\n\n\n\n\nThey have made a library out of it such that any model can be used.\nThe threshold on which to make the decission is now being learned by the data.\n\n\n\n\n\nAgain, these method is based on the assumption that the system which uses DNN has 2 modes of operation( normal mode and fall-back mode)\n\n:bangbang: | The same assumption on how a system uses uncertatiny, that the system has 2 modes functional and fall-back | :—: | :— |\n\n\n\n\n\nAll methods are based on the assumption that the system has 2 modes of operation\nThe uncertatiny estimation is used to determine whethere the DNN output should be trusted or should be avoided\n\n\n\n\nThe methods which use DNN dont have a fall back mode.\n\nIf there was an non DNN based method then by “First rule of Machine/Deep Learning” that will be used for solving the problem\n\nThere can be argument to say that there are redundant DNN systems and this method can be used to kick-off redundant system\n\nEven this argument is not valid as if you have redundant system, you should use all of them and make a decision\n\n\n\n\n\n\nThe one solution which I have been workin is about not binarizing the probability but the propagating it through the system\nThe best example is of the filters which have been developed over years to handle uncertain sensors.\n\n\n\n\n\n\n[1]M. Weiss and P. Tonella, “Fail-Safe Execution of Deep Learning based Systems through Uncertainty Monitoring,” arXiv:2102.00902 [cs], Feb. 2021, Accessed: Apr. 13, 2021. [Online]. Available: http://arxiv.org/abs/2102.00902.\n[2]M. Henne, A. Schwaiger, K. Roscher, and G. Weiss, “Benchmarking Uncertainty Estimation Methods for Deep Learning With Safety-Related Metrics,” p. 8, 2020."
  },
  {
    "objectID": "posts/markdown/2021-04-13-how-to-use-uncertainty-estimate-from-dnn.html#objective",
    "href": "posts/markdown/2021-04-13-how-to-use-uncertainty-estimate-from-dnn.html#objective",
    "title": "Using uncertainties in DNN application",
    "section": "",
    "text": "We would like to look into two papers which have developed methodologies to use the uncertatiny estimated by the deep neural network(DNN) in their system. The goal is to find the pros and cons of these methodologies"
  },
  {
    "objectID": "posts/markdown/2021-04-13-how-to-use-uncertainty-estimate-from-dnn.html#paper-1-benchmarking-uncertatinty-estimation-methods-in-deep-learning-with-safety-related-metrics",
    "href": "posts/markdown/2021-04-13-how-to-use-uncertainty-estimate-from-dnn.html#paper-1-benchmarking-uncertatinty-estimation-methods-in-deep-learning-with-safety-related-metrics",
    "title": "Using uncertainties in DNN application",
    "section": "",
    "text": "In this paper they propose two new Safety-Related Metrics: Remaining Error Rate(RER) and Remaining Accuracy Rate(Rate). Here is definition as per the paper: &gt; A system which relies on these estimates is expected to be in functional mode if the predictions are certain and in fall-back/mitigation mode if the prediction is uncertain. However, the most critical result regarding safety are the predictions where the model is certain about its prediction but incorrect (CI). We call the ratio of the number of certain but incorrect samples to all samples the Remaining Error Rate (RER). For minimizing the overall risk, it needs to be as low as possible. Nonetheless, if a model would always give a low confidence as output, the system would constantly remain in fall-back mode and will be unable to provide the intended functionality. Therefore, the ratio of the number of certain and correct samples to all samples - we call it the Remaining Accuracy Rate (RAR) - needs to be as high as possible to stay in performance mode for most of the time.\n\n\nThe predictions from the DNN are classified into 4 sections as below (Table 1 from paper)\n\n\n\n\nCertain\nUncertain\n\n\n\n\nCorrect\nCC\nUC\n\n\nIncorrect\nCI\nUI\n\n\n\nThe definition of the metrics are :\n\\(RER = \\frac{CI}{CC+CI+UC+UI}\\) \\(RAR = \\frac{CC}{CC+CI+UC+UI}\\)\n\n\n\nIts a very simple metric.\nSimplicity of metric is a very important thing for usability of metrics.\n\n\n\n\n\nA minor issue will be on the threshold which seprates Certain vs Uncertain. Is it 99% or 90% etc. All will yield different results\nA major problem which we consider is the assumption in which the uncertatiny is being planned to be used in the system. &gt; A system which relies on these estimates is expected to be in functional mode if the predictions are certain and in fall-back/mitigation mode if the prediction is uncertain.\nThis means that the system has 2 modes\n\nA functional mode\nA fall-back/mitigation mode\n\nIs this a safe assumption with regards to deployment of DNN?\nCan an application deploying DNN have 2 modes ?\nWhat should an autonomous car in fall-back mode do ?\n\n:bangbang: | The assumption on how a system uses uncertatiny is that the system has 2 modes functional and fall-back | :-: | :- |"
  },
  {
    "objectID": "posts/markdown/2021-04-13-how-to-use-uncertainty-estimate-from-dnn.html#paper-2-fail-safe-execution-of-deep-learning-based-systems-through-uncertatiny-monitoring",
    "href": "posts/markdown/2021-04-13-how-to-use-uncertainty-estimate-from-dnn.html#paper-2-fail-safe-execution-of-deep-learning-based-systems-through-uncertatiny-monitoring",
    "title": "Using uncertainties in DNN application",
    "section": "",
    "text": "In this paper, as the title suggests they create a separate model called the Supervisor Model which will monitor the uncertainty of Deep learning and avoid any faults in the system\nWhat is a supervisor model : &gt; Network supervision can be viewed as a binary classification task: malicious samples, i.e., inputs which lead to a misclassification &gt; (for classification problems) or to severe imprecision (in regression problems) are positive samples that have to be rejected. Other samples, also called benign samples, are negative samples in the binary classification task. An uncertainty based supervisor accepts an input i as a benign sample if its uncertainty u(i) is lower than some threshold t. The choice of t is a crucial setting, as a high t will fail to reject many malicious samples (false negatives) and a low t will cause too many false alerts (false positives).\nThus the supervisor is a binary classification task to avoid beningn samples. They also define a metric S-Score which combined measures the performance of both the model and the supervisor model\nThere is lot of similarity with respect to the above paper here also\n\n\n\n\nThey have made a library out of it such that any model can be used.\nThe threshold on which to make the decission is now being learned by the data.\n\n\n\n\n\nAgain, these method is based on the assumption that the system which uses DNN has 2 modes of operation( normal mode and fall-back mode)\n\n:bangbang: | The same assumption on how a system uses uncertatiny, that the system has 2 modes functional and fall-back | :—: | :— |"
  },
  {
    "objectID": "posts/markdown/2021-04-13-how-to-use-uncertainty-estimate-from-dnn.html#conclusion",
    "href": "posts/markdown/2021-04-13-how-to-use-uncertainty-estimate-from-dnn.html#conclusion",
    "title": "Using uncertainties in DNN application",
    "section": "",
    "text": "All methods are based on the assumption that the system has 2 modes of operation\nThe uncertatiny estimation is used to determine whethere the DNN output should be trusted or should be avoided\n\n\n\n\nThe methods which use DNN dont have a fall back mode.\n\nIf there was an non DNN based method then by “First rule of Machine/Deep Learning” that will be used for solving the problem\n\nThere can be argument to say that there are redundant DNN systems and this method can be used to kick-off redundant system\n\nEven this argument is not valid as if you have redundant system, you should use all of them and make a decision\n\n\n\n\n\n\nThe one solution which I have been workin is about not binarizing the probability but the propagating it through the system\nThe best example is of the filters which have been developed over years to handle uncertain sensors."
  },
  {
    "objectID": "posts/markdown/2021-04-13-how-to-use-uncertainty-estimate-from-dnn.html#references",
    "href": "posts/markdown/2021-04-13-how-to-use-uncertainty-estimate-from-dnn.html#references",
    "title": "Using uncertainties in DNN application",
    "section": "",
    "text": "[1]M. Weiss and P. Tonella, “Fail-Safe Execution of Deep Learning based Systems through Uncertainty Monitoring,” arXiv:2102.00902 [cs], Feb. 2021, Accessed: Apr. 13, 2021. [Online]. Available: http://arxiv.org/abs/2102.00902.\n[2]M. Henne, A. Schwaiger, K. Roscher, and G. Weiss, “Benchmarking Uncertainty Estimation Methods for Deep Learning With Safety-Related Metrics,” p. 8, 2020."
  },
  {
    "objectID": "posts/markdown/2020-05-29-Explanation-DNN-Uncertainty.html",
    "href": "posts/markdown/2020-05-29-Explanation-DNN-Uncertainty.html",
    "title": "Different types of uncertainty in DNN systems?",
    "section": "",
    "text": "This question is easily answered if you have read a little bit of DNN literature. The most popular answer is - Aleatoric uncertainty - Epistemic uncertainty\nAn additional statement is always added to these different types of uncertainty which will claim that - Aleatoric uncertatinty is model uncertainty - Epistemic uncertatinty is data uncertainty\nBut what actually are these values and what do they explain ? Lets do a brief overview of different literature to answer these questions."
  },
  {
    "objectID": "posts/markdown/2020-05-29-Explanation-DNN-Uncertainty.html#references",
    "href": "posts/markdown/2020-05-29-Explanation-DNN-Uncertainty.html#references",
    "title": "Different types of uncertainty in DNN systems?",
    "section": "References",
    "text": "References\n[1] Probability is Perfect, but we Can’t Elicitit Perfectly Anthony O’Hagan & Jeremy E. Oakley http://www.yaroslavvb.com/papers/epistemic.pdf\n[2] Challenge problems: uncertainty in system response given uncertain parameters Author links open overlay panelWilliam L.Oberkam https://www.sciencedirect.com/science/article/pii/S0951832004000493"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "devblog",
    "section": "",
    "text": "Uncertain Data types - Sampling based Bayes-Laplace Rule\n\n\n\n\n\nPython class for uncertain datatype\n\n\n\n\n\n\nJan 9, 2024\n\n\nDeebul Nair\n\n\n\n\n\n\n  \n\n\n\n\nRepresentation and propagation of uncertainty\n\n\n\n\n\nUncertainty representation in Robotics\n\n\n\n\n\n\nAug 25, 2023\n\n\nDeebul Nair\n\n\n\n\n\n\n  \n\n\n\n\nNon-Linear System Definitions - Application Kalman Filter\n\n\n\n\n\nExamples of non-linear systems\n\n\n\n\n\n\nAug 21, 2023\n\n\nDeebul Nair\n\n\n\n\n\n\n  \n\n\n\n\nFOMO - Embedded Image Segmentation Pytorch Model\n\n\n\n\n\nPytorch Implementation of FOMO model form Edge Impulse\n\n\n\n\n\n\nJun 16, 2023\n\n\nDeebul Nair\n\n\n\n\n\n\n  \n\n\n\n\nIntroduction To Statistical Testing\n\n\n\n\n\n\n\n\n\n\n\n\nJun 15, 2023\n\n\nDeebul Nair\n\n\n\n\n\n\n  \n\n\n\n\nFFMPEG - Automating video edition\n\n\n\n\n\nffmpeg different commands\n\n\n\n\n\n\nApr 29, 2023\n\n\n\n\n\n\n  \n\n\n\n\nBayesian Networks ? What and Why\n\n\n\n\n\nBrief Explanation of Bayesian Network\n\n\n\n\n\n\nApr 12, 2023\n\n\n\n\n\n\n  \n\n\n\n\nNeural Linear Model (aka Gaussian Process)\n\n\n\n\n\n\n\n\n\n\n\n\nMar 9, 2023\n\n\nDeebul Nair\n\n\n\n\n\n\n  \n\n\n\n\nDerivative of different Deep Neural Networks loss functions\n\n\n\n\n\nMSE loss, logistic regression, softmax regression\n\n\n\n\n\n\nMar 1, 2023\n\n\nDeebul Nair\n\n\n\n\n\n\n  \n\n\n\n\nBhattacharya Distance: Dirichlet and Multinomial distribution\n\n\n\n\n\nDerivation and Code\n\n\n\n\n\n\nFeb 28, 2023\n\n\nDeebul Nair\n\n\n\n\n\n\n  \n\n\n\n\nBuilding AI and Sustainability Solutions on SAP BTP\n\n\n\n\n\nCertification\n\n\n\n\n\n\nFeb 24, 2023\n\n\n\n\n\n\n  \n\n\n\n\nApproximating Cauchy with Gaussian: Boxcox transformation\n\n\n\n\n\nBoxcox transformation\n\n\n\n\n\n\nFeb 14, 2023\n\n\nDeebul Nair\n\n\n\n\n\n\n  \n\n\n\n\nFibonacci Sequence: Non Recursive Formula\n\n\n\n\n\nPlots and comparison to Exponential and notes on Power equations\n\n\n\n\n\n\nFeb 8, 2023\n\n\nDeebul Nair\n\n\n\n\n\n\n  \n\n\n\n\nGeneral loss fuction: L1, L2, L3 …\n\n\n\n\n\nLinear, Quadratic, Cubic\n\n\n\n\n\n\nJan 26, 2023\n\n\nDeebul Nair\n\n\n\n\n\n\n  \n\n\n\n\nError Correcting Output codes - Why one-hot encoding is prone to attack\n\n\n\n\n\nPaper reading\n\n\n\n\n\n\nJan 26, 2023\n\n\nDeebul Nair\n\n\n\n\n\n\n  \n\n\n\n\nGeneralized Gaussian Distribution: Uncertainty Estimation for Regression with Outlier(Noisy) Labels\n\n\n\n\n\nGeneralized Gaussian Distribution/Exponential Power Distribution\n\n\n\n\n\n\nJan 22, 2023\n\n\nDeebul Nair\n\n\n\n\n\n\n  \n\n\n\n\nExponential Power Distribution: PDF and NLL Visualization\n\n\n\n\n\nGeneralized Gaussian Distribution\n\n\n\n\n\n\nJan 17, 2023\n\n\nDeebul Nair\n\n\n\n\n\n\n  \n\n\n\n\nQuantization of Pytorch Models\n\n\n\n\n\nDifferent types of quantization\n\n\n\n\n\n\nJan 17, 2023\n\n\nMohan Raj, Deebul Nair\n\n\n\n\n\n\n  \n\n\n\n\nMigrating Kelo Tulip to ROS2\n\n\n\n\n\nMigrating Kelo Tulip to ROS2\n\n\n\n\n\n\nJan 13, 2023\n\n\n\n\n\n\n  \n\n\n\n\nDis-entaglement of Epistemic and Aleatoric uncertainty for Dirichlet Distribution\n\n\n\n\n\nAnalysis\n\n\n\n\n\n\nDec 19, 2022\n\n\nDeebul Nair\n\n\n\n\n\n\n  \n\n\n\n\nComparing Distributions : Normal, Laplace and Cauchy\n\n\n\n\n\nInterval score based distribution comparison\n\n\n\n\n\n\nDec 15, 2022\n\n\nDeebul Nair\n\n\n\n\n\n\n  \n\n\n\n\nRunning ros2 humble in ubuntu lxd container\n\n\n\n\n\nRunning ros2 humble in ubuntu lxd container\n\n\n\n\n\n\nOct 20, 2022\n\n\n\n\n\n\n  \n\n\n\n\nCompile Latex file using Github Action\n\n\n\n\n\nCompile Latex file using Github Action\n\n\n\n\n\n\nJun 25, 2022\n\n\n\n\n\n\n  \n\n\n\n\nLearning Probability for Application\n\n\n\n\n\nLearning Probability for Application\n\n\n\n\n\n\nMay 13, 2022\n\n\n\n\n\n\n  \n\n\n\n\nProper Scoring Rules: Interval Score and CRPS\n\n\n\n\n\nComparison of Proper Scoring Rules\n\n\n\n\n\n\nFeb 5, 2022\n\n\nDeebul Nair\n\n\n\n\n\n\n  \n\n\n\n\nEmbedding output for Multi-class classification\n\n\n\n\n\nVisualization and Analysis\n\n\n\n\n\n\nJan 11, 2022\n\n\nDeebul Nair\n\n\n\n\n\n\n  \n\n\n\n\nFlexible Distributions as an Approach to Robustness\n\n\n\n\n\nPaper reading\n\n\n\n\n\n\nSep 21, 2021\n\n\nDeebul Nair\n\n\n\n\n\n\n  \n\n\n\n\nNeurips Competition Uncertainty Estimation\n\n\n\n\n\nNeurips Competition Summary\n\n\n\n\n\n\nAug 8, 2021\n\n\n\n\n\n\n  \n\n\n\n\nUsing uncertainties in DNN application\n\n\n\n\n\nHow to use uncertainty estimates from deep neural networks\n\n\n\n\n\n\nApr 13, 2021\n\n\n\n\n\n\n  \n\n\n\n\nOne-vs-All Classifier\n\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2021\n\n\n\n\n\n\n  \n\n\n\n\nDNN Wiki\n\n\n\n\n\nDeep Neural Network Personal Wiki\n\n\n\n\n\n\nJul 22, 2020\n\n\n\n\n\n\n  \n\n\n\n\nDifferent types of uncertainty in DNN systems?\n\n\n\n\n\nA explanation of different uncertainties in DNN\n\n\n\n\n\n\nMay 29, 2020\n\n\n\n\n\n\n  \n\n\n\n\nReliability in DNN systems(WIP)\n\n\n\n\n\nReliability of DNN\n\n\n\n\n\n\nMay 29, 2020\n\n\n\n\n\n\n  \n\n\n\n\nRegression Uncertainty\n\n\n\n\n\nLearning uncertainty for regression using higher order distribution\n\n\n\n\n\n\nMay 27, 2020\n\n\n\n\n\n\n  \n\n\n\n\nDataset shift\n\n\n\n\n\nA explanation of dataset shifts in learning problems\n\n\n\n\n\n\nMay 21, 2020\n\n\n\n\n\n\n  \n\n\n\n\nPlotting Normal Inverse Gamma Distirbution\n\n\n\n\n\nPython plot Normal Inverse Gamma Distirbution\n\n\n\n\n\n\nMay 19, 2020\n\n\n\n\n\n\n  \n\n\n\n\nRegression Uncertainty Robustness\n\n\n\n\n\n\n\n\n\n\n\n\nMay 5, 2020\n\n\n\n\n\n\n  \n\n\n\n\nLikelihood\n\n\n\n\n\nTo understand Likelihood of distributions\n\n\n\n\n\n\nMar 20, 2020\n\n\nDeebul Nair\n\n\n\n\n\n\n  \n\n\n\n\nTemplate\n\n\n\n\n\nTo understand Likelihood of distributions\n\n\n\n\n\n\nJan 1, 2020\n\n\nDeebul Nair\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m a researcher at the Bonn-Aachen International Center for Information Technology (b-it) at the Autonomous Systems group in Bonn, Germany.\nMy research focus is on developing strategies for safe and reliable incorporation of deep learning methods into robotics.\nI am also the lead develper with the b-it-bots team which won the RoboCup WorldCup and GermanOpen in the work league."
  },
  {
    "objectID": "about.html#bayespy-bayesian-python",
    "href": "about.html#bayespy-bayesian-python",
    "title": "About",
    "section": "BayesPy – Bayesian Python",
    "text": "BayesPy – Bayesian Python\nBayesPy provides tools for Bayesian inference with Python. The user constructs a model as a Bayesian network, observes data and runs posterior inference. The goal is to provide a tool which is efficient, flexible and extendable enough for expert use but also accessible for more casual users."
  },
  {
    "objectID": "about.html#b-it-bots",
    "href": "about.html#b-it-bots",
    "title": "About",
    "section": "b-it-bots",
    "text": "b-it-bots\nROS software packages of b-it-bots for different robots."
  },
  {
    "objectID": "posts/markdown/2022-10-20-ROS2-LXD-Container.html",
    "href": "posts/markdown/2022-10-20-ROS2-LXD-Container.html",
    "title": "Running ros2 humble in ubuntu lxd container",
    "section": "",
    "text": "Its always dificult to get the appropriate ubuntu version for a running a particular software. For example, currently I have ubuntu 20.04 and I want to test a software in ros2 humble. Humble requires ubuntu version 22.04. I wanted to try if we can use lxd containers for running the appropriate ubuntu version and installing ros in those.\n\n\n\nInstall lxd in your ubuntu (Using snap)\nUse Lxc to make sure its without sudo\nFor using gui inside the container we need to attach profiles to the container.\nCreate a profile using the following command\n\n$ lxc profile create x11\nProfile x11 created\n\nEdit the profile with the following command\n\n$ lxc profile edit x11\n\nCopy paste below in the editor below\n\nconfig:\n  environment.DISPLAY: :0\n  environment.PULSE_SERVER: unix:/home/ubuntu/pulse-native\n  nvidia.driver.capabilities: all\n  nvidia.runtime: \"true\"\n  user.user-data: |\n    #cloud-config\n    runcmd:\n      - 'sed -i \"s/; enable-shm = yes/enable-shm = no/g\" /etc/pulse/client.conf'\n    packages:\n      - x11-apps\n      - mesa-utils\n      - pulseaudio\ndescription: GUI LXD profile\ndevices:\n  PASocket1:\n    bind: container\n    connect: unix:/run/user/1000/pulse/native\n    listen: unix:/home/ubuntu/pulse-native\n    security.gid: \"1000\"\n    security.uid: \"1000\"\n    uid: \"1000\"\n    gid: \"1000\"\n    mode: \"0777\"\n    type: proxy\n  X0:\n    bind: container\n    connect: unix:@/tmp/.X11-unix/X1\n    listen: unix:@/tmp/.X11-unix/X0\n    security.gid: \"1000\"\n    security.uid: \"1000\"\n    type: proxy\n  mygpu:\n    type: gpu\nname: x11\nused_by: []\n\nIn the above file check the line connect: unix:@/tmp/.X11-unix/X1 This depends on how your local machine DISPLAY is set. If your local machine DISPLAY is at X1 replace there with X0.\nTo check your local machine displayecho $DISPLAY.\nNow lets create a container with the profile\n\nlxc launch ubuntu:22.04 --profile default --profile x11 mycontainer\n\nTo get a shell in the container, run the following.\n\n$ lxc exec mycontainer -- sudo --user ubuntu --login\nmycontainer $ sudo apt install xclock \nmycontainer $ export DISPLAY=:0  #Add this in bashrc\nmycontainer $ xclock\n\nThe above command will open the xclock in GUI . If the GUI doesnt come then check your local DISPLAY and the DISPLAY inside the container.\nComplete blog with explanation on the process is provided by (Simos)[https://blog.simos.info/running-x11-software-in-lxd-containers/]\n\n\n\n\n\nStarted with blog by ubuntu\nIt gets you through the installation .\n\nI created a ubuntu 22.04 container and installed ros2 inside it .\nI create a user called ubuntu\nfor ros installation I followed ros2 documentation\n\nFor using ros started ros2 tutorials\nFirst problem gui not working\n\nBlog by Nick D Greg introduced the topic of using profiles\nFollowing the blog I created a lxc profile named gui\nThe blog assumes you start from begining but since we already had the container running we used the below command\n\nlxc profile assign ros-humble default,gui\n\ninside the container ‘export DISPLAY=:0’ in the bash (also added in bashrc)\nnow gui is running\n$&gt; ros2 run turtlesim turtlesim_node\n\n\n\n\n\n\nBoot your local ubuntu and first you want to check the active containers the command is lxc list\n\n$&gt; lxc list\n+------------+---------+----------------------+-----------------------------------------------+-----------+-----------+\n|    NAME    |  STATE  |         IPV4         |                     IPV6                      |   TYPE    | SNAPSHOTS |\n+------------+---------+----------------------+-----------------------------------------------+-----------+-----------+\n| ros-humble | RUNNING | 10.171.226.72 (eth0) | fd42:13f7:78ed:7795:216:3eff:fe9c:bde9 (eth0) | CONTAINER | 0         |\n+------------+---------+----------------------+-----------------------------------------------+-----------+-----------+\n\nGetting bash access\n\n$ lxc exec ros-humble -- su --login ubuntu\nubuntu@ubuntu-container:~$ \n\n\n\nHistory of comands used insde the container, after logging\n2  apt-cache policy | grep universe\n3  sudo apt install software-properties-common\n4  sudo add-apt-repository universe\n5  sudo apt update && sudo apt install curl gnupg lsb-release\n6  sudo curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key -o /usr/share/keyrings/ros-archive-keyring.gpg\n7  echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu $(source /etc/os-release && echo $UBUNTU_CODENAME) main\" | sudo tee /etc/apt/sources.list.d/ros2.list &gt; /dev/null\n8  sudo apt update && sudo apt install -y   build-essential   cmake   git   python3-colcon-common-extensions   python3-flake8   python3-flake8-blind-except   python3-flake8-builtins   python3-flake8-class-newline   python3-flake8-comprehensions   python3-flake8-deprecated   python3-flake8-docstrings   python3-flake8-import-order   python3-flake8-quotes   python3-pip   python3-pytest   python3-pytest-cov   python3-pytest-repeat   python3-pytest-rerunfailures   python3-rosdep   python3-setuptools   python3-vcstool   wget\n9  sudo apt update\n10  sudo apt install ros-humble-desktop\n\n\n\n\nSteps in the host computer to dowload ubuntu 20 and login to the virtual machine\n\n$ lxc launch images:ubuntu/20.04 noetic\nCreating noetic\nStarting noetic  \n$ lxc list\n+------------+---------+----------------------+----------------------------------------------+-----------+-----------+\n|    NAME    |  STATE  |         IPV4         |                     IPV6                     |   TYPE    | SNAPSHOTS |\n+------------+---------+----------------------+----------------------------------------------+-----------+-----------+\n| noetic     | RUNNING | 10.171.226.67 (eth0) | fd42:13f7:78ed:7795:216:3eff:fe25:30f (eth0) | CONTAINER | 0         |\n+------------+---------+----------------------+----------------------------------------------+-----------+-----------+\n$ lxc exec noetic -- su --login ubuntu\nTo run a command as administrator (user \"root\"), use \"sudo &lt;command&gt;\".\nSee \"man sudo_root\" for details.\n\nubuntu@noetic:~$ \n\n\nFor the GUI you have to stop and attach profile read above about creating a profile names x11\n\nubuntu@noetic:~$  exit\n$ lxc stop noetic\n$ lxc profile assign noetic default,x11 #or whatever name is given to profile. Check above on how to create profile\n$ lxc start noetic\nubuntu@noetic:~$ sudo apt install x11-apps\nubuntu@noetic:~$ xclock #should display the clock if not then check the DISPLAY value in both host and container\n\nSteps in the the container for installing ros and graphics\n\n// Follow the ros noetic page \n// Additional before adding keys install gpg \n\nsudo apt install gpg\nYou have a working ubuntu noetic container with ros noetic.\n\n\n\nInformation from here 1\nlxc config device add my-container video0 unix-char path=/dev/video0\nrestart the container and check\nThe group and permissions for your /dev/video0 are not correct. The groop root for your /dev/video0 will deny access to the camera for users outside this group.\nThe output of ls -l /dev/video0 should look like this:\ncrw-rw----+ 1 root video 81, 1 Apr 19 22:25 /dev/video0\nTry fixing the group by running:\nsudo chown root:video /dev/video0\nThen fix permissions by running:\nsudo chmod 660 /dev/video0\nif the group video is missing try fixing it by these commands and running again the above commands\nsudo adduser www-data video\nsudo usermod -a -G video www-data\nYou might need to give permissions"
  },
  {
    "objectID": "posts/markdown/2022-10-20-ROS2-LXD-Container.html#lxd-start-easy-steps",
    "href": "posts/markdown/2022-10-20-ROS2-LXD-Container.html#lxd-start-easy-steps",
    "title": "Running ros2 humble in ubuntu lxd container",
    "section": "",
    "text": "Install lxd in your ubuntu (Using snap)\nUse Lxc to make sure its without sudo\nFor using gui inside the container we need to attach profiles to the container.\nCreate a profile using the following command\n\n$ lxc profile create x11\nProfile x11 created\n\nEdit the profile with the following command\n\n$ lxc profile edit x11\n\nCopy paste below in the editor below\n\nconfig:\n  environment.DISPLAY: :0\n  environment.PULSE_SERVER: unix:/home/ubuntu/pulse-native\n  nvidia.driver.capabilities: all\n  nvidia.runtime: \"true\"\n  user.user-data: |\n    #cloud-config\n    runcmd:\n      - 'sed -i \"s/; enable-shm = yes/enable-shm = no/g\" /etc/pulse/client.conf'\n    packages:\n      - x11-apps\n      - mesa-utils\n      - pulseaudio\ndescription: GUI LXD profile\ndevices:\n  PASocket1:\n    bind: container\n    connect: unix:/run/user/1000/pulse/native\n    listen: unix:/home/ubuntu/pulse-native\n    security.gid: \"1000\"\n    security.uid: \"1000\"\n    uid: \"1000\"\n    gid: \"1000\"\n    mode: \"0777\"\n    type: proxy\n  X0:\n    bind: container\n    connect: unix:@/tmp/.X11-unix/X1\n    listen: unix:@/tmp/.X11-unix/X0\n    security.gid: \"1000\"\n    security.uid: \"1000\"\n    type: proxy\n  mygpu:\n    type: gpu\nname: x11\nused_by: []\n\nIn the above file check the line connect: unix:@/tmp/.X11-unix/X1 This depends on how your local machine DISPLAY is set. If your local machine DISPLAY is at X1 replace there with X0.\nTo check your local machine displayecho $DISPLAY.\nNow lets create a container with the profile\n\nlxc launch ubuntu:22.04 --profile default --profile x11 mycontainer\n\nTo get a shell in the container, run the following.\n\n$ lxc exec mycontainer -- sudo --user ubuntu --login\nmycontainer $ sudo apt install xclock \nmycontainer $ export DISPLAY=:0  #Add this in bashrc\nmycontainer $ xclock\n\nThe above command will open the xclock in GUI . If the GUI doesnt come then check your local DISPLAY and the DISPLAY inside the container.\nComplete blog with explanation on the process is provided by (Simos)[https://blog.simos.info/running-x11-software-in-lxd-containers/]"
  },
  {
    "objectID": "posts/markdown/2022-10-20-ROS2-LXD-Container.html#lxd-and-ros2-installation",
    "href": "posts/markdown/2022-10-20-ROS2-LXD-Container.html#lxd-and-ros2-installation",
    "title": "Running ros2 humble in ubuntu lxd container",
    "section": "",
    "text": "Started with blog by ubuntu\nIt gets you through the installation .\n\nI created a ubuntu 22.04 container and installed ros2 inside it .\nI create a user called ubuntu\nfor ros installation I followed ros2 documentation\n\nFor using ros started ros2 tutorials\nFirst problem gui not working\n\nBlog by Nick D Greg introduced the topic of using profiles\nFollowing the blog I created a lxc profile named gui\nThe blog assumes you start from begining but since we already had the container running we used the below command\n\nlxc profile assign ros-humble default,gui\n\ninside the container ‘export DISPLAY=:0’ in the bash (also added in bashrc)\nnow gui is running\n$&gt; ros2 run turtlesim turtlesim_node"
  },
  {
    "objectID": "posts/markdown/2022-10-20-ROS2-LXD-Container.html#comman-commands-to-get-started-with-lxc-development",
    "href": "posts/markdown/2022-10-20-ROS2-LXD-Container.html#comman-commands-to-get-started-with-lxc-development",
    "title": "Running ros2 humble in ubuntu lxd container",
    "section": "",
    "text": "Boot your local ubuntu and first you want to check the active containers the command is lxc list\n\n$&gt; lxc list\n+------------+---------+----------------------+-----------------------------------------------+-----------+-----------+\n|    NAME    |  STATE  |         IPV4         |                     IPV6                      |   TYPE    | SNAPSHOTS |\n+------------+---------+----------------------+-----------------------------------------------+-----------+-----------+\n| ros-humble | RUNNING | 10.171.226.72 (eth0) | fd42:13f7:78ed:7795:216:3eff:fe9c:bde9 (eth0) | CONTAINER | 0         |\n+------------+---------+----------------------+-----------------------------------------------+-----------+-----------+\n\nGetting bash access\n\n$ lxc exec ros-humble -- su --login ubuntu\nubuntu@ubuntu-container:~$"
  },
  {
    "objectID": "posts/markdown/2022-10-20-ROS2-LXD-Container.html#appendix",
    "href": "posts/markdown/2022-10-20-ROS2-LXD-Container.html#appendix",
    "title": "Running ros2 humble in ubuntu lxd container",
    "section": "",
    "text": "History of comands used insde the container, after logging\n2  apt-cache policy | grep universe\n3  sudo apt install software-properties-common\n4  sudo add-apt-repository universe\n5  sudo apt update && sudo apt install curl gnupg lsb-release\n6  sudo curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key -o /usr/share/keyrings/ros-archive-keyring.gpg\n7  echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu $(source /etc/os-release && echo $UBUNTU_CODENAME) main\" | sudo tee /etc/apt/sources.list.d/ros2.list &gt; /dev/null\n8  sudo apt update && sudo apt install -y   build-essential   cmake   git   python3-colcon-common-extensions   python3-flake8   python3-flake8-blind-except   python3-flake8-builtins   python3-flake8-class-newline   python3-flake8-comprehensions   python3-flake8-deprecated   python3-flake8-docstrings   python3-flake8-import-order   python3-flake8-quotes   python3-pip   python3-pytest   python3-pytest-cov   python3-pytest-repeat   python3-pytest-rerunfailures   python3-rosdep   python3-setuptools   python3-vcstool   wget\n9  sudo apt update\n10  sudo apt install ros-humble-desktop"
  },
  {
    "objectID": "posts/markdown/2022-10-20-ROS2-LXD-Container.html#additional-noetic-in-lxc",
    "href": "posts/markdown/2022-10-20-ROS2-LXD-Container.html#additional-noetic-in-lxc",
    "title": "Running ros2 humble in ubuntu lxd container",
    "section": "",
    "text": "Steps in the host computer to dowload ubuntu 20 and login to the virtual machine\n\n$ lxc launch images:ubuntu/20.04 noetic\nCreating noetic\nStarting noetic  \n$ lxc list\n+------------+---------+----------------------+----------------------------------------------+-----------+-----------+\n|    NAME    |  STATE  |         IPV4         |                     IPV6                     |   TYPE    | SNAPSHOTS |\n+------------+---------+----------------------+----------------------------------------------+-----------+-----------+\n| noetic     | RUNNING | 10.171.226.67 (eth0) | fd42:13f7:78ed:7795:216:3eff:fe25:30f (eth0) | CONTAINER | 0         |\n+------------+---------+----------------------+----------------------------------------------+-----------+-----------+\n$ lxc exec noetic -- su --login ubuntu\nTo run a command as administrator (user \"root\"), use \"sudo &lt;command&gt;\".\nSee \"man sudo_root\" for details.\n\nubuntu@noetic:~$ \n\n\nFor the GUI you have to stop and attach profile read above about creating a profile names x11\n\nubuntu@noetic:~$  exit\n$ lxc stop noetic\n$ lxc profile assign noetic default,x11 #or whatever name is given to profile. Check above on how to create profile\n$ lxc start noetic\nubuntu@noetic:~$ sudo apt install x11-apps\nubuntu@noetic:~$ xclock #should display the clock if not then check the DISPLAY value in both host and container\n\nSteps in the the container for installing ros and graphics\n\n// Follow the ros noetic page \n// Additional before adding keys install gpg \n\nsudo apt install gpg\nYou have a working ubuntu noetic container with ros noetic."
  },
  {
    "objectID": "posts/markdown/2022-10-20-ROS2-LXD-Container.html#adding-a-camera-to-the-container",
    "href": "posts/markdown/2022-10-20-ROS2-LXD-Container.html#adding-a-camera-to-the-container",
    "title": "Running ros2 humble in ubuntu lxd container",
    "section": "",
    "text": "Information from here 1\nlxc config device add my-container video0 unix-char path=/dev/video0\nrestart the container and check\nThe group and permissions for your /dev/video0 are not correct. The groop root for your /dev/video0 will deny access to the camera for users outside this group.\nThe output of ls -l /dev/video0 should look like this:\ncrw-rw----+ 1 root video 81, 1 Apr 19 22:25 /dev/video0\nTry fixing the group by running:\nsudo chown root:video /dev/video0\nThen fix permissions by running:\nsudo chmod 660 /dev/video0\nif the group video is missing try fixing it by these commands and running again the above commands\nsudo adduser www-data video\nsudo usermod -a -G video www-data\nYou might need to give permissions"
  },
  {
    "objectID": "posts/markdown/2023-01-13-Migration-ROS-Kelo-Tulip-ROS2.html",
    "href": "posts/markdown/2023-01-13-Migration-ROS-Kelo-Tulip-ROS2.html",
    "title": "Migrating Kelo Tulip to ROS2",
    "section": "",
    "text": "As per the blog the migration steps are (ROS2 migration guide)[https://docs.ros.org/en/foxy/The-ROS2-Project/Contributing/Migration-Guide.html]\n\nPackage manifests\nMetapackages\nMessage, service, and action definitions\nBuild system\nUpdate source code\n\nStep 1 : Package manifests\nMigration Gazebo\n\nhttps://github.com/ros-simulation/gazebo_ros_pkgs/wiki\n\nMessages\n\nFor messages and services replace the message using the formulation below\n#include &lt;sensor_msgs/JointState.hpp&gt; ➡️ #include &lt;sensor_msgs/msg/joint_state.hpp&gt;\n#include &lt;nav_msgs/Odometry.hpp&gt; ➡️ #include &lt;nav_msgs/msg/odometry.hpp&gt;\nYou add the msg and in small letters\n\nMain.cpp\n\n#include \"ros/ros.h\" ▶️ #include \"rclcpp/rclcpp.hpp\"\n\nLaunching robot in Gazebo : Error model visalization\n\nFor ROS2 usage, by changing the following in any of the cameras' urdf file\n&lt;mesh filename=\"package://realsense2_description/meshes/d415.stl\" /&gt;\ninto\n&lt;mesh filename=\"file://$(find realsense2_description)/meshes/d415.stl\" /&gt;\nwill resolve the issue, as it will evaluate to the full path when xacro generates the URDF.\n\nAdding laser scanner in gazebo . Errors\n\nUsed the xacro method from ros1\nxacro method works but plugins have changed\nlibgazebo_ros_laser.so is now changed to ➡️ libgazebo_ros_ray_sensor.so\nAlso the paraeter to initialize it is different\nCheck the github issue for proper initialization\n\n\nRos2 node with both cpp and python then do the following\n\nI have a mixed C++/Python package. To install a Python executable in this package, I’ve found it sufficient to do this:\nAdd the Python source file to my_package/scripts\nAdd this line at the top of ^that file: #!/usr/bin/env python3\nMake it executable with chmod +x\nAdd an empty init.py file in my_package/scripts\nAdd this to CMakeLists: ``` install(PROGRAMS\nscripts/my_python_file.py\nDESTINATION lib/${PROJECT_NAME} )\n\n\n``` * from https://answers.ros.org/question/299269/ros2-run-python-executable-not-found/\n\n\n\nStarting gazebo in the launch file gives “camera assertion error”\n\nThe solution is to source Gazebo’s setup file, i.e.: . /usr/share/gazebo/setup.sh\nhttps://answers.gazebosim.org//question/28066/is-libgazebo_ros_multicameraso-deprecated/\necho \"source /usr/share/gazebo/setup.bash\" &gt;&gt; ~/.bashrc ▶️ for persistence"
  },
  {
    "objectID": "posts/markdown/2023-01-13-Migration-ROS-Kelo-Tulip-ROS2.html#errors",
    "href": "posts/markdown/2023-01-13-Migration-ROS-Kelo-Tulip-ROS2.html#errors",
    "title": "Migrating Kelo Tulip to ROS2",
    "section": "",
    "text": "Starting gazebo in the launch file gives “camera assertion error”\n\nThe solution is to source Gazebo’s setup file, i.e.: . /usr/share/gazebo/setup.sh\nhttps://answers.gazebosim.org//question/28066/is-libgazebo_ros_multicameraso-deprecated/\necho \"source /usr/share/gazebo/setup.bash\" &gt;&gt; ~/.bashrc ▶️ for persistence"
  },
  {
    "objectID": "posts/markdown/2023-04-29-Fun-With-FFMPEG.html",
    "href": "posts/markdown/2023-04-29-Fun-With-FFMPEG.html",
    "title": "FFMPEG - Automating video edition",
    "section": "",
    "text": "ffmpeg -i input.mp4 -an -filter_complex \"[0:v]setpts=0.5*PTS,scale=1280:-2,\ndrawtext=text='2x Speed':x=(w-text_w)/2:y=10:fontsize=30:fontcolor=white\" -c:v libx264 -preset veryfast -crf 18 output.mp4\n\nIn this command, -i specifies the input video file, -an removes the audio stream, and -filter_complex applies a filter graph that speeds up the video, scales it to a width of 1280 pixels (keeping the aspect ratio), and adds a text annotation indicating the fast forward speed.\nThe setpts filter speeds up the video by setting the presentation timestamp (PTS) to half of its original value, effectively doubling the playback speed. The drawtext filter adds the text “2x Speed” to the center of the video frame with a font size of 30 and white color.\nThe -c:v libx264 -preset veryfast -crf 18 options specify the video codec and encoding parameters. In this case, the video is encoded using the H.264 codec with a CRF (constant rate factor) of 18, which produces a good balance of quality and file size. The veryfast preset is used to speed up the encoding process.\nThe output file is specified as output.mp4.\nNote that the speedup factor can be adjusted by changing the value in the setpts filter. For example, to speed up the video by a factor of 3, you would set the setpts filter to setpts=0.33*PTS.\nthe drawtext filter is used to add text to the video. The text option specifies the text to be added, and the x and y options specify the coordinates of the bottom left corner of the text. The fontfile, fontsize, and fontcolor options are used to specify the font file, font size, and font color of the text."
  },
  {
    "objectID": "posts/markdown/2023-04-29-Fun-With-FFMPEG.html#command-to-remove-the-audio-from-a-video-speed-it-up-and-add-an-annotation-to-indicate-the-fast-forward-speed",
    "href": "posts/markdown/2023-04-29-Fun-With-FFMPEG.html#command-to-remove-the-audio-from-a-video-speed-it-up-and-add-an-annotation-to-indicate-the-fast-forward-speed",
    "title": "FFMPEG - Automating video edition",
    "section": "",
    "text": "ffmpeg -i input.mp4 -an -filter_complex \"[0:v]setpts=0.5*PTS,scale=1280:-2,\ndrawtext=text='2x Speed':x=(w-text_w)/2:y=10:fontsize=30:fontcolor=white\" -c:v libx264 -preset veryfast -crf 18 output.mp4\n\nIn this command, -i specifies the input video file, -an removes the audio stream, and -filter_complex applies a filter graph that speeds up the video, scales it to a width of 1280 pixels (keeping the aspect ratio), and adds a text annotation indicating the fast forward speed.\nThe setpts filter speeds up the video by setting the presentation timestamp (PTS) to half of its original value, effectively doubling the playback speed. The drawtext filter adds the text “2x Speed” to the center of the video frame with a font size of 30 and white color.\nThe -c:v libx264 -preset veryfast -crf 18 options specify the video codec and encoding parameters. In this case, the video is encoded using the H.264 codec with a CRF (constant rate factor) of 18, which produces a good balance of quality and file size. The veryfast preset is used to speed up the encoding process.\nThe output file is specified as output.mp4.\nNote that the speedup factor can be adjusted by changing the value in the setpts filter. For example, to speed up the video by a factor of 3, you would set the setpts filter to setpts=0.33*PTS.\nthe drawtext filter is used to add text to the video. The text option specifies the text to be added, and the x and y options specify the coordinates of the bottom left corner of the text. The fontfile, fontsize, and fontcolor options are used to specify the font file, font size, and font color of the text."
  },
  {
    "objectID": "posts/markdown/2023-04-29-Fun-With-FFMPEG.html#speed-up-video-from-timeframe-to-timeframe",
    "href": "posts/markdown/2023-04-29-Fun-With-FFMPEG.html#speed-up-video-from-timeframe-to-timeframe",
    "title": "FFMPEG - Automating video edition",
    "section": "Speed up video from timeframe to timeframe",
    "text": "Speed up video from timeframe to timeframe\nffmpeg -i input.mp4 -filter_complex \"[0:v]trim=start=60:end=120,setpts=0.5*PTS[v];[0:a]atrim=start=60:end=120,atempo=2.0[a]\" \n-map \"[v]\" -map \"[a]\" output.mp4\n\nThe trim filter is used to select the specific timeframe of the video, starting at 1 minute (60 seconds) and ending at 2 minutes (120 seconds). The setpts filter is then used to adjust the timestamps of the frames in the selected timeframe to achieve the desired speedup factor. In this example, the 0.5*PTS value halves the timestamps of the frames, resulting in a speedup factor of 2.\nThe atrim and atempo filters are used to select the corresponding audio timeframe and adjust its speed accordingly.\nFinally, the -map option is used to select the video and audio streams to be included in the output file, which is specified as output.mp4.\nYou can adjust the values of start, end, and setpts to speed up a different timeframe and to achieve a different speedup factor."
  },
  {
    "objectID": "posts/markdown/2023-04-29-Fun-With-FFMPEG.html#different-annotation-at-different-time-periods",
    "href": "posts/markdown/2023-04-29-Fun-With-FFMPEG.html#different-annotation-at-different-time-periods",
    "title": "FFMPEG - Automating video edition",
    "section": "Different annotation at different time periods",
    "text": "Different annotation at different time periods\nffmpeg -i input.mp4 -vf \"drawtext=text='First Text':x=10:y=H-th-10:fontsize=24:fontcolor=white:enable='between(t,5,10)',\ndrawtext=text='Second Text':x=10:y=H-th-10:fontsize=24:fontcolor=white:enable='between(t,20,25)'\" -c:a copy output.mp4"
  },
  {
    "objectID": "posts/markdown/2023-04-29-Fun-With-FFMPEG.html#croping-the-shape-of-the-video",
    "href": "posts/markdown/2023-04-29-Fun-With-FFMPEG.html#croping-the-shape-of-the-video",
    "title": "FFMPEG - Automating video edition",
    "section": "Croping the shape of the video",
    "text": "Croping the shape of the video\nffmpeg -i input.mp4 -vf \"crop=w=640:h=480:x=320:y=240\" output.mp4\n\nIn this command, -i specifies the input video file, -vf specifies the video filtergraph, and crop is the filter that crops the video frame. The w and h options specify the width and height of the cropped frame, and the x and y options specify the position of the top-left corner of the cropped frame relative to the original frame.\nIn this example, the crop filter crops the frame to a size of 640x480, starting at position (320, 240) from the top-left corner of the original frame. You can adjust the values of w, h, x, and y to crop the frame to your desired size and position.\n\n## Overlay logo on the image\n ffmpeg -i input.mp4 -i logo.png -filter_complex \"overlay=10:10\" output.mp4\n\nIn this command, -i specifies the input video file and -i specifies the logo image file. The filter_complex option is used to apply multiple filters to the video.\nThe overlay filter is used to overlay the logo image onto the video. The 10:10 values specify the position of the top left corner of the logo image relative to the top left corner of the video.\nYou can adjust the position of the logo image by changing the 10:10 values to your desired position. Additionally, you can add other filters to the filter_complex option to apply more effects to the video.\nLop top right overlay=W-w-10:10 . W and w refer to the width of the video and the logo image, respectively. The overlay filter calculates the position of the logo image by subtracting the width of the logo from the width of the video and offsetting it by 10 pixels from the right edge of the video. The 10 value represents the vertical offset of the logo from the top edge of the video."
  },
  {
    "objectID": "posts/markdown/2023-04-12-Bayesian-Networks-Introduction.html",
    "href": "posts/markdown/2023-04-12-Bayesian-Networks-Introduction.html",
    "title": "Bayesian Networks ? What and Why",
    "section": "",
    "text": "A Bayesian network is a graphical model used to represent probabilistic relationships among a set of variables. In a Bayesian network, each variable is represented by a node in the graph, and the edges between nodes represent the probabilistic dependencies between them. The nodes in the graph are typically labeled with the name of the corresponding variable and the conditional probability distribution of the variable given its parents. Bayesian networks are commonly used in machine learning, artificial intelligence, and decision-making applications. They are particularly useful in situations where there are many variables with complex interdependencies, and where it is difficult to determine the relationships between them using traditional statistical methods. By using Bayesian networks, it is possible to model the probability of certain events occurring, given a set of observed data. This makes it a powerful tool for making predictions, performing diagnosis, and making decisions based on uncertain information."
  },
  {
    "objectID": "posts/markdown/2023-04-12-Bayesian-Networks-Introduction.html#python-code",
    "href": "posts/markdown/2023-04-12-Bayesian-Networks-Introduction.html#python-code",
    "title": "Bayesian Networks ? What and Why",
    "section": "Python code",
    "text": "Python code\nWe will use the PyAgum library to create the BN and try to infer .\n\n# Create a Bayesian network object\nbn = gum.BayesNet('Dialogue Management')\n\n# Add the nodes to the network\nuser_goal = bn.add(gum.LabelizedVariable('user_goal', 'User Goal', 3))\nuser_preference = bn.add(gum.LabelizedVariable('user_preference', 'User Preference', 3))\ndialogue_context = bn.add(gum.LabelizedVariable('dialogue_context', 'Dialogue Context', 3))\nrobot_understanding = bn.add(gum.LabelizedVariable('robot_understanding', 'Robot Understanding', 3))\nrobot_response = bn.add(gum.LabelizedVariable('robot_response', 'Robot Response', 3))\nbn.addArc(user_preference,robot_understanding)\nbn.addArc(dialogue_context,robot_understanding)\n#bn.addArc(user_goal,robot_understanding)\n\nbn.addArc(robot_understanding,robot_response)\n\n\n# Define the conditional probability distributions for each node\nbn.cpt(user_goal).fillWith([0.3, 0.4, 0.3])\nbn.cpt(user_preference).fillWith([0.4, 0.3, 0.3])\nbn.cpt(dialogue_context).fillWith([0.2, 0.6, 0.2])\n\nbn.cpt(robot_understanding)[{'user_preference': 0, 'dialogue_context': 0}] = [0.4, 0.3, 0.3]\nbn.cpt(robot_understanding)[{'user_preference': 0, 'dialogue_context': 1}] = [0.3, 0.4, 0.3]\nbn.cpt(robot_understanding)[{'user_preference': 0, 'dialogue_context': 2}] = [0.3, 0.3, 0.4]\n\nbn.cpt(robot_understanding)[{'user_preference': 1, 'dialogue_context': 0}] = [0.2, 0.5, 0.3]\nbn.cpt(robot_understanding)[{'user_preference': 1, 'dialogue_context': 1}] = [0.3, 0.4, 0.3]\nbn.cpt(robot_understanding)[{'user_preference': 1, 'dialogue_context': 2}] = [0.3, 0.3, 0.4]\n\nbn.cpt(robot_understanding)[{'user_preference': 2, 'dialogue_context': 0}] = [0.2, 0.3, 0.5]\nbn.cpt(robot_understanding)[{'user_preference': 2, 'dialogue_context': 1}] = [0.3, 0.3, 0.4]\nbn.cpt(robot_understanding)[{'user_preference': 2, 'dialogue_context': 2}] = [0.3, 0.4, 0.3]\n\nbn.cpt(robot_response)[{'robot_understanding': 0}] = [0.5, 0.2, 0.3]\nbn.cpt(robot_response)[{'robot_understanding': 1}] = [0.3, 0.5, 0.2]\nbn.cpt(robot_response)[{'robot_understanding': 2}] = [0.2, 0.3, 0.5]\n\ngnb.showBN(bn,size='30')\n\n# Observe the values of the user_goal and dialogue_context nodes\n#bn.setEvidence({'user_goal': 0, 'dialogue_context': 0})\n\n# Infer the posterior probabilities of the robot_understanding and robot_response nodes\nie = gum.LazyPropagation(bn)\n\n# Observe the values of the user_goal and dialogue_context nodes\nie.setEvidence({'user_goal': 0, 'dialogue_context': 0})\n\nie.makeInference()\n\nrobot_understanding_posterior = ie.posterior(robot_understanding)\nrobot_response_posterior = ie.posterior(robot_response)\n\n# Select the response with the highest probability as the robot's utterance\nrobot_response = robot_response_posterior.toarray().argmax()\n\nprint('Robot response: {}'.format(robot_response))\nOutput\nRobot response: 2"
  },
  {
    "objectID": "posts/markdown/2022-06-25-Github-Action-Latex-Compilation.html",
    "href": "posts/markdown/2022-06-25-Github-Action-Latex-Compilation.html",
    "title": "Compile Latex file using Github Action",
    "section": "",
    "text": "GitHub Actions provides full access to the runner at your disposal, and one thing you may want to do is make commits in a workflow run and push it back up to GitHub automatically. I’m going to show a simple example where we run the date unix command, save the contents to a file, and push it back to the master branch. Example workflow\n\n\n\nUse make file to automate all the actions which needs to be done after checking out the repo.\nHere is a Makefile for compiling latex file\n\nfilename=main\n\npdf:\n    mkdir -p build\n    pdflatex --output-directory build ${filename}\n    bibtex build/${filename}||true\n    pdflatex --output-directory build ${filename}\n    pdflatex --output-directory build ${filename}\n    mv build/${filename}.pdf .\n\nread:\n    evince build/${filename}.pdf &\n\nclean:\n    rm -f build/${filename}.{ps,pdf,log,aux,out,dvi,bbl,blg}\n\n\n\n\nInorder to use pdflatex in the ubuntu machine generted for compilation first you need to install the necessary packages in the ubuntu machine .\n\n\n\nThe following is a workflow which on push will do the following:\ncheckout the repo\ninstall latex dependency\nrun make command and compile\nsetup git config\ncommit the changed file and push it back to master\nname: Makefile CI\n\non:\n  push:\n    branches: [ \"master\" ]\n  pull_request:\n    branches: [ \"master\" ]\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v3\n    \n    - name: Install dependencies\n      run: sudo apt-get install texlive-latex-base texlive-fonts-recommended texlive-fonts-extra texlive-latex-extra\n  \n    - name: Compile\n      run: make\n      \n    - name: setup git config\n      run: |\n        # setup the username and email. I tend to use 'GitHub Actions Bot' with no email by default\n        git config user.name \"GitHub Actions Bot\"\n        git config user.email \"&lt;&gt;\"\n\n    - name: commit\n      run: |\n        # Stage the file, commit and push\n        git add main.pdf\n        git commit -m \"new main pdf commit\"\n        git push origin master\n\n[1] https://lannonbr.com/blog/2019-12-09-git-commit-in-actions/ [2] Example github page"
  },
  {
    "objectID": "posts/markdown/2022-06-25-Github-Action-Latex-Compilation.html#using-makefile",
    "href": "posts/markdown/2022-06-25-Github-Action-Latex-Compilation.html#using-makefile",
    "title": "Compile Latex file using Github Action",
    "section": "",
    "text": "Use make file to automate all the actions which needs to be done after checking out the repo.\nHere is a Makefile for compiling latex file\n\nfilename=main\n\npdf:\n    mkdir -p build\n    pdflatex --output-directory build ${filename}\n    bibtex build/${filename}||true\n    pdflatex --output-directory build ${filename}\n    pdflatex --output-directory build ${filename}\n    mv build/${filename}.pdf .\n\nread:\n    evince build/${filename}.pdf &\n\nclean:\n    rm -f build/${filename}.{ps,pdf,log,aux,out,dvi,bbl,blg}"
  },
  {
    "objectID": "posts/markdown/2022-06-25-Github-Action-Latex-Compilation.html#installing-latex-commands-in-github-action",
    "href": "posts/markdown/2022-06-25-Github-Action-Latex-Compilation.html#installing-latex-commands-in-github-action",
    "title": "Compile Latex file using Github Action",
    "section": "",
    "text": "Inorder to use pdflatex in the ubuntu machine generted for compilation first you need to install the necessary packages in the ubuntu machine ."
  },
  {
    "objectID": "posts/markdown/2022-06-25-Github-Action-Latex-Compilation.html#using-git-commit-in-github-actions",
    "href": "posts/markdown/2022-06-25-Github-Action-Latex-Compilation.html#using-git-commit-in-github-actions",
    "title": "Compile Latex file using Github Action",
    "section": "",
    "text": "The following is a workflow which on push will do the following:\ncheckout the repo\ninstall latex dependency\nrun make command and compile\nsetup git config\ncommit the changed file and push it back to master\nname: Makefile CI\n\non:\n  push:\n    branches: [ \"master\" ]\n  pull_request:\n    branches: [ \"master\" ]\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v3\n    \n    - name: Install dependencies\n      run: sudo apt-get install texlive-latex-base texlive-fonts-recommended texlive-fonts-extra texlive-latex-extra\n  \n    - name: Compile\n      run: make\n      \n    - name: setup git config\n      run: |\n        # setup the username and email. I tend to use 'GitHub Actions Bot' with no email by default\n        git config user.name \"GitHub Actions Bot\"\n        git config user.email \"&lt;&gt;\"\n\n    - name: commit\n      run: |\n        # Stage the file, commit and push\n        git add main.pdf\n        git commit -m \"new main pdf commit\"\n        git push origin master\n\n[1] https://lannonbr.com/blog/2019-12-09-git-commit-in-actions/ [2] Example github page"
  },
  {
    "objectID": "posts/markdown/2020-05-21-Explanation-Learning-DatasetShift.html",
    "href": "posts/markdown/2020-05-21-Explanation-Learning-DatasetShift.html",
    "title": "Dataset shift",
    "section": "",
    "text": "Dataset shift is still an unsolved problems when it comes to deploying learning models “in the wild”.\nThere are 2 different categories of dataset shift * Co-variate shift * label shift\nLet $ $ be the source data distribution and $ $ be the target data distribution. If we denote the input variables as x and output variables as y, then\n\n\n\\[ s(x) \\neq t(x) \\] input distribution of both source and target are different\nbut\n\\[ s(y|x) = t(y|x) \\] conditional output distirbution is invariant to dataset shift.\n\n\n\n\\[ s(y) \\neq t(y) \\] output distribution of both source and target are different\nbut\n\\[ s(x|y) = t(x|y) \\] conditional input distirbution is invariant to dataset shift\n\n\n\n\n\n\n\n\n\nCovariate Shift\nLabel Shift\n\n\n\n\ninput distribution\n\\(s(x) \\neq t(x)\\)\n\\(?\\)\n\n\noutput distribution\n\\(?\\)\n\\(s(y) \\neq t(y)\\)\n\n\nconditional output distribution\n\\(s(y\\vert x) = t(y \\vert x)\\)\n\\(?\\)\n\n\nconditional input Distribution\n\\(?\\)\n\\({s(x \\vert y) = t(x \\vert y)}\\)\n\n\n\n\n\n\nToDo\n\n\n\nThe problem can be simulated in image based calssification dataset like MNIST and CIFAR.\n\n\nrefers to the case where we set a class to have probability $ p &gt; 0.1$, while the distribution over the rest of the classes is uniform. ### Minority-Class Shiftis A more general version of Tweak-One shift, where a fixed number of classes to have probability \\(p &lt; 0.1\\), while the distribution over the rest of the classes isuniform. ### Dirichlet shift we draw a probability vector \\(p\\) from the Dirichlet distribution with concentration parameter set to \\(\\alpha\\) for all classes, before including sample points which correspond to the multinomial label variable according top."
  },
  {
    "objectID": "posts/markdown/2020-05-21-Explanation-Learning-DatasetShift.html#covariate-shift",
    "href": "posts/markdown/2020-05-21-Explanation-Learning-DatasetShift.html#covariate-shift",
    "title": "Dataset shift",
    "section": "",
    "text": "\\[ s(x) \\neq t(x) \\] input distribution of both source and target are different\nbut\n\\[ s(y|x) = t(y|x) \\] conditional output distirbution is invariant to dataset shift."
  },
  {
    "objectID": "posts/markdown/2020-05-21-Explanation-Learning-DatasetShift.html#label-shift",
    "href": "posts/markdown/2020-05-21-Explanation-Learning-DatasetShift.html#label-shift",
    "title": "Dataset shift",
    "section": "",
    "text": "\\[ s(y) \\neq t(y) \\] output distribution of both source and target are different\nbut\n\\[ s(x|y) = t(x|y) \\] conditional input distirbution is invariant to dataset shift\n\n\n\n\n\n\n\n\n\nCovariate Shift\nLabel Shift\n\n\n\n\ninput distribution\n\\(s(x) \\neq t(x)\\)\n\\(?\\)\n\n\noutput distribution\n\\(?\\)\n\\(s(y) \\neq t(y)\\)\n\n\nconditional output distribution\n\\(s(y\\vert x) = t(y \\vert x)\\)\n\\(?\\)\n\n\nconditional input Distribution\n\\(?\\)\n\\({s(x \\vert y) = t(x \\vert y)}\\)"
  },
  {
    "objectID": "posts/markdown/2020-05-21-Explanation-Learning-DatasetShift.html#examples",
    "href": "posts/markdown/2020-05-21-Explanation-Learning-DatasetShift.html#examples",
    "title": "Dataset shift",
    "section": "",
    "text": "ToDo"
  },
  {
    "objectID": "posts/markdown/2020-05-21-Explanation-Learning-DatasetShift.html#simluated-dataset-redo-with-examples",
    "href": "posts/markdown/2020-05-21-Explanation-Learning-DatasetShift.html#simluated-dataset-redo-with-examples",
    "title": "Dataset shift",
    "section": "",
    "text": "The problem can be simulated in image based calssification dataset like MNIST and CIFAR.\n\n\nrefers to the case where we set a class to have probability $ p &gt; 0.1$, while the distribution over the rest of the classes is uniform. ### Minority-Class Shiftis A more general version of Tweak-One shift, where a fixed number of classes to have probability \\(p &lt; 0.1\\), while the distribution over the rest of the classes isuniform. ### Dirichlet shift we draw a probability vector \\(p\\) from the Dirichlet distribution with concentration parameter set to \\(\\alpha\\) for all classes, before including sample points which correspond to the multinomial label variable according top."
  },
  {
    "objectID": "posts/markdown/2023-02-24-SAP-AI-Sustainability.html",
    "href": "posts/markdown/2023-02-24-SAP-AI-Sustainability.html",
    "title": "Building AI and Sustainability Solutions on SAP BTP",
    "section": "",
    "text": "Doing exercises using SAP AI Core\nFollowing instructions from the open source"
  },
  {
    "objectID": "posts/markdown/2023-02-24-SAP-AI-Sustainability.html#sap-ai-core",
    "href": "posts/markdown/2023-02-24-SAP-AI-Sustainability.html#sap-ai-core",
    "title": "Building AI and Sustainability Solutions on SAP BTP",
    "section": "",
    "text": "Doing exercises using SAP AI Core\nFollowing instructions from the open source"
  },
  {
    "objectID": "posts/markdown/2023-02-24-SAP-AI-Sustainability.html#why-sustainability",
    "href": "posts/markdown/2023-02-24-SAP-AI-Sustainability.html#why-sustainability",
    "title": "Building AI and Sustainability Solutions on SAP BTP",
    "section": "Why sustainability",
    "text": "Why sustainability\n\nSustainability\n\n\nPillars of sustainability - society, economy, environmnt\n\n\nSAP Product footprint management\n\n\nWith SAP Product Footprint Management customers gain insights on the environmental impacts of their products across the entire lifecycle for disclosure and internal product and process optimization. The solution reuses existing business data and combines it with environmental factors to calculate the footprints of the products periodically and at scale. The calculated footprints are integrated back into the end-to-end processes.\n\n\nSAP Responsible Design and Production SAP Responsible Design and Production helps producers manage their EPR obligations and plastic taxes so they can control and eliminate the costs of the downstream waste system and make design changes to eliminate waste.\nSAP Sustainability Control Tower Support customers to automate their integrated reporting and performance management by enabling transparency across financial, operational, compliance, environmental, and social key figures to understand their impact on the environment, society, and communities.\nSAP EHS Management, incident management / health and safety management SAP EHS solutions provide a holistic approach to worker safety that embeds operational risk management systematically across the entirety of your operations. This forms the basis of a robust corporate safety culture, able to respond proactively to hazards and withstand future health and safety challenges.\nSAP Ariba – EcoVadis Supplier Sustainability Rating EcoVadis is the most trusted provider of business sustainability ratings, used by over 75,000 companies worldwide. Backed by powerful technology and a global team of experts, EcoVadis’ easy-to-use scorecards provide actionable insights into environmental, social, and ethical risks."
  },
  {
    "objectID": "posts/notebooks/2023-08-25-Uncertainty-Representation-Propagation-Robotics.html",
    "href": "posts/notebooks/2023-08-25-Uncertainty-Representation-Propagation-Robotics.html",
    "title": "Representation and propagation of uncertainty",
    "section": "",
    "text": "From : A probabilistic framework for tracking uncertainties in robotic manipulation Huy Nguyen and Quang-Cuong Pham\n\nIn early works by [11] and [12], the uncertainty of a pose is simply represented by worst-case bounds which include all possible errors (min-max approach).This simple approach usually results in conservative estimates which make it difficult to apply in decision-making process.\nTo address this limitation, the probabilistic approach which uses the calculus of probability theory and assign probabilities to all potential positions of the object has been proposed.\nThe pose of an object is now represented by a probability distribution over the space [9], [13].\nAs a result, the probabilistic representation can make use of probability theory and, thus, provide more uncertainty manipulation methodologies (e.g. propagation, fusion, etc.) [3], [4], [14], [15].\nRecently, this probabilistic approach has been further investigated in [5], [6], [16], [17] where they provided a rigorous treatment of representing and propagating uncertainty on SO(3) and SE(3)\n\n\n\n\n[11] R. H. Taylor, “The synthesis of manipulator control programs from task- level specifications.” Ph.D. dissertation, Stanford University, Stanford, CA, USA, 1976, aAI7707174.\n[12] R. A. Brooks, “Symbolic error analysis and robot planning,” The International Journal of Robotics Research, vol. 1, no. 4, pp. 29–78,\n\n\n\n\n\n\n\n\n[9] S. Su and C. Lee, “Uncertainty manipulation and propagation and verification of applicability of actions in assembly tasks,” in IEEE International Conference on Robotics and Automation, vol. 3, 1991, pp. 2471–2476\n[13] S.-F. Su and C. G. Lee, “Manipulation and propagation of uncertainty and verification of applicability of actions in assembly tasks,” Systems Science and Cybernetics, IEEE Transactions on, vol. 22, no. 6, pp. 1376– 1389, 1992.\n\n\n\n\n\n[3] R. Smith, M. Self, and P. Cheeseman, “Estimating uncertain spatial relationships in robotics,” in Autonomous robot vehicles. Springer, 1990, pp. 167–193.\n[4] H. F. Durrant-Whyte, “Uncertainty geometry in robotics,” IEEE Journal of Robotics and Automation, vol. 4, no. 1, pp. 23–31, 1988.\n[14] R. A. Brooks, “Visual map making for a mobile robot,” in Robotics and Automation, 1985. Proceedings. IEEE International Conference on, vol. 2. IEEE, 1985, pp. 824–829.\n[15] R. C. Smith and P. Cheeseman, “On the representation and estimation of spatial uncertainty,” IEEE Journal of Robotics and Automation, vol. 5, no. 4, pp. 56–68, 1986.\n\n\n\n\n\n[5] Y. Wang and G. S. Chirikjian, “Nonparametric second-order theory of error propagation on motion groups,” International Journal of Robotics Research, vol. 27, no. 11-12, pp. 1258–1273, 2008.\n[6] T. D. Barfoot and P. T. Furgale, “Associating uncertainty with three- dimensional poses for use in estimation problems,” IEEE Transactions on Robotics, vol. 30, no. 3, pp. 679 – 693, June 2014.\n[16] G. Chirikjian, Stochastic Models, Information Theory, and Lie Groups, Volume 1: Classical Results and Geometric Methods. Springer Science & Business Media, 2009, vol. 1.\n[17] ——, Stochastic Models, Information Theory, and Lie Groups, Volume 2: Analytic Methods and Modern Applications. Springer Science & Business Media, 2011, vol. 2.\n\n\n!git clone https://github.com/dinhhuy2109/python-cope.git\n\nCloning into 'python-cope'...\nremote: Enumerating objects: 361, done.\nremote: Total 361 (delta 0), reused 0 (delta 0), pack-reused 361\nReceiving objects: 100% (361/361), 1.17 MiB | 3.46 MiB/s, done.\nResolving deltas: 100% (199/199), done.\n\n\n\n!pip install trimesh -q\n\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/685.4 kB ? eta -:--:--     ━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 71.7/685.4 kB 1.9 MB/s eta 0:00:01     ━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━ 317.4/685.4 kB 4.4 MB/s eta 0:00:01     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━ 614.4/685.4 kB 5.8 MB/s eta 0:00:01     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 685.4/685.4 kB 5.1 MB/s eta 0:00:00\n\n\n\nfrom importlib import reload  # Python 3.4+\n\n\n!cd python-cope && sudo pip install -e .\n\nObtaining file:///content/python-cope\n  Preparing metadata (setup.py) ... done\nInstalling collected packages: cope\n  Attempting uninstall: cope\n    Found existing installation: cope 1.0.0\n    Uninstalling cope-1.0.0:\n      Successfully uninstalled cope-1.0.0\n  Running setup.py develop for cope\nSuccessfully installed cope-1.0.0\n\n\n\nimport numpy  as np\nimport cope\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.pyplot as plt\nimport time\n\nstarttime = time.time()\ntiny = 1e-5\n\nT1 = np.eye(4)\nsigma1 = np.diag([tiny,tiny,tiny,tiny,tiny,tiny],0)\n\nT2 = np.eye(4)\nT2[:3,3] = np.array([0,0.15,0])\nsigma2 = np.diag([tiny,tiny,tiny,0.01,tiny,0.01],0)\n\nT3 = np.eye(4)\nT3[:3,3] = np.array([0,0,-0.03])\nsigma3 = np.diag([tiny,tiny,tiny,tiny,tiny,0.1],0)\n\nT4 = np.eye(4)\nT4[:3,3] = np.array([0,0.14,0])\nsigma4 = np.diag([tiny,tiny,tiny,tiny,tiny,tiny],0)\n\n\n\nT12, sigma12 = cope.Propagating(T1,sigma1,T2,sigma2)\n\nT23, sigma23 = cope.Propagating(T12,sigma12,T3,sigma3)\n\nT34, sigma34 = cope.Propagating(T23,sigma23,T4,sigma4)\nprint('Propagation took %.4f seconds' % (time.time() - starttime))\n\nTv = T34\nTv[:3,3] = Tv[:3,3] + np.array([0.001,0.002,-0.001])\nsigmav = np.diag([tiny,tiny,tiny,0.01,0.2,tiny])\n\nTe,sigmae,iters = cope.Fusing([T34,Tv],[sigma34,sigmav], maxiterations=10, retiter=True)\n\nprint('Took %.4f seconds and %d iterations' % (time.time() - starttime, iters))\n\ncope.Visualize([T12,T34,Te],[sigma12, sigma34,sigmae],100)\n# visualize(T,sigma,100,2)\n\n\n\nModuleNotFoundError: ignored\n\n\n\n\ndef Visualize(Tlist,sigmalist, nsamples = 100):\n  \"\"\"\n  Visualize an estimation (a point will be used to represent the translation position of a transformation)\n  @param Tlist:     a list of Transformations\n  @param sigmalist: a list of corresponding sigmas\n  @param nsamples:  the number of samples generated for each (T,sigma)\n  \"\"\"\n  import matplotlib.cm as cm\n  fig = plt.figure()\n  ax = fig.add_subplot(111, projection='3d')\n  cholsigmalist = []\n  colors = iter(cm.rainbow(np.linspace(0, 1, len(Tlist))))\n  for i in range(len(sigmalist)):\n    color = next(colors)\n    cholsigma = np.linalg.cholesky(sigmalist[i]).T\n    Tsample = []\n    for k in range(nsamples):\n      vecsample = np.dot(cholsigma,np.random.randn(6,1))\n      #vecsample = np.dot(cholsigma, np.random.uniform(-1,1,size = 6))\n      vecsample.resize(6)\n      Tsample = np.dot(VecToTran(vecsample), Tlist[i])\n      ax.scatter(Tsample[0,3],Tsample[1,3],Tsample[2,3], c = color)\n\n  ax.set_autoscaley_on(False)\n  ax.set_xlim([-0.5, 0.5])\n  ax.set_ylim([-0.5, 0.5])\n  ax.set_zlim([-0.5, 0.5])\n  ax.set_xlabel('X Label')\n  ax.set_ylabel('Y Label')\n  ax.set_zlabel('Z Label')\n  print(\"plotting now \")\n  plt.savefig('/content/plot.png')\n  plt.show()\n  return True\n\n\npython3: can't open file '/content/setup.py': [Errno 2] No such file or directory"
  },
  {
    "objectID": "posts/notebooks/2023-08-25-Uncertainty-Representation-Propagation-Robotics.html#uncertainty-of-pose-by-worst-case-bounds",
    "href": "posts/notebooks/2023-08-25-Uncertainty-Representation-Propagation-Robotics.html#uncertainty-of-pose-by-worst-case-bounds",
    "title": "Representation and propagation of uncertainty",
    "section": "",
    "text": "[11] R. H. Taylor, “The synthesis of manipulator control programs from task- level specifications.” Ph.D. dissertation, Stanford University, Stanford, CA, USA, 1976, aAI7707174.\n[12] R. A. Brooks, “Symbolic error analysis and robot planning,” The International Journal of Robotics Research, vol. 1, no. 4, pp. 29–78,"
  },
  {
    "objectID": "posts/notebooks/2023-08-25-Uncertainty-Representation-Propagation-Robotics.html#pose-of-object-as-probability-distribution-over-space-probabilistic-representation",
    "href": "posts/notebooks/2023-08-25-Uncertainty-Representation-Propagation-Robotics.html#pose-of-object-as-probability-distribution-over-space-probabilistic-representation",
    "title": "Representation and propagation of uncertainty",
    "section": "",
    "text": "[9] S. Su and C. Lee, “Uncertainty manipulation and propagation and verification of applicability of actions in assembly tasks,” in IEEE International Conference on Robotics and Automation, vol. 3, 1991, pp. 2471–2476\n[13] S.-F. Su and C. G. Lee, “Manipulation and propagation of uncertainty and verification of applicability of actions in assembly tasks,” Systems Science and Cybernetics, IEEE Transactions on, vol. 22, no. 6, pp. 1376– 1389, 1992."
  },
  {
    "objectID": "posts/notebooks/2023-08-25-Uncertainty-Representation-Propagation-Robotics.html#application-of-probability-pose-for-applications-propagation-fusion-etc",
    "href": "posts/notebooks/2023-08-25-Uncertainty-Representation-Propagation-Robotics.html#application-of-probability-pose-for-applications-propagation-fusion-etc",
    "title": "Representation and propagation of uncertainty",
    "section": "",
    "text": "[3] R. Smith, M. Self, and P. Cheeseman, “Estimating uncertain spatial relationships in robotics,” in Autonomous robot vehicles. Springer, 1990, pp. 167–193.\n[4] H. F. Durrant-Whyte, “Uncertainty geometry in robotics,” IEEE Journal of Robotics and Automation, vol. 4, no. 1, pp. 23–31, 1988.\n[14] R. A. Brooks, “Visual map making for a mobile robot,” in Robotics and Automation, 1985. Proceedings. IEEE International Conference on, vol. 2. IEEE, 1985, pp. 824–829.\n[15] R. C. Smith and P. Cheeseman, “On the representation and estimation of spatial uncertainty,” IEEE Journal of Robotics and Automation, vol. 5, no. 4, pp. 56–68, 1986."
  },
  {
    "objectID": "posts/notebooks/2023-08-25-Uncertainty-Representation-Propagation-Robotics.html#rigours-treatment-of-probabilistic-representation-and-propagation-uncertainty-on-so3-se3",
    "href": "posts/notebooks/2023-08-25-Uncertainty-Representation-Propagation-Robotics.html#rigours-treatment-of-probabilistic-representation-and-propagation-uncertainty-on-so3-se3",
    "title": "Representation and propagation of uncertainty",
    "section": "",
    "text": "[5] Y. Wang and G. S. Chirikjian, “Nonparametric second-order theory of error propagation on motion groups,” International Journal of Robotics Research, vol. 27, no. 11-12, pp. 1258–1273, 2008.\n[6] T. D. Barfoot and P. T. Furgale, “Associating uncertainty with three- dimensional poses for use in estimation problems,” IEEE Transactions on Robotics, vol. 30, no. 3, pp. 679 – 693, June 2014.\n[16] G. Chirikjian, Stochastic Models, Information Theory, and Lie Groups, Volume 1: Classical Results and Geometric Methods. Springer Science & Business Media, 2009, vol. 1.\n[17] ——, Stochastic Models, Information Theory, and Lie Groups, Volume 2: Analytic Methods and Modern Applications. Springer Science & Business Media, 2011, vol. 2.\n\n\n!git clone https://github.com/dinhhuy2109/python-cope.git\n\nCloning into 'python-cope'...\nremote: Enumerating objects: 361, done.\nremote: Total 361 (delta 0), reused 0 (delta 0), pack-reused 361\nReceiving objects: 100% (361/361), 1.17 MiB | 3.46 MiB/s, done.\nResolving deltas: 100% (199/199), done.\n\n\n\n!pip install trimesh -q\n\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/685.4 kB ? eta -:--:--     ━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 71.7/685.4 kB 1.9 MB/s eta 0:00:01     ━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━ 317.4/685.4 kB 4.4 MB/s eta 0:00:01     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━ 614.4/685.4 kB 5.8 MB/s eta 0:00:01     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 685.4/685.4 kB 5.1 MB/s eta 0:00:00\n\n\n\nfrom importlib import reload  # Python 3.4+\n\n\n!cd python-cope && sudo pip install -e .\n\nObtaining file:///content/python-cope\n  Preparing metadata (setup.py) ... done\nInstalling collected packages: cope\n  Attempting uninstall: cope\n    Found existing installation: cope 1.0.0\n    Uninstalling cope-1.0.0:\n      Successfully uninstalled cope-1.0.0\n  Running setup.py develop for cope\nSuccessfully installed cope-1.0.0\n\n\n\nimport numpy  as np\nimport cope\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.pyplot as plt\nimport time\n\nstarttime = time.time()\ntiny = 1e-5\n\nT1 = np.eye(4)\nsigma1 = np.diag([tiny,tiny,tiny,tiny,tiny,tiny],0)\n\nT2 = np.eye(4)\nT2[:3,3] = np.array([0,0.15,0])\nsigma2 = np.diag([tiny,tiny,tiny,0.01,tiny,0.01],0)\n\nT3 = np.eye(4)\nT3[:3,3] = np.array([0,0,-0.03])\nsigma3 = np.diag([tiny,tiny,tiny,tiny,tiny,0.1],0)\n\nT4 = np.eye(4)\nT4[:3,3] = np.array([0,0.14,0])\nsigma4 = np.diag([tiny,tiny,tiny,tiny,tiny,tiny],0)\n\n\n\nT12, sigma12 = cope.Propagating(T1,sigma1,T2,sigma2)\n\nT23, sigma23 = cope.Propagating(T12,sigma12,T3,sigma3)\n\nT34, sigma34 = cope.Propagating(T23,sigma23,T4,sigma4)\nprint('Propagation took %.4f seconds' % (time.time() - starttime))\n\nTv = T34\nTv[:3,3] = Tv[:3,3] + np.array([0.001,0.002,-0.001])\nsigmav = np.diag([tiny,tiny,tiny,0.01,0.2,tiny])\n\nTe,sigmae,iters = cope.Fusing([T34,Tv],[sigma34,sigmav], maxiterations=10, retiter=True)\n\nprint('Took %.4f seconds and %d iterations' % (time.time() - starttime, iters))\n\ncope.Visualize([T12,T34,Te],[sigma12, sigma34,sigmae],100)\n# visualize(T,sigma,100,2)\n\n\n\nModuleNotFoundError: ignored\n\n\n\n\ndef Visualize(Tlist,sigmalist, nsamples = 100):\n  \"\"\"\n  Visualize an estimation (a point will be used to represent the translation position of a transformation)\n  @param Tlist:     a list of Transformations\n  @param sigmalist: a list of corresponding sigmas\n  @param nsamples:  the number of samples generated for each (T,sigma)\n  \"\"\"\n  import matplotlib.cm as cm\n  fig = plt.figure()\n  ax = fig.add_subplot(111, projection='3d')\n  cholsigmalist = []\n  colors = iter(cm.rainbow(np.linspace(0, 1, len(Tlist))))\n  for i in range(len(sigmalist)):\n    color = next(colors)\n    cholsigma = np.linalg.cholesky(sigmalist[i]).T\n    Tsample = []\n    for k in range(nsamples):\n      vecsample = np.dot(cholsigma,np.random.randn(6,1))\n      #vecsample = np.dot(cholsigma, np.random.uniform(-1,1,size = 6))\n      vecsample.resize(6)\n      Tsample = np.dot(VecToTran(vecsample), Tlist[i])\n      ax.scatter(Tsample[0,3],Tsample[1,3],Tsample[2,3], c = color)\n\n  ax.set_autoscaley_on(False)\n  ax.set_xlim([-0.5, 0.5])\n  ax.set_ylim([-0.5, 0.5])\n  ax.set_zlim([-0.5, 0.5])\n  ax.set_xlabel('X Label')\n  ax.set_ylabel('Y Label')\n  ax.set_zlabel('Z Label')\n  print(\"plotting now \")\n  plt.savefig('/content/plot.png')\n  plt.show()\n  return True\n\n\npython3: can't open file '/content/setup.py': [Errno 2] No such file or directory"
  },
  {
    "objectID": "posts/notebooks/2020-05-05-uncertainty-regression-robustness.html",
    "href": "posts/notebooks/2020-05-05-uncertainty-regression-robustness.html",
    "title": "Regression Uncertainty Robustness",
    "section": "",
    "text": "Robustness in learning is the capacity of the network to handle corrupted data (training data or test data).\n\n\nTraining time robustness is capability of the model to overcome corrupted training data(input or labels).\nTesting time robustness is the capability of the model to corrupted data during testing eg. Adversarial test."
  },
  {
    "objectID": "posts/notebooks/2020-05-05-uncertainty-regression-robustness.html#robustness",
    "href": "posts/notebooks/2020-05-05-uncertainty-regression-robustness.html#robustness",
    "title": "Regression Uncertainty Robustness",
    "section": "",
    "text": "Robustness in learning is the capacity of the network to handle corrupted data (training data or test data).\n\n\nTraining time robustness is capability of the model to overcome corrupted training data(input or labels).\nTesting time robustness is the capability of the model to corrupted data during testing eg. Adversarial test."
  },
  {
    "objectID": "posts/notebooks/2020-05-05-uncertainty-regression-robustness.html#objective",
    "href": "posts/notebooks/2020-05-05-uncertainty-regression-robustness.html#objective",
    "title": "Regression Uncertainty Robustness",
    "section": "Objective",
    "text": "Objective\nThe objective of this blog is to understand the robustness capability of different loss fucntions with respect to training time dataset corruption.\nThe loss functions in considerations are: 1. Gaussian negative log likelihood 2. Laplace negative log likelihood 3. Cauchy negative log likelihood"
  },
  {
    "objectID": "posts/notebooks/2020-05-05-uncertainty-regression-robustness.html#data",
    "href": "posts/notebooks/2020-05-05-uncertainty-regression-robustness.html#data",
    "title": "Regression Uncertainty Robustness",
    "section": "Data",
    "text": "Data\nLets start with plotting our toy dataset.\nAs you can see the dataset has some corrupted labels which should not be considered while learning.\n\nfig, ax = plt.subplots(figsize=(5,5))\nax.scatter(x.data.numpy(),y.data.numpy())\nax.axis('equal')\nax.set_xlabel('$x$')\nax.set_ylabel('$y$')\nax.axis(\"equal\")\n\nax.annotate('noisy labels', xy=(0.25, 0.8), xytext=(0.0, 0.6),\n            arrowprops=dict(facecolor='red', shrink=0.05))\n\nax.annotate('noisy labels', xy=(0.85, 0.1), xytext=(0.7, 0.3),\n            arrowprops=dict(facecolor='red', shrink=0.05))\n\nText(0.7, 0.3, 'noisy labels')"
  },
  {
    "objectID": "posts/notebooks/2020-05-05-uncertainty-regression-robustness.html#model",
    "href": "posts/notebooks/2020-05-05-uncertainty-regression-robustness.html#model",
    "title": "Regression Uncertainty Robustness",
    "section": "Model",
    "text": "Model\nWe will train a simple linear model\n\n# this is one way to define a network\nclass Net(torch.nn.Module):\n    def __init__(self, n_feature, n_hidden, n_output):\n        super(Net, self).__init__()\n        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n\n    def forward(self, x):\n        x = F.relu(self.hidden(x))      # activation function for hidden layer\n        x = self.predict(x)             # linear output\n        return x"
  },
  {
    "objectID": "posts/notebooks/2020-05-05-uncertainty-regression-robustness.html#mean-square-loss-robustness-analysis",
    "href": "posts/notebooks/2020-05-05-uncertainty-regression-robustness.html#mean-square-loss-robustness-analysis",
    "title": "Regression Uncertainty Robustness",
    "section": "Mean Square Loss robustness analysis",
    "text": "Mean Square Loss robustness analysis\n\nloss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n# Fit a linear regression using mean squared error.\nregression = Net(n_feature=1, n_hidden=1, n_output=1)     # RegressionModel() \nparams = regression.parameters()\noptimizer = torch.optim.Adam(params, lr = 0.001) \n\n\nAnalysis MSE Regression"
  },
  {
    "objectID": "posts/notebooks/2020-05-05-uncertainty-regression-robustness.html#gaussian-loss-robustness-analysis",
    "href": "posts/notebooks/2020-05-05-uncertainty-regression-robustness.html#gaussian-loss-robustness-analysis",
    "title": "Regression Uncertainty Robustness",
    "section": "Gaussian Loss Robustness analysis",
    "text": "Gaussian Loss Robustness analysis\nFor gaussian loss the model in addition to the prediction also predicts the confidence in the prediction in the form of the gaussian variance.\n\n# this is one way to define a network\nclass GaussianNet(torch.nn.Module):\n    def __init__(self, n_feature, n_hidden, n_output):\n        super(GaussianNet, self).__init__()\n        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n        self.variance = torch.nn.Linear(n_hidden, 1)   # variance layer\n        #torch.nn.init.xavier_uniform_(self.variance.weight)\n        #torch.nn.init.normal_(self.variance.weight, mean=1.0)\n        #torch.nn.init.normal_(self.variance.bias, mean=0.0)\n\n    def forward(self, x):\n        x = F.relu(self.hidden(x))      # activation function for hidden layer\n        out = self.predict(x)             # linear output\n        var = F.softplus(self.variance(x))\n\n        return out, var\n\n\nloss_func = torch.nn.GaussianNLLLoss( reduction='none')\n# Fit a linear regression using mean squared error.\nregression = GaussianNet(n_feature=1, n_hidden=2, n_output=1)     # RegressionModel() \nparams = regression.parameters()\noptimizer = torch.optim.Adam(params, lr = 0.001) \n\n\nSmaller comparable network"
  },
  {
    "objectID": "posts/notebooks/2020-05-05-uncertainty-regression-robustness.html#laplace-loss-function",
    "href": "posts/notebooks/2020-05-05-uncertainty-regression-robustness.html#laplace-loss-function",
    "title": "Regression Uncertainty Robustness",
    "section": "Laplace loss function",
    "text": "Laplace loss function\n\ndef LaplaceNLLLoss(input, target, scale, eps=1e-06, reduction='mean'):\n  loss = torch.log(2*scale) + torch.abs(input - target)/scale\n\n  # Inputs and targets much have same shape\n  input = input.view(input.size(0), -1)\n  target = target.view(target.size(0), -1)\n  if input.size() != target.size():\n      raise ValueError(\"input and target must have same size\")\n\n  # Second dim of scale must match that of input or be equal to 1\n  scale = scale.view(input.size(0), -1)\n  if scale.size(1) != input.size(1) and scale.size(1) != 1:\n      raise ValueError(\"scale is of incorrect size\")\n\n  # Check validity of reduction mode\n  if reduction != 'none' and reduction != 'mean' and reduction != 'sum':\n      raise ValueError(reduction + \" is not valid\")\n\n  # Entries of var must be non-negative\n  if torch.any(scale &lt; 0):\n      raise ValueError(\"scale has negative entry/entries\")\n\n  # Clamp for stability\n  scale = scale.clone()\n  with torch.no_grad():\n      scale.clamp_(min=eps)\n\n  # Calculate loss (without constant)\n  loss = (torch.log(2*scale) + torch.abs(input - target) / scale).view(input.size(0), -1).sum(dim=1)\n\n\n  # Apply reduction\n  if reduction == 'mean':\n      return loss.mean()\n  elif reduction == 'sum':\n      return loss.sum()\n  else:\n      return loss\n\n    \n\n\nloss_func = LaplaceNLLLoss\n# Fit a linear regression using mean squared error.\nregression = GaussianNet(n_feature=1, n_hidden=2, n_output=1)     # RegressionModel() \nparams = regression.parameters()\noptimizer = torch.optim.Adam(params, lr = 0.001) \n\n#####################\n# Training\n####################\n\n\nmy_images = []\nfig, (ax1, ax2) = plt.subplots(figsize=(20,7), nrows=1, ncols=2)\n\n# train the network\nfor epoch in range(4000):\n   \n\n    prediction, scales = regression(x) \n\n    loss_all = loss_func(prediction, y, scales, reduction='none')     # must be (1. nn output, 2. target)\n    loss = torch.mean(loss_all)\n    #if t%10 == 0: print (loss)\n\n    optimizer.zero_grad()   # clear gradients for next train\n    loss.backward()         # backpropagation, compute gradients\n    optimizer.step()        # apply gradients\n    if np.mod(epoch, 100) == 0:\n      sort_x, _ = torch.sort(x, dim=0)\n      sort_prediction, sort_scales = regression(sort_x) \n    \n      print (loss)\n\n      # plot and show learning process\n      plt.cla()\n      ax1.cla()\n      ax1.set_title('Regression Analysis', fontsize=35)\n      ax1.set_xlabel('Independent variable', fontsize=24)\n      ax1.set_ylabel('Dependent variable', fontsize=24)\n      ax1.set_xlim(-0.05, 1.0)\n      ax1.set_ylim(-0.1, 1.0)\n      ax1.scatter(x.data.numpy(), y.data.numpy(), color = \"orange\")\n      ax1.plot(sort_x.data.numpy(), sort_prediction.data.numpy(), 'g-', lw=3)\n      dyfit = 2 * sort_scales.data.numpy()  # 2*sigma ~ 95% confidence region\n\n      ax1.fill_between( np.squeeze(sort_x.data.numpy()), \n                         np.squeeze(sort_prediction.data.numpy() - dyfit),  \n                       np.squeeze(sort_prediction.data.numpy()  + dyfit),\n                 color='gray', alpha=0.2)\n      \n      #l2_loss_plot_x = np.linspace(0,1,num=100)\n      #y_plot_true = l2_loss_plot_x * scale_true + shift_true\n      #ax1.plot(l2_loss_plot_x, y_plot_true, 'k')\n\n      ax1.text(1.0, 0.1, 'Step = %d' % epoch, fontdict={'size': 24, 'color':  'red'})\n      ax1.text(1.0, 0, 'Loss = %.4f' % loss.data.numpy(),\n              fontdict={'size': 24, 'color':  'red'})\n      diff = prediction.data.numpy() - y.data.numpy()\n\n      ax2.cla()\n      l2_loss_plot_x = np.linspace(-1,1,num=100)\n      ax2.plot(l2_loss_plot_x, 0.5*l2_loss_plot_x**2, color=\"green\", lw=3, alpha=0.5)\n      ax2.scatter(diff,  loss_all.data.numpy())\n      ax2.set_title('Loss ', fontsize=35)\n      ax2.set_xlabel('y - y_pred')\n      ax2.set_ylim(-3.1, 3)\n      ax2.set_xlim(-1, 1)\n      # Used to return the plot as an image array \n      # (https://ndres.me/post/matplotlib-animated-gifs-easily/)\n      fig.canvas.draw()       # draw the canvas, cache the renderer\n      image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n      image  = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n\n      my_images.append(image)\n\ntensor(1.4615, grad_fn=&lt;MeanBackward0&gt;)\ntensor(0.8189, grad_fn=&lt;MeanBackward0&gt;)\ntensor(0.1342, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.2028, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.6679, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8267, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8590, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8677, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8730, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8773, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8809, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8837, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8857, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8873, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8879, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8891, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8894, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8898, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8901, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8902, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8901, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8901, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8903, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8901, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8902, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8901, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8903, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8904, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8902, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8900, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8903, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8903, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8902, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8905, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8903, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8903, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8905, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8900, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8904, grad_fn=&lt;MeanBackward0&gt;)\ntensor(-0.8905, grad_fn=&lt;MeanBackward0&gt;)\n\n\n\n\n\n\nAnalysis Laplace NLL Regression\n\n\nThe line is better fit to the data by avoiding to the noisy data."
  },
  {
    "objectID": "posts/notebooks/2020-05-05-uncertainty-regression-robustness.html#cauchy-nll-loss-function-robustness-analysis",
    "href": "posts/notebooks/2020-05-05-uncertainty-regression-robustness.html#cauchy-nll-loss-function-robustness-analysis",
    "title": "Regression Uncertainty Robustness",
    "section": "Cauchy NLL Loss function Robustness analysis",
    "text": "Cauchy NLL Loss function Robustness analysis\n\ndef CauchyNLLLoss(input, target, scale, eps=1e-06, reduction='mean'):\n\n  # Inputs and targets much have same shape\n  input = input.view(input.size(0), -1)\n  target = target.view(target.size(0), -1)\n  if input.size() != target.size():\n      raise ValueError(\"input and target must have same size\")\n\n  # Second dim of scale must match that of input or be equal to 1\n  scale = scale.view(input.size(0), -1)\n  if scale.size(1) != input.size(1) and scale.size(1) != 1:\n      raise ValueError(\"scale is of incorrect size\")\n\n  # Check validity of reduction mode\n  if reduction != 'none' and reduction != 'mean' and reduction != 'sum':\n      raise ValueError(reduction + \" is not valid\")\n\n  # Entries of var must be non-negative\n  if torch.any(scale &lt; 0):\n      raise ValueError(\"scale has negative entry/entries\")\n\n  # Clamp for stability\n  scale = scale.clone()\n  with torch.no_grad():\n      scale.clamp_(min=eps)\n\n  # Calculate loss (without constant)\n  loss = (torch.log(3.14*scale) + torch.log(1 + ((input - target)**2)/scale**2)) .view(input.size(0), -1).sum(dim=1)\n\n\n  # Apply reduction\n  if reduction == 'mean':\n      return loss.mean()\n  elif reduction == 'sum':\n      return loss.sum()\n  else:\n      return loss\n\n    \n\n\nloss_func = CauchyNLLLoss\n# Fit a linear regression using mean squared error.\nregression = GaussianNet(n_feature=1, n_hidden=2, n_output=1)     # RegressionModel() \nparams = regression.parameters()\noptimizer = torch.optim.Adam(params, lr = 0.001) \n\n#####################\n# Training\n####################\n\n\nmy_images = []\nfig, (ax1, ax2) = plt.subplots(figsize=(20,7), nrows=1, ncols=2)\n\n# train the network\nfor epoch in range(4000):\n  \n    prediction, sigmas = regression(x)     # input x and predict based on x\n\n    loss_all = loss_func(prediction, y, sigmas, reduction='none')     # must be (1. nn output, 2. target)\n    loss = torch.mean(loss_all)\n    #if t%10 == 0: print (loss)\n\n    optimizer.zero_grad()   # clear gradients for next train\n    loss.backward()         # backpropagation, compute gradients\n    optimizer.step()        # apply gradients\n    if np.mod(epoch, 100) == 0:\n      #print (loss)\n      sort_x, _ = torch.sort(x, dim=0)\n      sort_prediction, sort_sigmas = regression(sort_x)     # input x and predict based on x\n\n\n      # plot and show learning process\n      plt.cla()\n      ax1.cla()\n      ax1.set_title('Regression Analysis', fontsize=35)\n      ax1.set_xlabel('Independent variable', fontsize=24)\n      ax1.set_ylabel('Dependent variable', fontsize=24)\n      ax1.set_xlim(-0.05, 1.0)\n      ax1.set_ylim(-0.1, 1.0)\n      ax1.scatter(x.data.numpy(), y.data.numpy(), color = \"orange\")\n      ax1.plot(sort_x.data.numpy(), sort_prediction.data.numpy(), 'g-', lw=3)\n      dyfit = 2 * np.sqrt(sort_sigmas.data.numpy())  # 2*sigma ~ 95% confidence region\n\n      ax1.fill_between( np.squeeze(sort_x.data.numpy()), \n                         np.squeeze(sort_prediction.data.numpy() - dyfit),  \n                       np.squeeze(sort_prediction.data.numpy()  + dyfit),\n                 color='gray', alpha=0.2)\n      \n      #l2_loss_plot_x = np.linspace(0,1,num=100)\n      #y_plot_true = l2_loss_plot_x * scale_true + shift_true\n      #ax1.plot(l2_loss_plot_x, y_plot_true, 'k')\n\n      ax1.text(1.0, 0.1, 'Step = %d' % epoch, fontdict={'size': 24, 'color':  'red'})\n      ax1.text(1.0, 0, 'Loss = %.4f' % loss.data.numpy(),\n              fontdict={'size': 24, 'color':  'red'})\n      diff = prediction.data.numpy() - y.data.numpy()\n\n      ax2.cla()\n      l2_loss_plot_x = np.linspace(-1,1,num=100)\n      ax2.plot(l2_loss_plot_x, 0.5*l2_loss_plot_x**2, color=\"green\", lw=3, alpha=0.5)\n      ax2.scatter(diff,  loss_all.data.numpy())\n      ax2.set_title('Loss ', fontsize=35)\n      ax2.set_xlabel('y - y_pred')\n      ax2.set_ylim(-3.1, 3)\n      ax2.set_xlim(-1, 1)\n      # Used to return the plot as an image array \n      # (https://ndres.me/post/matplotlib-animated-gifs-easily/)\n      fig.canvas.draw()       # draw the canvas, cache the renderer\n      image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n      image  = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n\n      my_images.append(image)\n\n\n\n\n\nAnalysis Cauchy NLL Regression\n\n\nThe line is better fit to the data than the gaussian by avoiding to the noisy data."
  },
  {
    "objectID": "posts/notebooks/2020-05-05-uncertainty-regression-robustness.html#plotting-loss-surface",
    "href": "posts/notebooks/2020-05-05-uncertainty-regression-robustness.html#plotting-loss-surface",
    "title": "Regression Uncertainty Robustness",
    "section": "Plotting Loss Surface",
    "text": "Plotting Loss Surface\n\nsigma_2 = np.logspace(0.1, 1, num=70, base=10 ) \nprint (sigma_2.max(), sigma_2.min())\ndiff = np.linspace(-3, 5, num=70)\ndef gauss_logL(xbar, sigma_2, mu):\n  return -0.5*np.log(2*np.pi)-0.5*np.log(sigma_2)-0.5*(xbar -mu)**2/sigma_2\nxbar = 1\nlogL = gauss_logL(xbar, sigma_2[:, np.newaxis], diff)\nlogL -= logL.max()\n\nx_grid, sigma_grid = np.meshgrid(diff, sigma_2)\nlogL = gauss_logL(xbar, sigma_grid, x_grid)\nlogL = logL*-1\n\n10.0 1.2589254117941673\n\n\n\nfig, ax = plt.subplots(figsize=(10,8),constrained_layout=True)\n\nax = plt.axes(projection='3d')\nax.plot_surface(x_grid, sigma_grid, logL, rstride=1, cstride=1,\n                cmap='viridis', edgecolor='none')\nax.set_title('NLL loss surface');\n\n\n\n\n\nfrom itertools import cycle\ncycol = cycle('bgrcmk')\n\nfig, ax = plt.subplots(figsize=(10,7))\n\n#for s_2 in [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 2]:\nfor s_2 in [1e-3, 1e-2, 2e-3]:\n\n  x = np.linspace(-3, 3, num=100)\n  logL = (-1*gauss_logL(0, s_2, x))/1000\n  ax.plot(x, 0.5*x**2, color=\"cyan\", lw=3, alpha=0.5)\n  ax.plot(x,logL, c=next(cycol))"
  },
  {
    "objectID": "posts/notebooks/2021-01-01-one-vs-all-classifier-revisiting.html#the-paper",
    "href": "posts/notebooks/2021-01-01-one-vs-all-classifier-revisiting.html#the-paper",
    "title": "One-vs-All Classifier",
    "section": "The paper",
    "text": "The paper\nPadhy, S. et al. (2020) ‘Revisiting One-vs-All Classifiers for Predictive Uncertainty and Out-of-Distribution Detection in Neural Networks’, arXiv:2007.05134 [cs, stat]. Available at: http://arxiv.org/abs/2007.05134 (Accessed: 26 January 2021)."
  },
  {
    "objectID": "posts/notebooks/2021-01-01-one-vs-all-classifier-revisiting.html#abstract",
    "href": "posts/notebooks/2021-01-01-one-vs-all-classifier-revisiting.html#abstract",
    "title": "One-vs-All Classifier",
    "section": "Abstract",
    "text": "Abstract\n\nProblem\n\nOut-of-Distribution - finding on which samples the classifier should not predict\nOOD using uncertainty estimate\nuncertainty estimate - correctly estimate the confidence (uncertainty) in the prediction\n\n\n\nHow\n\nUsing oves-vs-all classifier\ndistance-based logit representation to encode uncertainty"
  },
  {
    "objectID": "posts/notebooks/2021-01-01-one-vs-all-classifier-revisiting.html#unique-selling-points",
    "href": "posts/notebooks/2021-01-01-one-vs-all-classifier-revisiting.html#unique-selling-points",
    "title": "One-vs-All Classifier",
    "section": "Unique selling points",
    "text": "Unique selling points\n\nwe first study the contribution of the loss function used during training to the quality of predictive uncertainty of models.\nSpecifically, we show why the parametrization of the probabilities underlying softmax cross-entropy loss are ill-suited for uncertainty estimation.\nWe then propose two simple replacements to the parametrization of the probability distribution:\n\na one-vs-all normalization scheme that does not force all points in the input space to map to one of the classes, thereby naturally capturing the notion of “none of the above”, and\na distance-based logit representation to encode uncertainty as a function of distance to the training manifold."
  },
  {
    "objectID": "posts/notebooks/2020-05-27-uncertainty-regression.html",
    "href": "posts/notebooks/2020-05-27-uncertainty-regression.html",
    "title": "Regression Uncertainty",
    "section": "",
    "text": "In machine learning problems we take input data \\(x\\) and use it to predict the output data \\(y\\). If the predicted data is continuous or discrete. When the output data \\(y\\) is continuous then the problem is called regression while if its is discrete then the problem is called classification .\nDeep neural networks have prooved to be a good tool for solving regression tasks. Currently there are new improvements in making the regression task robust by not only predicting the output data \\(y\\) but also the corresponding uncertainty.\nIn this blog we will look into 2 methods of representing uncertatinty from literature. 1. Epistemic uncertatinty (Data uncertatinty) [1] 2. Aleotary uncertainty (Model uncertatinty) [2]\n\n\n\nIn regression task can be modelled in 3 different methods based on which all uncertainty needs to be accounted for during architecture of the deep network. The different layers and their hierarchichal structre is represented in the image above.\n\n\n\n\n\n\n\n\n\n\nName\nloss function\nuncertatinty\noutput\ndistribution\n\n\n\n\nDeterministic Regression\nmean square error\nnot modeled\n\\(\\hat{y}\\)\n-\n\n\nLikelihood Regression\nMaximum likelihood estimation\ndata\n\\(\\hat{y}\\), \\(\\sigma^2\\)\nNormal\n\n\nEvidential Regression\nMaximum likelihood estimation\ndata + model\n\\(\\hat{y}\\),\\(\\alpha\\), \\(\\beta\\), \\(\\lambda\\)\nNormal inverse gamma"
  },
  {
    "objectID": "posts/notebooks/2020-05-27-uncertainty-regression.html#regression",
    "href": "posts/notebooks/2020-05-27-uncertainty-regression.html#regression",
    "title": "Regression Uncertainty",
    "section": "",
    "text": "In machine learning problems we take input data \\(x\\) and use it to predict the output data \\(y\\). If the predicted data is continuous or discrete. When the output data \\(y\\) is continuous then the problem is called regression while if its is discrete then the problem is called classification .\nDeep neural networks have prooved to be a good tool for solving regression tasks. Currently there are new improvements in making the regression task robust by not only predicting the output data \\(y\\) but also the corresponding uncertainty.\nIn this blog we will look into 2 methods of representing uncertatinty from literature. 1. Epistemic uncertatinty (Data uncertatinty) [1] 2. Aleotary uncertainty (Model uncertatinty) [2]\n\n\n\nIn regression task can be modelled in 3 different methods based on which all uncertainty needs to be accounted for during architecture of the deep network. The different layers and their hierarchichal structre is represented in the image above.\n\n\n\n\n\n\n\n\n\n\nName\nloss function\nuncertatinty\noutput\ndistribution\n\n\n\n\nDeterministic Regression\nmean square error\nnot modeled\n\\(\\hat{y}\\)\n-\n\n\nLikelihood Regression\nMaximum likelihood estimation\ndata\n\\(\\hat{y}\\), \\(\\sigma^2\\)\nNormal\n\n\nEvidential Regression\nMaximum likelihood estimation\ndata + model\n\\(\\hat{y}\\),\\(\\alpha\\), \\(\\beta\\), \\(\\lambda\\)\nNormal inverse gamma"
  },
  {
    "objectID": "posts/notebooks/2020-05-27-uncertainty-regression.html#dataset",
    "href": "posts/notebooks/2020-05-27-uncertainty-regression.html#dataset",
    "title": "Regression Uncertainty",
    "section": "Dataset",
    "text": "Dataset\nWe will start by creating a one dimension synthetic regression dataset. The synthetic dataset has added priori noise. The dataset is generated from \\[ y =\\frac{ \\sin(3x)}{3x} + \\epsilon \\] where \\(\\epsilon \\sim \\mathcal{N}(0, 0.02)\\)\nThe training dataset consist of \\(x\\) values between \\(-3 \\leq x \\leq 3\\); while the test dataset consist of values outside of training \\(-4 \\leq x \\leq 4\\)"
  },
  {
    "objectID": "posts/notebooks/2020-05-27-uncertainty-regression.html#model",
    "href": "posts/notebooks/2020-05-27-uncertainty-regression.html#model",
    "title": "Regression Uncertainty",
    "section": "Model",
    "text": "Model\nWe will be using a common model for all the different learning formulation.\n\n\n# this is one way to define a network\nclass Net(torch.nn.Module):\n    def __init__(self, n_feature, n_hidden, n_output):\n        super(Net, self).__init__()\n      \n        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n        self.hidden_2 = torch.nn.Linear(n_hidden, n_hidden)\n        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n\n    def forward(self, x):\n        x = self.hidden(x)\n        x = F.relu(self.hidden_2(x))      # activation function for hidden layer\n        x = self.predict(x)             # linear output\n        return x"
  },
  {
    "objectID": "posts/notebooks/2020-05-27-uncertainty-regression.html#deterministic-regression",
    "href": "posts/notebooks/2020-05-27-uncertainty-regression.html#deterministic-regression",
    "title": "Regression Uncertainty",
    "section": "Deterministic Regression",
    "text": "Deterministic Regression\n\nLoss function\nMean square error \\[ \\mathcal{L} = \\frac{1}{2} \\vert \\vert y_i - \\hat{y} \\vert \\vert ^2\\]\n\n\nOutput\nThe model will have single output \\(\\hat{y}\\)\n\n\n\nmsenet = Net(n_feature=1, n_hidden=10, n_output=1)     # define the network\nprint(msenet)  # net architecture\n\n#optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\noptimizer = torch.optim.Adam(msenet.parameters(), lr=0.001)\nloss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n\n\n# train the network\nfor t in range(10000):\n  \n    prediction = msenet(x)     # input x and predict based on x\n\n    loss = loss_func(prediction, y)     # must be (1. nn output, 2. target)\n\n    optimizer.zero_grad()   # clear gradients for next train\n    loss.backward()         # backpropagation, compute gradients\n    optimizer.step()        # apply gradients\n    if t%1000 == 0: print(loss)\n\nprediction = msenet(test_x)\nplot_prediction(test_x, test_y, prediction)\n\nNet(\n  (hidden): Linear(in_features=1, out_features=10, bias=True)\n  (hidden_2): Linear(in_features=10, out_features=10, bias=True)\n  (predict): Linear(in_features=10, out_features=1, bias=True)\n)\ntensor(0.5153, grad_fn=&lt;MseLossBackward&gt;)\ntensor(0.0478, grad_fn=&lt;MseLossBackward&gt;)\ntensor(0.0023, grad_fn=&lt;MseLossBackward&gt;)\ntensor(0.0019, grad_fn=&lt;MseLossBackward&gt;)\ntensor(0.0019, grad_fn=&lt;MseLossBackward&gt;)\ntensor(0.0019, grad_fn=&lt;MseLossBackward&gt;)\ntensor(0.0019, grad_fn=&lt;MseLossBackward&gt;)\ntensor(0.0019, grad_fn=&lt;MseLossBackward&gt;)\ntensor(0.0019, grad_fn=&lt;MseLossBackward&gt;)\ntensor(0.0019, grad_fn=&lt;MseLossBackward&gt;)"
  },
  {
    "objectID": "posts/notebooks/2020-05-27-uncertainty-regression.html#likelihood-regression",
    "href": "posts/notebooks/2020-05-27-uncertainty-regression.html#likelihood-regression",
    "title": "Regression Uncertainty",
    "section": "Likelihood Regression",
    "text": "Likelihood Regression\n\nLoss function\nIn here we will use the maximum likelihood estimation error, which is also called as the Negative log likelihood.\n\\[ \\mathcal{L} = -\\left(-0.5\\log(2\\pi) - 0.5\\sum\\log(\\sigma^2) - 0.5\\sum\\frac{(y - \\hat{y})^2}{\\sigma^2} \\right) \\]\n\n\nOutput\nWe will create a deep net with 2 output variables. - predicted output \\(\\hat{y}\\) - the variance of the normal distribution \\(\\sigma^2\\)"
  },
  {
    "objectID": "posts/notebooks/2020-05-27-uncertainty-regression.html#note",
    "href": "posts/notebooks/2020-05-27-uncertainty-regression.html#note",
    "title": "Regression Uncertainty",
    "section": "Note",
    "text": "Note\nWe aer also adding a regularizer \\(\\frac{ \\| y - \\hat{y} \\| }{ \\sigma^2}\\). This helps to regluarize the learning. It is inversely related to \\(\\sigma^2\\) and it scales based on distance from the actual value.\nThe regularizer ensures that values predicted far from true values have higher variance.So for values near to the predicted it gives less loss but values far away from prediction gives a large loss.\n\n# Loss Function\nclass MLELoss(torch.nn.Module):\n  def __init__(self, weight=None, size_average=True):\n    super(MLELoss, self).__init__()\n\n  def forward(self, inputs, targets, smooth=1):\n    \n    targets = targets.view(-1) #converting variable to single dimension\n\n    mu = inputs[:,0].view(-1) #extracting mu and sigma_2\n    logsigma_2 = inputs[:,1].view(-1) #logsigma and exp drives the variable to positive values always\n    sigma_2 = torch.exp(logsigma_2)\n\n    kl_divergence = (targets - mu)**2/sigma_2 #Regularizer \n    mse = -0.5 * torch.sum(((targets - mu)**2)/sigma_2)\n    sigma_trace = -0.5  * torch.sum(sigma_2)\n    log2pi = -0.5 *  np.log(2 * np.pi)\n    J =  mse + sigma_trace + log2pi\n \n    loss = -J + kl_divergence.sum()\n    return loss\n\n\nmlenet = Net(n_feature=1, n_hidden=10, n_output=2)     # define the network\nprint(mlenet)  # net architecture\n\noptimizer = torch.optim.Adam(mlenet.parameters(), lr=0.001)\nloss_func = MLELoss()  # this is for regression mean squared loss\n\n\n# train the network\nfor t in range(10000):\n  \n    prediction = mlenet(x)     # input x and predict based on x\n\n    loss = loss_func(prediction, y)     # must be (1. nn output, 2. target)\n\n    optimizer.zero_grad()   # clear gradients for next train\n    loss.backward()         # backpropagation, compute gradients\n    optimizer.step()        # apply gradients\n    if t%1000 == 0: \n      print(loss)\n\nprediction = mlenet(test_x)\nmu = prediction[:,0]\nsigma2 = torch.exp(prediction[:,1])\nsigma = torch.sqrt(sigma2)\nplot_prediction(test_x, test_y, mu, sigma)\n\nNet(\n  (hidden): Linear(in_features=1, out_features=10, bias=True)\n  (hidden_2): Linear(in_features=10, out_features=10, bias=True)\n  (predict): Linear(in_features=10, out_features=2, bias=True)\n)\ntensor(68.1900, grad_fn=&lt;AddBackward0&gt;)\ntensor(6.4617, grad_fn=&lt;AddBackward0&gt;)\ntensor(6.1683, grad_fn=&lt;AddBackward0&gt;)\ntensor(6.1068, grad_fn=&lt;AddBackward0&gt;)\ntensor(6.0325, grad_fn=&lt;AddBackward0&gt;)\ntensor(5.9853, grad_fn=&lt;AddBackward0&gt;)\ntensor(5.9657, grad_fn=&lt;AddBackward0&gt;)\ntensor(5.9485, grad_fn=&lt;AddBackward0&gt;)\ntensor(5.9929, grad_fn=&lt;AddBackward0&gt;)\ntensor(5.9366, grad_fn=&lt;AddBackward0&gt;)"
  },
  {
    "objectID": "posts/notebooks/2020-05-27-uncertainty-regression.html#evidential-regression",
    "href": "posts/notebooks/2020-05-27-uncertainty-regression.html#evidential-regression",
    "title": "Regression Uncertainty",
    "section": "Evidential Regression",
    "text": "Evidential Regression\nEvidential regression is based on paper [2] (Amini & e.t.al, 2019), which is based on the ideas of [3, 4] that if we represent the output of the model with a higher order data distribution its possible to model the data and model uncertainties.\n\nLoss\n\\[ \\mathcal{L} = \\left( \\frac{ \\Gamma(\\alpha - 0.5)}{4\\Gamma(\\alpha)\\lambda\\sqrt\\beta} \\right) \\left( 2\\beta(1 + \\lambda) + (2\\alpha -1)\\lambda(y_i - \\hat{y})^2 \\right)\\]\n\n\noutput\nThe model has 4 outputs - \\(\\hat{y}\\) - \\(\\alpha\\) - \\(\\beta\\) - \\(\\lambda\\)\n\n\nRegularizer\nRegularizer is required to penalize the loss function for OOD predictions.\n\\[ \\| y - \\hat{y}\\| ^2 (2 \\alpha + \\lambda)\\]\n\nclass EvidentialLoss(torch.nn.Module):\n  def __init__(self, weight=None, size_average=True):\n    super(EvidentialLoss, self).__init__()\n\n  def forward(self, inputs, targets, smooth=1):\n    targets = targets.view(-1)\n    y = inputs[:,0].view(-1) #first column is mu,delta, predicted value\n    loga = inputs[:,1].view(-1) #alpha\n    logb = inputs[:,2].view(-1) #beta\n    logl = inputs[:,3].view(-1) #lamda\n\n    a = torch.exp(loga)\n    b = torch.exp(logb)\n    l = torch.exp(logl)\n\n\n    term1 = (torch.exp(torch.lgamma(a - 0.5)))/(4 * torch.exp(torch.lgamma(a)) * l * torch.sqrt(b))\n    #print(\"term1 :\", term1)\n    term2 = 2 * b *(1 + l) + (2*a - 1)*l*(y - targets)**2\n    #print(\"term2 :\", term2)\n\n    J = term1 * term2\n    #print(\"J :\", J)\n    Kl_divergence = torch.abs(y - targets) * (2*a + l)\n    #Kl_divergence = ((y - targets)**2) * (2*a + l)\n    \n    #print (\"KL \",Kl_divergence.data.numpy())\n    loss = J + Kl_divergence\n\n    #print (\"loss :\", loss)\n\n    return loss.mean()\n\nevnet = Net(n_feature=1, n_hidden=10, n_output=4)     # define the network\nprint(evnet)  # net architecture\n\noptimizer = torch.optim.Adam(evnet.parameters(), lr=0.001)\nloss_func = EvidentialLoss() \n\n\n# train the network\nfor t in range(20000):\n  \n    prediction = evnet(x)     # input x and predict based on x\n\n    loss = loss_func(prediction, y)     # must be (1. nn output, 2. target)\n\n    optimizer.zero_grad()   # clear gradients for next train\n    loss.backward()         # backpropagation, compute gradients\n    optimizer.step()        # apply gradients\n\n    if t%10000 == 0: print(loss)\n\n\n\nprediction = evnet(test_x)\nmu = prediction[:,0].view(-1) #first column is mu,delta, predicted value\na = prediction[:,1].view(-1) #alpha\nb = prediction[:,2].view(-1) #beta\nl = prediction[:,3].view(-1) #lamda\n\na = torch.exp(a); b = torch.exp(b); l = torch.exp(l)\nvar = b / ((a -1)*l) #epistemic/ model/prediciton uncertaitnty\ne = b / (a - 1) # aleatoric uncertainty/ data uncertainty\nplot_prediction(test_x, test_y, mu, var, e)\n\nNet(\n  (hidden): Linear(in_features=1, out_features=10, bias=True)\n  (hidden_2): Linear(in_features=10, out_features=10, bias=True)\n  (predict): Linear(in_features=10, out_features=4, bias=True)\n)\ntensor(3.1019, grad_fn=&lt;MeanBackward0&gt;)\ntensor(0.1492, grad_fn=&lt;MeanBackward0&gt;)"
  },
  {
    "objectID": "posts/notebooks/2020-05-27-uncertainty-regression.html#conclusions",
    "href": "posts/notebooks/2020-05-27-uncertainty-regression.html#conclusions",
    "title": "Regression Uncertainty",
    "section": "Conclusions",
    "text": "Conclusions\n\nLoss functions of maximum likelihood and evidence have been implemented from formulas from the paper. :::{.callout-important}\n\nLeasons Learned  - how to treat loss function when one of the output variable is always positive. (log and exponential to rescue)  -The difference between optimize and loss function and do you sum and add constant ones or do you add constant in all equation and sum.\n:::\n\nThe trianing is working on some runs not all.\nThe model learns the function easily but learning the uncertainty in unkonw region takes longer number of iterations. Needs to be further investigated.\n\n\n\n\n\n\n\nNote\n\n\n\nToDo : Test functions for the loss function written\n\n\n\n\n\n\n\n\nNote\n\n\n\nToDo : What is stopping condition? when to stop learning?\n\n\n\n\n\n\n\n\nNote\n\n\n\nToDo : Replace the regularizer in regularizer in likelihood loss with actual regularizer.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWhy is uncertatiny different for both the models. Evidential model seems to be very confident in the known region, which seems to be fishy\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe loss function doesnt give same results all the time, so needs to be further investigated"
  },
  {
    "objectID": "posts/notebooks/2020-05-27-uncertainty-regression.html#references",
    "href": "posts/notebooks/2020-05-27-uncertainty-regression.html#references",
    "title": "Regression Uncertainty",
    "section": "References",
    "text": "References\n[1] Kendall, Alex, and Yarin Gal. “What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?” ArXiv:1703.04977 [Cs], October 5, 2017. http://arxiv.org/abs/1703.04977.\n[2] Amini, Alexander, Wilko Schwarting, Ava Soleimany, and Daniela Rus. “Deep Evidential Regression.” ArXiv:1910.02600 [Cs, Stat], October 7, 2019. http://arxiv.org/abs/1910.02600.\n[3] Sensoy, Murat, Lance Kaplan, and Melih Kandemir. “Evidential Deep Learning to Quantify Classification Uncertainty,” n.d., 11.\n[4] Malinin, Andrey, and Mark Gales. “Predictive uncertainty estimation via prior networks.” Advances in Neural Information Processing Systems. 2018."
  },
  {
    "objectID": "posts/notebooks/2023-01-26-error-correcting-output-codes-.html#paper-reading",
    "href": "posts/notebooks/2023-01-26-error-correcting-output-codes-.html#paper-reading",
    "title": "Error Correcting Output codes - Why one-hot encoding is prone to attack",
    "section": "Paper reading",
    "text": "Paper reading\n\nError Correcting Output Codes Improve Probability Estimation and Adversarial Robustness of Deep Neural Networks\n\nneurips link : https://proceedings.neurips.cc/paper/2019/hash/cd61a580392a70389e27b0bc2b439f49-Abstract.html\ncode : https://github.com/Gunjan108/robust-ecoc"
  },
  {
    "objectID": "posts/notebooks/2023-01-26-error-correcting-output-codes-.html#meta-review",
    "href": "posts/notebooks/2023-01-26-error-correcting-output-codes-.html#meta-review",
    "title": "Error Correcting Output codes - Why one-hot encoding is prone to attack",
    "section": "Meta Review",
    "text": "Meta Review\nThis paper proposes the use of error correcting codes as class representations to improve robustness for adversarial attacks. The main idea of error correcting output codes is well-known, but this is the paper that shows that such ideas can be used for adversarial robustness. The paper shows very promising results especially in the rebuttal for CIFAR10. The distance bound is equivalent to Plotkin as the reviewer pointed out so this should be fixed in the paper."
  },
  {
    "objectID": "posts/notebooks/2023-01-26-error-correcting-output-codes-.html#contributions",
    "href": "posts/notebooks/2023-01-26-error-correcting-output-codes-.html#contributions",
    "title": "Error Correcting Output codes - Why one-hot encoding is prone to attack",
    "section": "Contributions",
    "text": "Contributions\n\nThe paper demonstrates why standard one-hot encoding is susceptible to adversarial and fooling examples and prone to overconfident probability estimates.\nIt also demonstrate that well-chosen error-correcting output codes, coupled with a modified decoding strategy, leads to an intrinsically more robust system that also yields better probabillity estimates.\nHow Softmax is prone to attack as compared to sigmoid and tanh"
  },
  {
    "objectID": "posts/notebooks/2023-01-26-error-correcting-output-codes-.html#reviewer-3",
    "href": "posts/notebooks/2023-01-26-error-correcting-output-codes-.html#reviewer-3",
    "title": "Error Correcting Output codes - Why one-hot encoding is prone to attack",
    "section": "Reviewer 3",
    "text": "Reviewer 3\nThe region of uncertainty (prediction probability close to 0.5) for softmax of logits is extremely small near an M-1 dimensional hyperplane in the logits space. The reason is changing one of the logits for one of the classes affects the probability vectors in all dimensions. The authors show that, if each logit is first converted to an independent probability using 1/(1+exp(-x)) function and the probability vector correlated with each codeword of an error correcting in a soft way to decode, this method has a large volume of uncertainty. The volume of uncertainty is larger when the min hamming distance of the code is large. This because multiple logits must be changed at the same time to cause a wrong decoding. Authors demonstrate this with nice plots. Authors propose to use subset of rows of Hamming Matrix for two properties: They have almost the best minimum hamming distance (half the dimension of the code) and they are orthogonal (which is important for unconfused decoding). They derive an upper bound on distance for any code. I checked the proof of the upper bound - it seems correct. Then the authors demonstrate performance (using Hamming 16 code) against PGD and Carlini Wagner attacks."
  },
  {
    "objectID": "posts/notebooks/2023-01-26-error-correcting-output-codes-.html#ploting-figure-1",
    "href": "posts/notebooks/2023-01-26-error-correcting-output-codes-.html#ploting-figure-1",
    "title": "Error Correcting Output codes - Why one-hot encoding is prone to attack",
    "section": "Ploting Figure 1",
    "text": "Ploting Figure 1\n\nimport numpy as np\nimport torch\n\n\nimport matplotlib.pyplot as plt\n\n\nsamples = 100\nz0 = np.linspace(-10, 10, samples)\nz1 = np.linspace(10, -10, samples)\nxv, yv = np.meshgrid(z0, z1)\nt = torch.tensor([list(xv.ravel()),list(yv.ravel())])\nt = t.permute(1,0)\n\nsoftmax = torch.nn.functional.softmax(t, dim=1).numpy()\nsigmoid = torch.sigmoid(t)\nsigmoid = sigmoid/sigmoid.sum(dim=1, keepdim=True)\n\nplt.imshow(softmax[:,0].reshape(samples,samples))\n\n&lt;matplotlib.image.AxesImage at 0x7ff402d979d0&gt;\n\n\n\n\n\n\nplt.imshow(sigmoid[:,0].reshape(samples,samples))\n\n&lt;matplotlib.image.AxesImage at 0x7ff402d1bbb0&gt;"
  },
  {
    "objectID": "posts/notebooks/2023-01-26-error-correcting-output-codes-.html#thin-green-region",
    "href": "posts/notebooks/2023-01-26-error-correcting-output-codes-.html#thin-green-region",
    "title": "Error Correcting Output codes - Why one-hot encoding is prone to attack",
    "section": "Thin Green Region",
    "text": "Thin Green Region\n\nFor Softmax the uncertain region (in green here) is thin, which basically means its easier to shift from one confident region to another.\nFor sigmoid this region is huge. Its not exact replica of the paper beause the sigmoid is of range -10 to 10 and here its just -1 to 1"
  },
  {
    "objectID": "posts/notebooks/2021-09-21-robust-statistics.html",
    "href": "posts/notebooks/2021-09-21-robust-statistics.html",
    "title": "Flexible Distributions as an Approach to Robustness",
    "section": "",
    "text": "Understanding paper “Flexible Distributions as an Approach to Robustness : The Skew-t Case” by Adelchi Azzalini"
  },
  {
    "objectID": "posts/notebooks/2021-09-21-robust-statistics.html#introduction",
    "href": "posts/notebooks/2021-09-21-robust-statistics.html#introduction",
    "title": "Flexible Distributions as an Approach to Robustness",
    "section": "Introduction",
    "text": "Introduction\nWhen a continuous variable of interest spans the whole real line, an interesting distribution is the one with density function\n\\[ c_v \\exp(- \\frac{|x|^{v}}{v}), \\qquad   x \\in \\mathbb{R} \\]\nwhere $ V &gt; 0 $ and\n\\[ C_v = \\frac{1}{ 2 v^{1/v} \\Gamma(1 + \\frac{1}{v})}\\]\nHere the parameter \\(v\\) manoeuvres the tail weight in the sense that 1. \\(v\\) = 2 corresponds to the normal distribution, 2. \\(0 &lt; v &lt; 2\\) produces tails heavier than the normal ones, 3. $ v &gt; 2 $ produces lighter tails.\n\nimport sympy as sym\nprint (sym.__version__)\n\n1.8\n\n\n\nv = sym.Symbol('v')\nx = sym.Symbol('x')\ngamma_v = sym.gamma(v + 1/v)\nc_v = 1 / (2 * v**(1/v) * gamma_v)\nskew_t = c_v * sym.exp(-sym.Abs(x)**v/ v)\n\n\np1 = sym.plot(skew_t.subs(v, 2), label=\"Gaussian\", line_color='blue', show=False, legend=True)\np2 = sym.plot(skew_t.subs(v, 1), label=\"Heavy Tail\", line_color='red', show=False)\np3 = sym.plot(skew_t.subs(v, 3), label=\"Thin Tail\", line_color='cyan', show=False)\np4 = sym.plot(skew_t.subs(v, 0.5), label=\"Heavy Tail\", line_color='black', show=False)\np1.append(p2[0])\np1.append(p3[0])\np1.append(p4[0])\np1.show()\n\n\n\n\n\n\np1 = sym.plot(-sym.log(skew_t.subs(v, 2)), (x, -1, 1), label=\"Gaussian\", line_color='blue', show=False, legend=True)\np2 = sym.plot(-sym.log(skew_t.subs(v, 1)), (x, -1, 1), label=\"Heavy Tail\", line_color='red', show=False, legend=True)\np3 = sym.plot(-sym.log(skew_t.subs(v, 3)), (x, -1, 1), label=\"Thin Tail\", line_color='cyan', show=False, legend=True)\np4 = sym.plot(-sym.log(skew_t.subs(v, 0.6)), (x, -1, 1), label=\"Heavy Tail\", line_color='black', show=False)\n\np1.append(p2[0])\np1.append(p3[0])\np1.append(p4[0])\np1.show()"
  },
  {
    "objectID": "posts/notebooks/2021-09-21-robust-statistics.html#notes",
    "href": "posts/notebooks/2021-09-21-robust-statistics.html#notes",
    "title": "Flexible Distributions as an Approach to Robustness",
    "section": "Notes",
    "text": "Notes\n[Analyzing distribution with Sympy] (https://brianzhang01.github.io/2018/04/distributions-with-sympy/)\n\nsym.init_printing()\nx, t = sym.symbols('x t', real=True)\ndef area(dist):\n    return sym.simplify(sym.integrate(dist, (x, -sym.oo, sym.oo)))\ndef mean(dist):\n    return area(dist*x)\ndef EX2(dist):\n    return area(dist*x**2)\ndef variance(dist):\n    return sym.simplify(EX2(dist) - mean(dist)**2)\ndef mgf(dist):\n    return sym.simplify(area(dist*sym.exp(x*t)))\ndef latex(result):\n    return \"$\" + sym.latex(result) + \"$\\n\" \ndef summarize(dist):\n    #print (\"Distribution: \" + latex(dist))\n    (dist)\n    print (\"Area: \" + latex(area(dist)))\n    print (\"Mean: \" + latex(mean(dist)))\n    print (\"Variance: \" + latex(variance(dist)))\n    print (\"MGF: \" + latex(mgf(dist)))\nsummarise = summarize  # alias\n\n\n# Define other symbols that show up\nmu = sym.symbols('mu', real=True)\nsigma, a, b, lamb, nu = sym.symbols('sigma a b lambda nu', positive=True)\n\n\n# Normal Distribution\nnormal = (2*sym.pi*sigma**2) ** sym.Rational(-1, 2) * sym.exp(-(x-mu)**2/(2*sigma**2))\nsummarize(normal)\nsym.pprint(normal)\n\nArea: $1$\n\nMean: $\\mu$\n\nVariance: $\\sigma^{2}$\n\nMGF: $e^{\\frac{t \\left(2 \\mu + \\sigma^{2} t\\right)}{2}}$\n\n             2 \n    -(-μ + x)  \n    ───────────\n           2   \n        2⋅σ    \n√2⋅ℯ           \n───────────────\n     2⋅√π⋅σ    \n\n\n\nsym.pprint (sym.latex(mu))\n\n\\mu\n\n\n\n sym.pprint(skew_t.subs(v, 2))\n\n        2 \n    -│x│  \n    ──────\n      2   \n√2⋅ℯ      \n──────────\n   3⋅√π   \n\n\n\nfrom sympy.stats import *\nz = sym.Symbol('z')\nv = Normal('v', 30, 1)\npdf = density(v)\nsym.plot(pdf(z), (z, 27, 33))\n\n\n\n\n&lt;sympy.plotting.plot.Plot at 0x7f119269c9d0&gt;\n\n\n\nsym.pprint(pdf(z))\n\n             2 \n    -(z - 30)  \n    ───────────\n         2     \n√2⋅ℯ           \n───────────────\n      2⋅√π     \n\n\n\ngamma_v = sym.gamma(v + 1/v)\nprint (gamma_v)\n\ngamma(v + 1/v)\n\n\n\ngamma_v.subs(v,2)\n\n\\(\\displaystyle \\frac{3 \\sqrt{\\pi}}{4}\\)"
  },
  {
    "objectID": "posts/notebooks/2020-05-19-probability-normalinversegamma.html",
    "href": "posts/notebooks/2020-05-19-probability-normalinversegamma.html",
    "title": "Plotting Normal Inverse Gamma Distirbution",
    "section": "",
    "text": "Scipy stats doesnt have Normal Inverse Gamma distirbution.\nWe would like to incorporate Normal Inverse Gamma distirbution in “scipy.stats” package.\nLearning about Normal Inverse Gamma(NIG) distribution will lead you to a plot like this from wikipedia. .\nIt was intruiging enough to find out how to plot this graph in python and was sure that there will be some already plots available. But to my suprise there is no blogs or docs to plot NIG in python. The closest I found was in R langugage in [1] by Frank Portman.\nSo I spent some time to plot NIG in python below is the snippet for it. Special thanks to Jake Vadendeplas[2] for his wonderful blogs about visualization in python."
  },
  {
    "objectID": "posts/notebooks/2020-05-19-probability-normalinversegamma.html#normal-inverse-gamma-distribution",
    "href": "posts/notebooks/2020-05-19-probability-normalinversegamma.html#normal-inverse-gamma-distribution",
    "title": "Plotting Normal Inverse Gamma Distirbution",
    "section": "Normal Inverse Gamma Distribution",
    "text": "Normal Inverse Gamma Distribution\nLet the input \\(x\\) on which its modelled be : \\[ x = [\\mu, \\sigma^2] \\]\n\nProbability density function (PDF)\n\\[ f(x | \\delta, \\alpha, \\beta, \\lambda ) = \\sqrt{\\left(\\frac{\\lambda}{2 \\pi x[\\sigma^2]} \\right)} \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} \\left(\\frac{1}{x[\\sigma^2]} \\right)^{(\\alpha + 1)} \\exp{ \\left( - \\frac{2\\beta + \\lambda \\left(x[\\mu] - \\delta \\right)^2 }{ 2 x[\\sigma]^2} \\right)} \\]\n\nfrom scipy.stats import rv_continuous\nfrom scipy.stats import norm\nfrom scipy.stats import gengamma\nfrom scipy.special import gamma\nfrom scipy.stats import expon\nimport numpy as np\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\n\nclass norminvgamma():\n  r\"\"\"A normal inverse gamma random variable.\n    The mu (``mu``) keyword specifies the parmaeter mu.\n    %(before_notes)s\n    Notes\n    -----\n    The probability density function for `norminvgamma` is:\n    .. math::\n        x = [\\mu, \\sigma^2]\n        f(x | \\delta, \\alpha, \\beta, \\lamda) = \n               \\sqrt(\\frac{\\lamda}{2 \\pi x[\\sigma^2}])\n               \\frac{\\beta^\\alpha}{\\gamma(\\alpha)}\n               \\frac{1}{x[\\sigma^2]}^(\\alpha + 1)\n               \\exp(- \\frac{2\\beta + \\lamda(x[\\mu] - delta)^2}{2 x[\\sigma^2] })\n        \n    for a real number :math:`x` and for positive number :math: `\\sigma^2` &gt; 0\n    %(after_notes)s\n    %(example)s\n    \"\"\"\n  def __init__(self, delta, alpha, beta, lamda):\n    self.argcheck(delta, alpha, beta, lamda)\n    self.delta = delta\n    self.alpha = alpha\n    self.beta = beta\n    self.lamda = lamda\n\n  def argcheck(self, delta, alpha, beta, lamda):\n        return (alpha &gt; 0) \n\n  def rvs(self, size=1):\n    sigma_2 = gengamma.rvs(self.alpha, self.beta,  size=size)\n    sigma_2 = np.array(sigma_2)\n    return [[norm.rvs(self.delta, s/self.lamda), s] for s in sigma_2]\n  \n  def pdf(self, xmu, xsigma2):\n    t1 = ((self.lamda)**0.5) * ((self.beta)**self.alpha)\n    t2 = (xsigma2 * (2 * 3.15)**0.5) * gamma(self.alpha)\n    t3 = (1 / xsigma2**2)**(self.alpha + 1)\n    t4 = expon.pdf((2*self.beta + self.lamda*(self.delta-xmu)**2)/(2*xsigma2**2))\n    #print (t1, t2, t3, t4)\n    return (t1/t2)*t3*t4\n    \n\n  def stats(self):\n    #ToDo\n    return\n\n  def plot(self,zoom=0.9, axs=None):\n    \n    steps = 50\n    max_sig_sq = gengamma.ppf(zoom, self.alpha, self.beta) * self.lamda\n    #print(max_sig_sq)\n    mu_range = np.linspace(self.delta - 1 * max_sig_sq, self.delta + 1 * max_sig_sq, num=steps)\n    #print (mu_range[0], mu_range[-1])\n    sigma_range = np.linspace(0.01, max_sig_sq, num=steps)\n    mu_grid, sigma_grid = np.meshgrid(mu_range, sigma_range)\n    pdf_mesh = self.pdf(mu_grid, sigma_grid)\n\n    if axs:\n\n      contours = axs.contour(mu_grid, sigma_grid, pdf_mesh,  20, cmap='RdGy');\n\n      plt.clabel(contours, inline=True, fontsize=8)\n      #extent=[mu_range[0], mu_range[-1], sigma_range[0], sigma_range[-1]]\n      axs.imshow(pdf_mesh, extent=[mu_range[0], mu_range[-1], sigma_range[0], sigma_range[-1]],\n                origin='lower', cmap='Blues', alpha=0.5)\n      axs.axis('equal')\n      axs.set_title(\"(\"+str(self.delta)+\",\"+str(self.alpha)+\",\" \n                    +str(self.beta)+\",\"+str(self.lamda)+\")\")\n      #plt.colorbar();\n    else:\n      assert True, \"Pass the axes to plot from matplotlib\""
  },
  {
    "objectID": "posts/notebooks/2020-05-19-probability-normalinversegamma.html#varying-different-range-of-alpha",
    "href": "posts/notebooks/2020-05-19-probability-normalinversegamma.html#varying-different-range-of-alpha",
    "title": "Plotting Normal Inverse Gamma Distirbution",
    "section": "Varying different range of \\(\\alpha\\)",
    "text": "Varying different range of \\(\\alpha\\)\n\n\n#norminvgamma = norminvgamma_gen()\nfig, axs = plt.subplots(1, 3, sharey=True, figsize=(15,5))\nfig.suptitle('Vertically alpha')\nnig = norminvgamma(delta=0,alpha=1,beta=1, lamda=1)\nsamples = nig.rvs(size=10)\nnig.plot(axs=axs[0])\nnig = norminvgamma(delta=0,alpha=2,beta=1, lamda=1)\nnig.plot(zoom=0.7, axs=axs[1])\nnig = norminvgamma(delta=0,alpha=4,beta=1, lamda=1)\n\nnig.plot(zoom=0.2, axs=axs[2])"
  },
  {
    "objectID": "posts/notebooks/2020-05-19-probability-normalinversegamma.html#varying-different-range-of-beta",
    "href": "posts/notebooks/2020-05-19-probability-normalinversegamma.html#varying-different-range-of-beta",
    "title": "Plotting Normal Inverse Gamma Distirbution",
    "section": "Varying different range of \\(\\beta\\)",
    "text": "Varying different range of \\(\\beta\\)\n\nfig, axs = plt.subplots(1, 3, sharey=True, figsize=(15,5))\nfig.suptitle('Varying beta')\nnig = norminvgamma(delta=0,alpha=1,beta=1, lamda=1)\nsamples = nig.rvs(size=10)\nnig.plot(axs=axs[0])\nnig = norminvgamma(delta=0,alpha=1,beta=2, lamda=1)\nnig.plot( axs=axs[1])\nnig = norminvgamma(delta=0,alpha=1,beta=3, lamda=1)\n\nnig.plot(axs=axs[2])"
  },
  {
    "objectID": "posts/notebooks/2020-05-19-probability-normalinversegamma.html#varying-different-range-of-lambda",
    "href": "posts/notebooks/2020-05-19-probability-normalinversegamma.html#varying-different-range-of-lambda",
    "title": "Plotting Normal Inverse Gamma Distirbution",
    "section": "Varying different range of \\(\\lambda\\)",
    "text": "Varying different range of \\(\\lambda\\)\n\nfig, axs = plt.subplots(1, 3, sharey=True, figsize=(15,5))\nfig.suptitle('Verying lamda ')\nnig = norminvgamma(delta=0,alpha=1,beta=1, lamda=1)\nsamples = nig.rvs(size=10)\nnig.plot(axs=axs[0])\nnig = norminvgamma(delta=0,alpha=1,beta=1, lamda=2)\nnig.plot( axs=axs[1])\nnig = norminvgamma(delta=0,alpha=1,beta=1, lamda=4)\n\nnig.plot(axs=axs[2])"
  },
  {
    "objectID": "posts/notebooks/2020-05-19-probability-normalinversegamma.html#references",
    "href": "posts/notebooks/2020-05-19-probability-normalinversegamma.html#references",
    "title": "Plotting Normal Inverse Gamma Distirbution",
    "section": "References",
    "text": "References\n\nhttps://frankportman.github.io/bayesAB/reference/plotNormalInvGamma.html\nhttps://jakevdp.github.io/PythonDataScienceHandbook/04.04-density-and-contour-plots.html"
  },
  {
    "objectID": "posts/notebooks/2023-01-17-exponential-power-distribution.html#generalized-gaussian-distirbution",
    "href": "posts/notebooks/2023-01-17-exponential-power-distribution.html#generalized-gaussian-distirbution",
    "title": "Exponential Power Distribution: PDF and NLL Visualization",
    "section": "Generalized Gaussian Distirbution",
    "text": "Generalized Gaussian Distirbution\nPlotting the PDF and Negative log likelihood of the distribution.\nAnalysis on the effect of the parameters on the pdf and the nll.\n\nimport sympy.plotting as symplot\nimport sympy as sym\nsym.init_printing(use_unicode=True)\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport matplotlib.colors as mcolors\nimport matplotlib.pyplot as plt\n\ncolor = list(mcolors.TABLEAU_COLORS)\n\nplt.rcParams['figure.figsize'] = 25, 10 #Plot​ Size\nplt.rcParams['legend.fontsize']=10 #Legend​ Size\n\nfrom typing import List,Tuple\n\n\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np"
  },
  {
    "objectID": "posts/notebooks/2023-01-17-exponential-power-distribution.html#sympy-plotting-function",
    "href": "posts/notebooks/2023-01-17-exponential-power-distribution.html#sympy-plotting-function",
    "title": "Exponential Power Distribution: PDF and NLL Visualization",
    "section": "Sympy Plotting Function",
    "text": "Sympy Plotting Function\n\ndef plot_exponential_power_distribution(alphas: List,\n                                        betas: List,\n                                        sympy_function,\n                                        plot_ylim: Tuple = (0,6),\n                                        plot_xlim: Tuple = (-2,2)):\n    xlim = 1e-21\n    \n    p1 = symplot.plot(sympy_function.subs([(beta, betas[0]), (alpha, alphas[0])]), (diff,-xlim,xlim), show=False, line_color='darkgreen')\n    p1[0].label = ''\n    i=0\n    for a in alphas:\n      for b in betas:\n          p = symplot.plot(sympy_function.subs([(beta,b), (alpha, a)]), (diff,-3,3), show=False, line_color=color[i%len(color)])\n          p[0].label =  'beta %s, alpha %s, zero %s'% (str(b),str(a),str(sympy_function.subs([(beta,b), (diff,0),(alpha, a)])))\n          p1.append(p[0])\n          i = i+1\n\n    p1.legend = True\n    p1.ylim = plot_ylim\n    p1.xlim = plot_xlim\n    p1.show()"
  },
  {
    "objectID": "posts/notebooks/2023-01-17-exponential-power-distribution.html#probability-density-function",
    "href": "posts/notebooks/2023-01-17-exponential-power-distribution.html#probability-density-function",
    "title": "Exponential Power Distribution: PDF and NLL Visualization",
    "section": "Probability Density function",
    "text": "Probability Density function\n\\[ \\frac{\\beta}{2 \\alpha \\Gamma(1/\\beta)} e^{- (|x - \\mu | / \\alpha)^{\\beta}} \\]\nReplacing \\(x - \\mu\\) with \\(diff\\) a single variable.\n\\[ \\frac{\\beta}{2 \\alpha \\Gamma(1/\\beta)} e^{- (|diff | / \\alpha)^{\\beta}} \\]\n\nalpha, beta, diff = sym.symbols('alpha, beta, diff')\n\n\npdf =  ( beta / (2 * alpha * sym.gamma(1 / beta)) ) * sym.exp(-((sym.Abs(diff)/alpha)**beta))\npdf\n\n\n\n\n\nFixed alpha changing beta\n\nObservtion\n\nThe Maximum is at \\(beta = 2.0\\) (Gaussian) at any fixed alpha\n\\(beta = 0.3\\) the max pdf is 0.5 which is less than 1 -&gt; can be considered for the minimum beta value\n\n\nalphas = [0.1]\nbetas = [ 0.3, 0.4, 0.5, 1.0, 1.5, 2.0, 8.0]\nplot_exponential_power_distribution(alphas, betas, pdf)\n\n\n\n\n\n\n\nFixed beta changing alpha\n\nObservtion\n\nAlpha is the variance value -&gt; the lower the better the more confident.\n\n\n\nalphas = [ 0.01, 0.1, 0.5, 1.0, 2.0]\nbetas = [ 2.0] #Gussian Distirbution\nplot_exponential_power_distribution(alphas, betas, pdf)\n\n\n\n\n\nalphas = [ 0.01, 0.1, 0.5, 1.0, 2.0]\nbetas = [ 1.0] #Laplace distirbution\nplot_exponential_power_distribution(alphas, betas, pdf)"
  },
  {
    "objectID": "posts/notebooks/2023-01-17-exponential-power-distribution.html#negative-log-likelihood",
    "href": "posts/notebooks/2023-01-17-exponential-power-distribution.html#negative-log-likelihood",
    "title": "Exponential Power Distribution: PDF and NLL Visualization",
    "section": "Negative log likelihood",
    "text": "Negative log likelihood\nHere we take the logarithmic of the pdf and the invert it .\nThe NLL are usually used as loss function in regresion problems.\n\nnll_pdf = -1 * sym.log(pdf)\nnll_pdf\n\n\n\n\n\nnll_pdf.subs([(beta,0.5), (diff,0),(alpha, 1.0)])\n\n\n\n\n\nalphas = [1.5, 2.0]\nbetas = [ 0.1, 0.5, 1.0, 2.0, 8.0]\n\nplot_exponential_power_distribution(alphas, betas, nll_pdf, plot_ylim=(0,3))"
  },
  {
    "objectID": "posts/notebooks/2023-01-17-exponential-power-distribution.html#entropy",
    "href": "posts/notebooks/2023-01-17-exponential-power-distribution.html#entropy",
    "title": "Exponential Power Distribution: PDF and NLL Visualization",
    "section": "Entropy",
    "text": "Entropy\n\\[ \\frac{1}{\\beta} - \\log [ \\frac{\\beta}{2 \\alpha \\Gamma(1/\\beta)}] \\]\n\nObservations\n\nWith reducing value of alpha entropy reduces (since alpha is the variance this fits perfectly)\nWith increasing beta the entropy reduces\n\nThis is little counter intutive\nExpected that entropy will be low only for beta = 2 (Gaussian) since it had max value in pdf.\nBut apparently when beta increases the confidence increases that the value is between some range and not a single value .\n\n\n\n#Modelling in sympy\nentropy = (1 / beta) - sym.log(beta / (2 * alpha * sym.gamma(1/beta)) )\nentropy\n\n\n\n\n\nbetas = [ 0.1, 0.5, 1.0, 2.0, 8.0]\nalphas = [ 0.01, 0.1, 0.5, 1.0, 2.0]\n\nval = []\nfor a in alphas:\n  for b in betas:\n    #print ('Entropy : {}, beta: {}, alpha: {}'.format(entropy.subs([(alpha, a), (beta,b)]), b, a))\n    val.append([float(entropy.subs([(alpha, a), (beta,b)])), b, a])\n\nentropy_data_frame = pd.DataFrame(val, columns=['entropy','beta', 'alpha'])\nprint (entropy_data_frame.dtypes)\n\nentropy_data_frame =  entropy_data_frame.pivot('alpha', 'beta', 'entropy')\nprint (entropy_data_frame.dtypes)\n\nentropy_data_frame\n\nentropy    float64\nbeta       float64\nalpha      float64\ndtype: object\nbeta\n0.1    float64\n0.5    float64\n1.0    float64\n2.0    float64\n8.0    float64\ndtype: object\n\n\n\n  \n    \n      \n\n\n\n\n\nbeta\n0.1\n0.5\n1.0\n2.0\n8.0\n\n\nalpha\n\n\n\n\n\n\n\n\n\n0.01\n21.192390\n-1.218876\n-2.912023\n-3.532805\n-3.847046\n\n\n0.10\n23.494975\n1.083709\n-0.609438\n-1.230220\n-1.544461\n\n\n0.50\n25.104413\n2.693147\n1.000000\n0.379218\n0.064977\n\n\n1.00\n25.797560\n3.386294\n1.693147\n1.072365\n0.758124\n\n\n2.00\n26.490707\n4.079442\n2.386294\n1.765512\n1.451271\n\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nsns.heatmap(entropy_data_frame, annot=True, fmt=\".1f\")\n\n&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f34544d1b80&gt;"
  },
  {
    "objectID": "posts/notebooks/2023-01-17-exponential-power-distribution.html#interval",
    "href": "posts/notebooks/2023-01-17-exponential-power-distribution.html#interval",
    "title": "Exponential Power Distribution: PDF and NLL Visualization",
    "section": "Interval",
    "text": "Interval\n\nToDO\n\nCan we calculucalte interval from variance\nCan we calculate interval from the quantile\ninterval is ppf function which is inverse cdf function\nWe have the CDF function . How to calculate the inverse CDF ?\n\n\nimport scipy.stats as stats\n\n\na = 0.1\nb = 2.0\np = 0.9 \nstats.gamma()\n\n&lt;scipy.stats._continuous_distns.gamma_gen at 0x7fbaf9fd26a0&gt;\n\n\n\ncdf = 0.5 + (sym.sign(diff)/2 )*(1/sym.gamma(1/beta))"
  },
  {
    "objectID": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#what-is-quantization",
    "href": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#what-is-quantization",
    "title": "Quantization of Pytorch Models",
    "section": "What is quantization",
    "text": "What is quantization\n\nQuantization describes methods for carrying out calculations and storing tensors at smaller bit width than floating point precision. The default size of floating point numbers are 32 bits.\nFor instance, quantizing the deep learning model means, converting the 32-bit floating point numbers (of weights & activation outputs) to 8-bit integers."
  },
  {
    "objectID": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#types-of-quantization",
    "href": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#types-of-quantization",
    "title": "Quantization of Pytorch Models",
    "section": "Types of quantization",
    "text": "Types of quantization\n\nPost Training Quantization (PTQ)\n\nStatic\nDynamic/Weight only\n\nQuantization Aware Training (QAT)\n\nStatic\n\n\n\n\n\nPros\nCons\n\n\n\n\nModel gets smaller\nPotential for little degradation in accuracy\n\n\nReduced memory usage during inferencing\n\n\n\nImproves hardware accelerator latency\n\n\n\nReduces inference latency\n\n\n\nDeployment on Edge AI devices with limited memory"
  },
  {
    "objectID": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#pytorch-quantisation-approach",
    "href": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#pytorch-quantisation-approach",
    "title": "Quantization of Pytorch Models",
    "section": "PyTorch Quantisation approach",
    "text": "PyTorch Quantisation approach"
  },
  {
    "objectID": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#onnx-quantisation-approach",
    "href": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#onnx-quantisation-approach",
    "title": "Quantization of Pytorch Models",
    "section": "ONNX Quantisation approach",
    "text": "ONNX Quantisation approach"
  },
  {
    "objectID": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#api",
    "href": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#api",
    "title": "Quantization of Pytorch Models",
    "section": "API",
    "text": "API\n\nPyTorch Quantization (QAT)\n\nhttps://pytorch.org/tutorials/advanced/static_quantization_tutorial.html\nimport torch\nfrom torchvision.models import MobileNetV2\n\nmodel = MobileNetV2()\n\nFuse relu & Conv2d\nInsert Stubs to model\n\nmodel = nn.Sequential(torch.quantization.QuantStub(), model, torch.quantization.DeQuantStub())\n\nPrepare model\n\nm.train()\nbackend = “fbgemm”\nmodel.qconfig = torch.quantization.get_default_qconfig(backend)\ntorch.quantization.prepare_qat(model, inplace=True)\n\nRun standard training loop\nConvert\n\nm.eval()\nmodel_quantized = torch.quantization.convert(model, inplace=True)\ntorch.save(model_quantized, model_file_path)\n\n\nPyTorch -&gt; ONNX\n\nhttps://pytorch.org/docs/stable/onnx.html\nimport torch\ntorch.onnx.export(model, sample_input, onnx_model_path, opset_version=12, input_names=[‘input’], output_names=[‘output’])\n\nONNX Qunatization (Dynamic)\n\nhttps://onnxruntime.ai/docs/performance/quantization.html\nimport onnx\nfrom onnxruntime.quantization import quantize_dynamic, QuantType\nquantized_model = quantize_dynamic(model_path, quantised_model_path)\n\nONNX -&gt; Blob\n\nhttps://docs.luxonis.com/en/latest/pages/tutorials/creating-custom-nn-models/\nimport blobconverter\nonnx_model = onnx.load(“./results/networks/test1.onnx”) model_simpified, check = simplify(onnx_model) onnx.save(model_simpified, “./results/networks/test_sim1.onnx”)\nblobconverter.from_onnx(model=onnx_model_path, data_type=“FP16”, shaves=6, use_cache=False, output_dir=blob_model_path, optimizer_params=[])\n\nONNX -&gt; TF\n\nhttps://github.com/onnx/onnx-tensorflow/blob/main/example/onnx_to_tf.py\nimport onnx\nfrom onnx_tf.backend import prepare\nonnx_model = onnx.load(onnx_model_path)\ntf_rep = prepare(onnx_model)\ntf_rep.export_graph(tf_model_path)\n\nTF -&gt; TFLite\n\nhttps://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter\nimport tensorflow as tf\nconverter = tf.lite.TFLiteConverter.from_saved_model(tf_model_path)\ntflite_model = converter.convert()\nwith open(tflite_model_path, ‘wb’) as f: f.write(tflite_model)\n\nTFLite -&gt; EdgeTPU TFLite\n\nhttps://coral.ai/docs/edgetpu/compiler/\ncurl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\necho “deb https://packages.cloud.google.com/apt coral-edgetpu-stable main” | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\nsudo apt-get update\nsudo apt-get install edgetpu-compiler\nedgetpu_compiler [options] tflite_model_path\n\nPyTorch Quantization (PTQ - Dynamic/Weight only)\n\nhttps://pytorch.org/blog/quantization-in-practice/\n\nPyTorch Quantization (PTQ - Static)\n\nhttps://pytorch.org/blog/quantization-in-practice/\n\n\n\n!rm -rf /tmp/MobileNet*\n!ls -lh /tmp/MobileNet*\n\nls: cannot access '/tmp/MobileNet*': No such file or directory\n\n\n\ntorch_model_path = \"/tmp/MobileNetV2.pt\"\ntorch_QAT_quant_path = \"/tmp/MobileNetV2_TorchQATQuant.pt\"\nonnx_model_path = \"/tmp/MobileNetV2.onnx\"\nonnx_quant_model_path = \"/tmp/MobileNetV2_OnnxQuant.onnx\"\nonnx_sim_model_path = \"/tmp/MobileNetV2_OnnxSim.onnx\"\nblob_model_path = \"/tmp/MobileNetV2.blob\"\ntf_model_path = \"/tmp/MobileNetV2.tf\"\ntflite_model_path = \"/tmp/MobileNetV2.tflite\"\nedgetpu_tflite_model_path = \"/tmp/MobileNetV2_edgetpu.tflite\"\ntorch_PTQ_Weight_Eager_path = \"/tmp/MobileNet_V2_Torch_PTQ_Quant_W_EG.pt\"\ntorch_PTQ_Weight_FX_path = \"/tmp/MobileNet_V2_Torch_PTQ_Quant_W_FX.pt\"\ntorch_PTQ_Static_Eager_path = \"/tmp/MobileNet_V2_Torch_PTQ_Quant_S_EG.pt\"\ntorch_PTQ_Static_FX_path = \"/tmp/MobileNet_V2_Torch_PTQ_Quant_S_FX.pt\""
  },
  {
    "objectID": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#pytorch-quantization-qat",
    "href": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#pytorch-quantization-qat",
    "title": "Quantization of Pytorch Models",
    "section": "1. PyTorch Quantization (QAT)",
    "text": "1. PyTorch Quantization (QAT)\n\nimport os\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.models import MobileNetV2\n\ndata_dir = os.path.abspath(\"./data\")\ntransform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), transforms.RandomErasing()])\ntrainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)\ntrain_sub_len = int(len(trainset) * 0.001)\ntrain_subset, val_subset = torch.utils.data.random_split(trainset, [train_sub_len, len(trainset) - train_sub_len])\ntrainloader = torch.utils.data.DataLoader(train_subset, batch_size=4, shuffle=True, num_workers=2)\n\n\nmodel = MobileNetV2()\n\n\"\"\"Fuse\"\"\"\n# pair_of_modules_to_fuze = []\n# for name, layer in model.named_modules():\n#     if isinstance(layer, torch.nn.Linear):\n#         pair_of_modules_to_fuze.append([name.split('.')[-1]])\n#     elif isinstance(layer, torch.nn.ReLU) and len(pair_of_modules_to_fuze) &gt; 0:\n#         pair_of_modules_to_fuze[-1].append(name.split('.')[-1])\n# pair_of_modules_to_fuze = list(filter(lambda x: len(x) == 2, pair_of_modules_to_fuze))\n# torch.quantization.fuse_modules(model.modules(), pair_of_modules_to_fuze, inplace=True)\n\n\n\"\"\"Insert stubs\"\"\"\nmodel = torch.nn.Sequential(torch.quantization.QuantStub(), \n                  model, \n                  torch.quantization.DeQuantStub())\n\n\n\"\"\"Prepare\"\"\"\nmodel.train()\nmodel.qconfig = torch.quantization.get_default_qconfig(\"fbgemm\")\ntorch.quantization.prepare_qat(model, inplace=True)\n\n\n\"\"\"Training Loop\"\"\"\nn_epochs = 3\nopt = torch.optim.SGD(model.parameters(), lr=0.1)\nloss_fn = torch.nn.CrossEntropyLoss()\n\n\nfor epoch in range(n_epochs):\n    for inputs, labels in trainloader:\n        opt.zero_grad()\n        out = model(inputs)\n        loss = loss_fn(out, labels)\n        loss.backward()\n        opt.step()\n\n\n\"\"\"Convert\"\"\"\nmodel.eval()\nmodel_quantized = torch.quantization.convert(model, inplace=True)\ntorch.save(model_quantized, torch_QAT_quant_path)\n\nFiles already downloaded and verified\n\n\n/usr/local/lib/python3.8/dist-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n  warnings.warn(\n\n\n\n!ls -lh /tmp/MobileNet*\n\n-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.pt\n-rw-r--r-- 1 root root 4.1M Jan 20 14:20 /tmp/MobileNetV2_TorchQATQuant.pt"
  },
  {
    "objectID": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#onnx-to-blob",
    "href": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#onnx-to-blob",
    "title": "Quantization of Pytorch Models",
    "section": "4. ONNX to Blob",
    "text": "4. ONNX to Blob\n\n!pip install onnxsim -q\n\n!pip install Flask==2.1.0 PyYAML==5.4.1 boto3==1.17.39 gunicorn==20.1.0 sentry-sdk -q\n!pip install blobconverter -q\n\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 66.8 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 238.9/238.9 KB 21.2 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.5/84.5 KB 9.4 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 95.2/95.2 KB 9.6 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 662.4/662.4 KB 29.8 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 131.4/131.4 KB 14.9 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.5/79.5 KB 9.5 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 177.4/177.4 KB 15.3 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 232.7/232.7 KB 21.5 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.6/96.6 KB 11.3 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.1/133.1 KB 15.1 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 73.4/73.4 KB 7.3 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.7/7.7 MB 77.3 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 140.6/140.6 KB 14.0 MB/s eta 0:00:00\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorboard 2.9.1 requires protobuf&lt;3.20,&gt;=3.9.2, but you have protobuf 3.20.3 which is incompatible.\nnotebook 5.7.16 requires jinja2&lt;=3.0.0, but you have jinja2 3.1.2 which is incompatible.\n\n\n\nimport onnx\nfrom onnxsim import simplify\nimport blobconverter\n\n\nmodel_simpified, check = simplify(onnx_model_path)\nonnx.save(model_simpified, onnx_sim_model_path)\n\n\n# blobconverter.from_onnx(\n#     model=onnx_sim_model_path,\n#     data_type=\"FP16\",\n#     shaves=6,\n#     use_cache=False,\n#     output_dir=blob_model_path,\n#     optimizer_params=[])\n\n!ls -lh /tmp/MobileNet*\n\n-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.onnx\n-rw-r--r-- 1 root root 3.6M Jan 20 14:20 /tmp/MobileNetV2_OnnxQuant.onnx\n-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2_OnnxSim.onnx\n-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.pt\n-rw-r--r-- 1 root root 4.1M Jan 20 14:20 /tmp/MobileNetV2_TorchQATQuant.pt"
  },
  {
    "objectID": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#onnx-to-tf",
    "href": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#onnx-to-tf",
    "title": "Quantization of Pytorch Models",
    "section": "5. ONNX to TF",
    "text": "5. ONNX to TF\n\n!pip install onnx-tf -q\n\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/226.1 KB ? eta -:--:--     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 226.1/226.1 KB 16.3 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/1.1 MB ? eta -:--:--     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 53.7 MB/s eta 0:00:00\n\n\n\nfrom onnx_tf.backend import prepare\nimport tensorflow_probability\nonnx_model = onnx.load(onnx_model_path)\ntf_rep = prepare(onnx_model)\ntf_rep.export_graph(tf_model_path)\n\nWARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n\n\n\n!ls -lh /tmp/MobileNet*\n\n-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.onnx\n-rw-r--r-- 1 root root 3.6M Jan 20 14:20 /tmp/MobileNetV2_OnnxQuant.onnx\n-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2_OnnxSim.onnx\n-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.pt\n-rw-r--r-- 1 root root 4.1M Jan 20 14:20 /tmp/MobileNetV2_TorchQATQuant.pt\n\n/tmp/MobileNetV2.tf:\ntotal 14M\ndrwxr-xr-x 2 root root 4.0K Jan 20 14:21 assets\n-rw-r--r-- 1 root root  14M Jan 20 14:21 saved_model.pb\ndrwxr-xr-x 2 root root 4.0K Jan 20 14:21 variables"
  },
  {
    "objectID": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#tf-to-tflite",
    "href": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#tf-to-tflite",
    "title": "Quantization of Pytorch Models",
    "section": "6. TF to TFLite",
    "text": "6. TF to TFLite\n\nimport tensorflow as tf\nimport numpy as np\n\n# def fake_dataset_generator(shape, n_iter):\n#     def dataset():\n#         for _ in range(n_iter):\n#             data = np.random.randn(*shape)\n#             data *= (1 / 255)\n#             batch = np.expand_dims(data, axis=0)\n#             yield [batch.astype(np.float32)]\n#     return dataset\n# datagen = fake_dataset_generator((192, 192, 3), 10)\n\nconverter = tf.lite.TFLiteConverter.from_saved_model(tf_model_path)\n# converter.representative_dataset = datagen\n# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n# converter.inference_input_type = tf.uint8\n# converter.inference_output_type = tf.uint8\n# converter.optimizations = [tf.lite.Optimize.DEFAULT]\ntflite_model = converter.convert()\nwith open(tflite_model_path, 'wb') as f: \n  f.write(tflite_model)\n\n\n!ls -lh /tmp/MobileNet*\n\n-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.onnx\n-rw-r--r-- 1 root root 3.6M Jan 20 14:20 /tmp/MobileNetV2_OnnxQuant.onnx\n-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2_OnnxSim.onnx\n-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.pt\n-rw-r--r-- 1 root root  14M Jan 20 14:22 /tmp/MobileNetV2.tflite\n-rw-r--r-- 1 root root 4.1M Jan 20 14:20 /tmp/MobileNetV2_TorchQATQuant.pt\n\n/tmp/MobileNetV2.tf:\ntotal 14M\ndrwxr-xr-x 2 root root 4.0K Jan 20 14:21 assets\n-rw-r--r-- 1 root root  14M Jan 20 14:21 saved_model.pb\ndrwxr-xr-x 2 root root 4.0K Jan 20 14:21 variables"
  },
  {
    "objectID": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#tflite-to-edgetpu-tflite",
    "href": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#tflite-to-edgetpu-tflite",
    "title": "Quantization of Pytorch Models",
    "section": "7. TFLite to EdgeTPU TFLite",
    "text": "7. TFLite to EdgeTPU TFLite\n\n!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n!echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n!sudo apt-get update\n!sudo apt-get install edgetpu-compiler\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100  1210  100  1210    0     0  60500      0 --:--:-- --:--:-- --:--:-- 60500\nOK\ndeb https://packages.cloud.google.com/apt coral-edgetpu-stable main\nGet:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\nHit:2 http://archive.ubuntu.com/ubuntu focal InRelease\nGet:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\nGet:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\nGet:5 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\nGet:6 https://packages.cloud.google.com/apt coral-edgetpu-stable InRelease [6,332 B]\nIgn:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\nGet:8 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\nHit:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\nHit:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\nGet:11 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 Packages [2,317 B]\nHit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\nGet:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2,909 kB]\nHit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\nHit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\nGet:17 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [982 kB]\nGet:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,374 kB]\nGet:19 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1,879 kB]\nGet:20 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,284 kB]\nGet:21 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,436 kB]\nGet:22 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,003 kB]\nGet:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,125 kB]\nFetched 15.4 MB in 2s (7,459 kB/s)\nReading package lists... Done\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following NEW packages will be installed:\n  edgetpu-compiler\n0 upgraded, 1 newly installed, 0 to remove and 30 not upgraded.\nNeed to get 7,913 kB of archives.\nAfter this operation, 31.2 MB of additional disk space will be used.\nGet:1 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 edgetpu-compiler amd64 16.0 [7,913 kB]\nFetched 7,913 kB in 1s (14.9 MB/s)\ndebconf: unable to initialize frontend: Dialog\ndebconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, &lt;&gt; line 1.)\ndebconf: falling back to frontend: Readline\ndebconf: unable to initialize frontend: Readline\ndebconf: (This frontend requires a controlling tty.)\ndebconf: falling back to frontend: Teletype\ndpkg-preconfigure: unable to re-open stdin: \nSelecting previously unselected package edgetpu-compiler.\n(Reading database ... 129504 files and directories currently installed.)\nPreparing to unpack .../edgetpu-compiler_16.0_amd64.deb ...\nUnpacking edgetpu-compiler (16.0) ...\nSetting up edgetpu-compiler (16.0) ...\nProcessing triggers for libc-bin (2.31-0ubuntu9.9) ...\n\n\n\n#https://github.com/google-coral/edgetpu/issues/453\n!edgetpu_compiler \"/tmp/MobileNetV2.tflite\"\n\nEdge TPU Compiler version 16.0.384591198\nStarted a compilation timeout timer of 180 seconds.\nERROR: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.\nCompilation failed: Model failed in Tflite interpreter. Please ensure model can be loaded/run in Tflite interpreter.\nCompilation child process completed within timeout period.\nCompilation failed! \n\n\n\n!ls -lh /tmp/MobileNet*\n\n-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.onnx\n-rw-r--r-- 1 root root 3.6M Jan 20 14:20 /tmp/MobileNetV2_OnnxQuant.onnx\n-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2_OnnxSim.onnx\n-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.pt\n-rw-r--r-- 1 root root  14M Jan 20 14:22 /tmp/MobileNetV2.tflite\n-rw-r--r-- 1 root root 4.1M Jan 20 14:20 /tmp/MobileNetV2_TorchQATQuant.pt\n\n/tmp/MobileNetV2.tf:\ntotal 14M\ndrwxr-xr-x 2 root root 4.0K Jan 20 14:21 assets\n-rw-r--r-- 1 root root  14M Jan 20 14:21 saved_model.pb\ndrwxr-xr-x 2 root root 4.0K Jan 20 14:21 variables"
  },
  {
    "objectID": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#pytorch-quantization-ptq---dynamicweight-only",
    "href": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#pytorch-quantization-ptq---dynamicweight-only",
    "title": "Quantization of Pytorch Models",
    "section": "PyTorch Quantization (PTQ - Dynamic/Weight only)",
    "text": "PyTorch Quantization (PTQ - Dynamic/Weight only)\nhttps://pytorch.org/blog/quantization-in-practice/\n\nimport torch\nfrom torch import nn\n\nmodel = MobileNetV2()\nmodel.eval()\n\n## EAGER MODE\nfrom torch.quantization import quantize_dynamic\nmodel_quantized = quantize_dynamic(model=model, qconfig_spec={nn.LSTM, nn.Linear}, dtype=torch.qint8, inplace=False)\ntorch.save(model_quantized, torch_PTQ_Weight_Eager_path)\n\n## FX MODE\nfrom torch.quantization import quantize_fx\nqconfig_dict = {\"\": torch.quantization.default_dynamic_qconfig} \nexample_inputs = iter(trainloader)\nimg, lab = next(example_inputs)\nmodel_prepared = quantize_fx.prepare_fx(model, qconfig_dict, img)\nmodel_quantized = quantize_fx.convert_fx(model_prepared)\ntorch.save(model_quantized, torch_PTQ_Weight_FX_path)\n\n/usr/local/lib/python3.8/dist-packages/torch/ao/quantization/fx/prepare.py:1530: UserWarning: Passing a QConfig dictionary to prepare is deprecated and will not be supported in a future version. Please pass in a QConfigMapping instead.\n  warnings.warn(\n\n\n\n!ls -lh /tmp/MobileNet*\n\n-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.onnx\n-rw-r--r-- 1 root root 3.6M Jan 20 14:20 /tmp/MobileNetV2_OnnxQuant.onnx\n-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2_OnnxSim.onnx\n-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.pt\n-rw-r--r-- 1 root root  14M Jan 20 14:22 /tmp/MobileNetV2.tflite\n-rw-r--r-- 1 root root  10M Jan 20 14:22 /tmp/MobileNet_V2_Torch_PTQ_Quant_W_EG.pt\n-rw-r--r-- 1 root root 9.8M Jan 20 14:22 /tmp/MobileNet_V2_Torch_PTQ_Quant_W_FX.pt\n-rw-r--r-- 1 root root 4.1M Jan 20 14:20 /tmp/MobileNetV2_TorchQATQuant.pt\n\n/tmp/MobileNetV2.tf:\ntotal 14M\ndrwxr-xr-x 2 root root 4.0K Jan 20 14:21 assets\n-rw-r--r-- 1 root root  14M Jan 20 14:21 saved_model.pb\ndrwxr-xr-x 2 root root 4.0K Jan 20 14:21 variables"
  },
  {
    "objectID": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#pytorch-quantization-ptq---static",
    "href": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#pytorch-quantization-ptq---static",
    "title": "Quantization of Pytorch Models",
    "section": "PyTorch Quantization (PTQ - Static)",
    "text": "PyTorch Quantization (PTQ - Static)\nhttps://pytorch.org/blog/quantization-in-practice/\n\nimport torch\nfrom torch import nn\nimport copy\n\nmodel = MobileNetV2()\n\n## EAGER MODE\nm = copy.deepcopy(model)\nm.eval()\n\n# torch.quantization.fuse_modules(m, ['0','1'], inplace=True) \n# torch.quantization.fuse_modules(m, ['2','3'], inplace=True) \n\nm = nn.Sequential(torch.quantization.QuantStub(), \n                  m, \n                  torch.quantization.DeQuantStub())\n\nm.qconfig = torch.quantization.get_default_qconfig(\"fbgemm\")\ntorch.quantization.prepare(m, inplace=True)\n\nexample_inputs = iter(trainloader)\nimg, lab = next(example_inputs)\n\nwith torch.inference_mode():\n  for _ in range(10):\n    m(img)\nmodel_quantized = torch.quantization.convert(m, inplace=True)\ntorch.save(model_quantized, torch_PTQ_Static_Eager_path)\n\n\n## FX MODE\nfrom torch.quantization import quantize_fx\nm = copy.deepcopy(model)\nm.eval()\nqconfig_dict = {\"\": torch.quantization.get_default_qconfig(\"fbgemm\")}\nmodel_prepared = quantize_fx.prepare_fx(m, qconfig_dict, img)\n\nwith torch.inference_mode():\n  for _ in range(10):\n    model_prepared(img)\nmodel_quantized = quantize_fx.convert_fx(model_prepared)\ntorch.save(model_quantized, torch_PTQ_Static_FX_path)\n\n/usr/local/lib/python3.8/dist-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n  warnings.warn(\n\n\n\n!ls -lh /tmp/MobileNet*\n\n-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.onnx\n-rw-r--r-- 1 root root 3.6M Jan 20 14:20 /tmp/MobileNetV2_OnnxQuant.onnx\n-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2_OnnxSim.onnx\n-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.pt\n-rw-r--r-- 1 root root  14M Jan 20 14:22 /tmp/MobileNetV2.tflite\n-rw-r--r-- 1 root root 4.1M Jan 20 14:22 /tmp/MobileNet_V2_Torch_PTQ_Quant_S_EG.pt\n-rw-r--r-- 1 root root 3.8M Jan 20 14:22 /tmp/MobileNet_V2_Torch_PTQ_Quant_S_FX.pt\n-rw-r--r-- 1 root root  10M Jan 20 14:22 /tmp/MobileNet_V2_Torch_PTQ_Quant_W_EG.pt\n-rw-r--r-- 1 root root 9.8M Jan 20 14:22 /tmp/MobileNet_V2_Torch_PTQ_Quant_W_FX.pt\n-rw-r--r-- 1 root root 4.1M Jan 20 14:20 /tmp/MobileNetV2_TorchQATQuant.pt\n\n/tmp/MobileNetV2.tf:\ntotal 14M\ndrwxr-xr-x 2 root root 4.0K Jan 20 14:21 assets\n-rw-r--r-- 1 root root  14M Jan 20 14:21 saved_model.pb\ndrwxr-xr-x 2 root root 4.0K Jan 20 14:21 variables\n\n\nhttps://pytorch.org/docs/stable/generated/torch.quantization.quantize_fx.prepare_fx.html"
  },
  {
    "objectID": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#test---qat-iris",
    "href": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#test---qat-iris",
    "title": "Quantization of Pytorch Models",
    "section": "Test - QAT IRIS",
    "text": "Test - QAT IRIS\n\nimport torch.nn.functional as F\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom torch.autograd import Variable\nfrom torch.quantization import QuantStub, DeQuantStub\n\nx, y = load_iris(return_X_y=True)\ntrain_X, test_X, train_y, test_y = train_test_split(x, y, test_size=0.8)\ntrain_X = Variable(torch.Tensor(train_X).float())\ntest_X = Variable(torch.Tensor(test_X).float())\ntrain_y = Variable(torch.Tensor(train_y).long())\ntest_y = Variable(torch.Tensor(test_y).long())\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(4, 100)\n        self.fc2 = nn.Linear(100, 100)\n        self.fc3 = nn.Linear(100, 3)\n        self.softmax = nn.Softmax(dim=1)\n        self.quant = QuantStub() \n        self.dequant = DeQuantStub() \n\n    def forward(self, X):\n        X = self.quant(X)\n        X = F.relu(self.fc1(X))\n        X = self.fc2(X)\n        X = self.fc3(X)\n        X = self.softmax(X)\n        X = self.dequant(X)\n        return X\n\nm = Net()\n\nm.train()\nbackend = \"fbgemm\"\nm.qconfig = torch.quantization.get_default_qconfig(backend)\ntorch.quantization.prepare_qat(m, inplace=True)\n\nn_epochs = 10\nopt = torch.optim.SGD(m.parameters(), lr=0.1)\nloss_fn = torch.nn.CrossEntropyLoss()\n\n\nfor epoch in range(n_epochs):\n    opt.zero_grad()\n    out = m(train_X)\n    loss = loss_fn(out, train_y)\n    loss.backward()\n    opt.step()\n    \nm.eval()\nmodel_quantized = torch.quantization.convert(m, inplace=True)\ntorch.save(model_quantized, '/tmp/Test_QAT_iris.pt')\n\n/usr/local/lib/python3.8/dist-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n  warnings.warn("
  },
  {
    "objectID": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#test---blob-converter",
    "href": "posts/notebooks/2023-01-17-quantize-dnn-model-pytorch.html#test---blob-converter",
    "title": "Quantization of Pytorch Models",
    "section": "Test - Blob Converter",
    "text": "Test - Blob Converter\n\nclass CatImgs(nn.Module):\n    def forward(self, img1, img2, img3):\n        return torch.cat((img1, img2, img3), 3)\n\n\nX = torch.ones((1, 3, 300, 300), dtype=torch.float32)\ntorch.onnx.export(\n    CatImgs(),\n    (X, X, X),\n    \"/tmp/Test_Blob_Onnx.onnx\",\n    opset_version=12,\n    do_constant_folding=True,\n)\n\nimport onnx\nfrom onnxsim import simplify\n\nonnx_model = onnx.load(\"/tmp/Test_Blob_Onnx.onnx\")\nmodel_simpified, check = simplify(onnx_model)\nonnx.save(model_simpified, \"/tmp/Test_Blob_OnnxSim.onnx\")\n\nimport blobconverter\n\nblobconverter.from_onnx(\n    model=\"/tmp/Test_Blob_OnnxSim.onnx\",\n    output_dir=\"/tmp/Test_Blob.blob\",\n    data_type=\"FP16\",\n    shaves=6,\n    use_cache=False,\n    optimizer_params=[]\n)\n\nDownloading /tmp/Test_Blob.blob/Test_Blob_OnnxSim_openvino_2021.4_6shave.blob...\n[==================================================]\nDone\n\n\nPosixPath('/tmp/Test_Blob.blob/Test_Blob_OnnxSim_openvino_2021.4_6shave.blob')\n\n\n\n!ls -lh /tmp/MobileNet* & ls -lh /tmp/Test*\n\n-rw-r--r-- 1 root root  283 Jan 20 14:22 /tmp/Test_Blob_Onnx.onnx\n-rw-r--r-- 1 root root  285 Jan 20 14:22 /tmp/Test_Blob_OnnxSim.onnx\n-rw-r--r-- 1 root root  21K Jan 20 14:22 /tmp/Test_QAT_iris.pt\n\n/tmp/Test_Blob.blob:\n-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.onnx\n-rw-r--r-- 1 root root 3.6M Jan 20 14:20 /tmp/MobileNetV2_OnnxQuant.onnx\n-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2_OnnxSim.onnx\n-rw-r--r-- 1 root root  14M Jan 20 14:20 /tmp/MobileNetV2.pt\n-rw-r--r-- 1 root root  14M Jan 20 14:22 /tmp/MobileNetV2.tflite\n-rw-r--r-- 1 root root 4.1M Jan 20 14:22 /tmp/MobileNet_V2_Torch_PTQ_Quant_S_EG.pt\n-rw-r--r-- 1 root root 3.8M Jan 20 14:22 /tmp/MobileNet_V2_Torch_PTQ_Quant_S_FX.pt\n-rw-r--r-- 1 root root  10M Jan 20 14:22 /tmp/MobileNet_V2_Torch_PTQ_Quant_W_EG.pt\n-rw-r--r-- 1 root root 9.8M Jan 20 14:22 /tmp/MobileNet_V2_Torch_PTQ_Quant_W_FX.pt\n-rw-r--r-- 1 root root 4.1M Jan 20 14:20 /tmp/MobileNetV2_TorchQATQuant.pt\n\n/tmp/MobileNetV2.tf:\ntotal 4.0K\n-rw-r--r-- 1 root root 1.0K Jan 20 14:22 Test_Blob_OnnxSim_openvino_2021.4_6shave.blob\ntotal 14M\ndrwxr-xr-x 2 root root 4.0K Jan 20 14:21 assets\n-rw-r--r-- 1 root root  14M Jan 20 14:21 saved_model.pb\ndrwxr-xr-x 2 root root 4.0K Jan 20 14:21 variables\n\n\nTODO 1. Fix Blob converter for MobileNet\n2. Fix Compile TFLite to EdgeTPU TFLite"
  },
  {
    "objectID": "posts/notebooks/2023-03-09-Neural-Link-Model-Uncertainty-Estimation.html",
    "href": "posts/notebooks/2023-03-09-Neural-Link-Model-Uncertainty-Estimation.html",
    "title": "Neural Linear Model (aka Gaussian Process)",
    "section": "",
    "text": "Based on the tweet by Andrew Jesson. Below is from the notebook shared by Andrew.\nThanks to David Holzmüller, Kevin Patrick Murphy, and Jason Hartford for correctly identifying this approach as the Neural Linear Model (NLM). The NLM seems to have first appeared as the Marginalized Neural Network in Marginalized Neural Network Mixtures for Large-Scale Regression and then in Scalable Bayesian Optimization Using Deep Neural Networks. Benchmarking the Neural Linear Model for Regression compares the NLM to mean field variational inference and Monte Carlo dropout Bayesian Neural Networks and concludes that methods such as NLM which do exact inference over a subset of parameters may perform better than methods that do variational inference over all parameters.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport torch\nfrom torch.nn.functional import softplus\n\nrc = {\n    \"figure.constrained_layout.use\": True,\n    \"axes.titlesize\": 20,\n    \"figure.figsize\": (12, 9),\n}\nsns.set_theme(style=\"darkgrid\", palette=\"colorblind\", rc=rc)\n\n\nclass Simulated(torch.utils.data.Dataset):\n    def __init__(self, n=1000, sigma=0.1, in_between=False, outliers_percentage=None):\n        if in_between:\n            mask = torch.distributions.Bernoulli(0.5).sample(torch.Size([n, 1]))\n            self.data = (-2 * torch.rand(n, 1).float() - 1) * mask \\\n                + (2 * torch.rand(n, 1).float() + 1) * (1. - mask)\n        else:\n            self.data = torch.randn(n, 1).float()\n        self.targets = f(self.data, sigma).float()\n        #Adding outliers\n        if (outliers_percentage):\n          num_outliers = int((outliers_percentage/100) * n)\n          outliers = torch.distributions.Uniform(\n              torch.tensor([-5.0]), torch.tensor([5.0])).sample(torch.Size([num_outliers]))\n          mask = torch.randint_like(outliers, high=n).long()\n          #print(outliers)\n          self.targets[mask] = outliers.float()\n\n\n    def __len__(self):\n        return len(self.targets)\n\n    def __getitem__(self, idx):\n        return self.data[idx], self.targets[idx]\n\n\ndef f(x, sigma=0.1):\n    w = torch.tensor([-0.6667, -0.6012, -1.0172, -0.7687, 1.4680, -0.1678])\n    fx = 0\n    for i in range(len(w)):\n        fx += w[i] * (x**i)\n    fx *= np.sin(np.pi * x)\n    fx *= np.exp(-0.5 * (x**2)) / np.sqrt(2 * np.pi)\n    return (\n        fx.squeeze(-1)\n        + torch.randn(\n            len(x),\n        )\n        * sigma\n    )\n\n\nnum_features = 100\nn_train = 200\ndr = 0.05\n\nmodel = torch.nn.Sequential(\n    torch.nn.Linear(1, num_features),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(dr),\n    torch.nn.Linear(num_features, num_features),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(dr),\n    torch.nn.Linear(num_features, num_features),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(dr),\n    torch.nn.Linear(num_features, 1),\n)\nlog_sigma = torch.nn.Parameter(-2 * torch.ones(1))\nds = Simulated(n=n_train)\ndl = torch.utils.data.DataLoader(\n    ds,\n    batch_size=32,\n    shuffle=True,\n    drop_last=True\n)\noptimizer = torch.optim.AdamW(\n    [\n        \n        {\n            \"params\": model.parameters(),\n            \"lr\": 1e-3,\n            \"weight_decay\": (1 - dr)\n            / (2 * len(ds)),\n        },\n        {\n            \"params\": log_sigma,\n            \"lr\": 1e-2,\n            \"weight_decay\": 1e-6,\n        },\n    ]\n)\n\n\nmodel.train()\nfor epoch in range(500):\n  train_loss = []\n  for batch in dl:\n    x, y = batch\n    mu = model(x)\n    dist = torch.distributions.Normal(mu, softplus(log_sigma))\n    loss = -dist.log_prob(y.unsqueeze(-1)).mean()\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    train_loss.append(loss.item())\n  if epoch % 20 == 0:\n    print(f\"Epoch {epoch}, loss: {np.mean(train_loss):.02f}\")\n\nEpoch 0, loss: 2.83\nEpoch 20, loss: 0.10\nEpoch 40, loss: -0.08\nEpoch 60, loss: -0.28\nEpoch 80, loss: -0.36\nEpoch 100, loss: -0.38\nEpoch 120, loss: -0.48\nEpoch 140, loss: -0.67\nEpoch 160, loss: -0.67\nEpoch 180, loss: -0.63\nEpoch 200, loss: -0.73\nEpoch 220, loss: -0.67\nEpoch 240, loss: -0.70\nEpoch 260, loss: -0.76\nEpoch 280, loss: -0.71\nEpoch 300, loss: -0.58\nEpoch 320, loss: -0.84\nEpoch 340, loss: -0.75\nEpoch 360, loss: -0.79\nEpoch 380, loss: -0.83\nEpoch 400, loss: -0.79\nEpoch 420, loss: -0.71\nEpoch 440, loss: -0.62\nEpoch 460, loss: -0.74\nEpoch 480, loss: -0.89\n\n\n\n\nNeed to compute \\(\\phi(X_{\\text{test}})\\) and \\(\\phi(X_{\\text{train}})\\)\n\nx_test = torch.linspace(-4, 4, 150).unsqueeze(-1)\nmodel.eval()\nwith torch.no_grad():\n    mu_pred = model(x_test)\n    phi_test = model[:-1](x_test)\n    phi_train = model[:-1](ds.data)\nprint(phi_train.shape, phi_test.shape)\n\ntorch.Size([200, 100]) torch.Size([150, 100])\n\n\nNow we calculate, \\(\\sigma^{-2}\\phi(X_{\\text{train}})^{⊤} \\phi(X_{\\text{train}}) + \\mathbf{I}\\), which has shape num_features x num_features. This is different from a standard GP with size n_train x n_train.\n\nI = torch.eye(num_features)\nA = phi_train.T @ phi_train / torch.square(softplus(log_sigma).detach())  + I\n\nNow we solve for \\(\\phi(x)^{\\top}\\left(\\sigma^{-2}\\phi(X_{\\text{train}})^{⊤} \\phi(X_{\\text{train}}) + \\mathbf{I}\\right)^{-1}\\phi(x)\\). We can use the identity \\(\\phi(x)^{\\top}\\left(\\sigma^{-2}\\phi(X_{\\text{train}})^{⊤} \\phi(X_{\\text{train}}) + \\mathbf{I}\\right)^{-1}\\phi(x) = ||L^{-1}\\phi(x)||^2_2\\), with \\(L\\) the Cholesky decomposition of \\(\\left(\\sigma^{-2}\\phi(X_{\\text{train}})^{⊤} \\phi(X_{\\text{train}}) + \\mathbf{I}\\right)^{-1}\\). Thank you Andreas Kirsch.\nAs pointed out by Yarin Gal, this is in fact Bayesian Linear regression in penultimate layer feature space. Which is indeed, “sort of a deep kernel GP.”\n\nL = torch.linalg.cholesky(A)\nprint(L.shape)\nv = torch.linalg.solve_triangular(L, phi_test.T, upper=False)\ncov = v.T @ v + 1e-5 * torch.eye(len(phi_test))\nf_stddev = torch.sqrt(torch.diag(cov))\n\ntorch.Size([100, 100])\n\n\n\n_ = plt.figure(figsize=(12,9))\n_ = sns.scatterplot(x=ds.data.ravel(), y=ds.targets.ravel())\n_ = sns.lineplot(x=x_test.ravel(), y=mu_pred.ravel())\n_ = plt.fill_between(\n    x=x_test.ravel(), \n    y1=mu_pred.ravel() + 1.96 * f_stddev, \n    y2=mu_pred.ravel() - 1.96 * f_stddev,\n    alpha=0.3,\n)\n_ = plt.ylim(-2, 2)\n\n\n\n\n\n\n\ndist = torch.distributions.MultivariateNormal(loc=mu_pred.ravel(), covariance_matrix=cov)\nf_samples = dist.sample(torch.Size([20]))\n\n\n_ = sns.scatterplot(x=ds.data.ravel(), y=ds.targets.ravel())\nfor func in f_samples:\n    _ = sns.lineplot(x=x_test.ravel(), y=func.to(\"cpu\"), color=\"C0\", alpha=0.1)\n_ = plt.ylim(-2, 2)\n\n\n\n\n\n\n\n\nGreat comment from Yingzhen Li on in-between uncertainty! Let’s take a look.\n\nnum_features = 100\nn_train = 200\ndr = 0.05\n\nmodel = torch.nn.Sequential(\n    torch.nn.Linear(1, num_features),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(dr),\n    torch.nn.Linear(num_features, num_features),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(dr),\n    torch.nn.Linear(num_features, num_features),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(dr),\n    torch.nn.Linear(num_features, 1),\n)\nlog_sigma = torch.nn.Parameter(-2 * torch.ones(1))\nds = Simulated(n=n_train, in_between=True)\ndl = torch.utils.data.DataLoader(\n    ds,\n    batch_size=32,\n    shuffle=True,\n    drop_last=True\n)\noptimizer = torch.optim.AdamW(\n    [\n        \n        {\n            \"params\": model.parameters(),\n            \"lr\": 1e-3,\n            \"weight_decay\": (1 - dr)\n            / (2 * len(ds)),\n        },\n        {\n            \"params\": log_sigma,\n            \"lr\": 1e-2,\n            \"weight_decay\": 1e-6,\n        },\n    ]\n)\n\n\nmodel.train()\nfor epoch in range(500):\n  train_loss = []\n  for batch in dl:\n    x, y = batch\n    mu = model(x)\n    dist = torch.distributions.Normal(mu, softplus(log_sigma))\n    loss = -dist.log_prob(y.unsqueeze(-1)).mean()\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    train_loss.append(loss.item())\n  if epoch % 20 == 0:\n    print(f\"Epoch {epoch}, loss: {np.mean(train_loss):.02f}\")\n\nEpoch 0, loss: 13.52\nEpoch 20, loss: 0.87\nEpoch 40, loss: 0.26\nEpoch 60, loss: -0.04\nEpoch 80, loss: -0.14\nEpoch 100, loss: -0.13\nEpoch 120, loss: -0.25\nEpoch 140, loss: -0.03\nEpoch 160, loss: -0.42\nEpoch 180, loss: -0.35\nEpoch 200, loss: -0.41\nEpoch 220, loss: -0.47\nEpoch 240, loss: -0.36\nEpoch 260, loss: -0.41\nEpoch 280, loss: -0.44\nEpoch 300, loss: -0.54\nEpoch 320, loss: -0.48\nEpoch 340, loss: -0.55\nEpoch 360, loss: -0.55\nEpoch 380, loss: -0.57\nEpoch 400, loss: -0.46\nEpoch 420, loss: -0.52\nEpoch 440, loss: -0.44\nEpoch 460, loss: -0.60\nEpoch 480, loss: -0.52\n\n\n\nx_test = torch.linspace(-4, 4, 150).unsqueeze(-1)\nmodel.eval()\nwith torch.no_grad():\n    mu_pred = model(x_test)\n    phi_test = model[:-1](x_test)\n    phi_train = model[:-1](ds.data)\n\nI = torch.eye(num_features)\nA = phi_train.T @ phi_train / torch.square(softplus(log_sigma).detach())  + I\n\nL = torch.linalg.cholesky(A)\nv = torch.linalg.solve_triangular(L, phi_test.T, upper=False)\ncov = v.T @ v + 1e-5 * torch.eye(len(phi_test))\nf_stddev = torch.sqrt(torch.diag(cov))\n\n\n_ = plt.figure(figsize=(12,9))\n_ = sns.scatterplot(x=ds.data.ravel(), y=ds.targets.ravel())\n_ = sns.lineplot(x=x_test.ravel(), y=mu_pred.ravel())\n_ = plt.fill_between(\n    x=x_test.ravel(), \n    y1=mu_pred.ravel() + 1.96 * f_stddev, \n    y2=mu_pred.ravel() - 1.96 * f_stddev,\n    alpha=0.3,\n)\n\n\n\n\n\ndist = torch.distributions.MultivariateNormal(loc=mu_pred.ravel(), covariance_matrix=cov)\nf_samples = dist.sample(torch.Size([50]))\n\n\n_ = sns.scatterplot(x=ds.data.ravel(), y=ds.targets.ravel())\nfor func in f_samples:\n    _ = sns.lineplot(x=x_test.ravel(), y=func.to(\"cpu\"), color=\"C0\", alpha=0.1)\n_ = plt.ylim(-2, 2)\n\n\n\n\n\n\n\nAdding 5% outliers : The loss increases from -0.89 to 1.27 .\n\nnum_features = 100\nn_train = 200\ndr = 0.05\n\nmodel = torch.nn.Sequential(\n    torch.nn.Linear(1, num_features),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(dr),\n    torch.nn.Linear(num_features, num_features),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(dr),\n    torch.nn.Linear(num_features, num_features),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(dr),\n    torch.nn.Linear(num_features, 1),\n)\nlog_sigma = torch.nn.Parameter(-2 * torch.ones(1))\nds = Simulated(n=n_train, outliers_percentage=5)\ndl = torch.utils.data.DataLoader(\n    ds,\n    batch_size=32,\n    shuffle=True,\n    drop_last=True\n)\noptimizer = torch.optim.AdamW(\n    [\n        \n        {\n            \"params\": model.parameters(),\n            \"lr\": 1e-3,\n            \"weight_decay\": (1 - dr)\n            / (2 * len(ds)),\n        },\n        {\n            \"params\": log_sigma,\n            \"lr\": 1e-2,\n            \"weight_decay\": 1e-6,\n        },\n    ]\n)\n\nmodel.train()\nfor epoch in range(500):\n  train_loss = []\n  for batch in dl:\n    x, y = batch\n    mu = model(x)\n    dist = torch.distributions.Normal(mu, softplus(log_sigma))\n    loss = -dist.log_prob(y.unsqueeze(-1)).mean()\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    train_loss.append(loss.item())\n  if epoch % 20 == 0:\n    print(f\"Epoch {epoch}, loss: {np.mean(train_loss):.02f}\")\n\nx_test = torch.linspace(-4, 4, 150).unsqueeze(-1)\nmodel.eval()\nwith torch.no_grad():\n    mu_pred = model(x_test)\n    phi_test = model[:-1](x_test)\n    phi_train = model[:-1](ds.data)\nprint(phi_train.shape, phi_test.shape)\n\nI = torch.eye(num_features)\nA = phi_train.T @ phi_train / torch.square(softplus(log_sigma).detach())  + I\n\nL = torch.linalg.cholesky(A)\nprint(L.shape)\nv = torch.linalg.solve_triangular(L, phi_test.T, upper=False)\ncov = v.T @ v + 1e-5 * torch.eye(len(phi_test))\nf_stddev = torch.sqrt(torch.diag(cov))\n\n_ = plt.figure(figsize=(12,9))\n_ = sns.scatterplot(x=ds.data.ravel(), y=ds.targets.ravel())\n_ = sns.lineplot(x=x_test.ravel(), y=mu_pred.ravel())\n_ = plt.fill_between(\n    x=x_test.ravel(), \n    y1=mu_pred.ravel() + 1.96 * f_stddev, \n    y2=mu_pred.ravel() - 1.96 * f_stddev,\n    alpha=0.3,\n)\n_ = plt.ylim(-2, 2)\n\nEpoch 0, loss: 25.33\nEpoch 20, loss: 5.53\nEpoch 40, loss: 3.51\nEpoch 60, loss: 2.53\nEpoch 80, loss: 2.00\nEpoch 100, loss: 1.35\nEpoch 120, loss: 1.61\nEpoch 140, loss: 1.49\nEpoch 160, loss: 1.43\nEpoch 180, loss: 1.39\nEpoch 200, loss: 1.33\nEpoch 220, loss: 1.34\nEpoch 240, loss: 1.23\nEpoch 260, loss: 1.27\nEpoch 280, loss: 1.21\nEpoch 300, loss: 1.32\nEpoch 320, loss: 1.29\nEpoch 340, loss: 1.27\nEpoch 360, loss: 1.29\nEpoch 380, loss: 1.28\nEpoch 400, loss: 1.29\nEpoch 420, loss: 1.28\nEpoch 440, loss: 1.22\nEpoch 460, loss: 1.17\nEpoch 480, loss: 1.27\ntorch.Size([200, 100]) torch.Size([150, 100])\ntorch.Size([100, 100])"
  },
  {
    "objectID": "posts/notebooks/2023-03-09-Neural-Link-Model-Uncertainty-Estimation.html#computing-uncertainty",
    "href": "posts/notebooks/2023-03-09-Neural-Link-Model-Uncertainty-Estimation.html#computing-uncertainty",
    "title": "Neural Linear Model (aka Gaussian Process)",
    "section": "",
    "text": "Need to compute \\(\\phi(X_{\\text{test}})\\) and \\(\\phi(X_{\\text{train}})\\)\n\nx_test = torch.linspace(-4, 4, 150).unsqueeze(-1)\nmodel.eval()\nwith torch.no_grad():\n    mu_pred = model(x_test)\n    phi_test = model[:-1](x_test)\n    phi_train = model[:-1](ds.data)\nprint(phi_train.shape, phi_test.shape)\n\ntorch.Size([200, 100]) torch.Size([150, 100])\n\n\nNow we calculate, \\(\\sigma^{-2}\\phi(X_{\\text{train}})^{⊤} \\phi(X_{\\text{train}}) + \\mathbf{I}\\), which has shape num_features x num_features. This is different from a standard GP with size n_train x n_train.\n\nI = torch.eye(num_features)\nA = phi_train.T @ phi_train / torch.square(softplus(log_sigma).detach())  + I\n\nNow we solve for \\(\\phi(x)^{\\top}\\left(\\sigma^{-2}\\phi(X_{\\text{train}})^{⊤} \\phi(X_{\\text{train}}) + \\mathbf{I}\\right)^{-1}\\phi(x)\\). We can use the identity \\(\\phi(x)^{\\top}\\left(\\sigma^{-2}\\phi(X_{\\text{train}})^{⊤} \\phi(X_{\\text{train}}) + \\mathbf{I}\\right)^{-1}\\phi(x) = ||L^{-1}\\phi(x)||^2_2\\), with \\(L\\) the Cholesky decomposition of \\(\\left(\\sigma^{-2}\\phi(X_{\\text{train}})^{⊤} \\phi(X_{\\text{train}}) + \\mathbf{I}\\right)^{-1}\\). Thank you Andreas Kirsch.\nAs pointed out by Yarin Gal, this is in fact Bayesian Linear regression in penultimate layer feature space. Which is indeed, “sort of a deep kernel GP.”\n\nL = torch.linalg.cholesky(A)\nprint(L.shape)\nv = torch.linalg.solve_triangular(L, phi_test.T, upper=False)\ncov = v.T @ v + 1e-5 * torch.eye(len(phi_test))\nf_stddev = torch.sqrt(torch.diag(cov))\n\ntorch.Size([100, 100])\n\n\n\n_ = plt.figure(figsize=(12,9))\n_ = sns.scatterplot(x=ds.data.ravel(), y=ds.targets.ravel())\n_ = sns.lineplot(x=x_test.ravel(), y=mu_pred.ravel())\n_ = plt.fill_between(\n    x=x_test.ravel(), \n    y1=mu_pred.ravel() + 1.96 * f_stddev, \n    y2=mu_pred.ravel() - 1.96 * f_stddev,\n    alpha=0.3,\n)\n_ = plt.ylim(-2, 2)\n\n\n\n\n\n\n\ndist = torch.distributions.MultivariateNormal(loc=mu_pred.ravel(), covariance_matrix=cov)\nf_samples = dist.sample(torch.Size([20]))\n\n\n_ = sns.scatterplot(x=ds.data.ravel(), y=ds.targets.ravel())\nfor func in f_samples:\n    _ = sns.lineplot(x=x_test.ravel(), y=func.to(\"cpu\"), color=\"C0\", alpha=0.1)\n_ = plt.ylim(-2, 2)"
  },
  {
    "objectID": "posts/notebooks/2023-03-09-Neural-Link-Model-Uncertainty-Estimation.html#in-between-uncertainty",
    "href": "posts/notebooks/2023-03-09-Neural-Link-Model-Uncertainty-Estimation.html#in-between-uncertainty",
    "title": "Neural Linear Model (aka Gaussian Process)",
    "section": "",
    "text": "Great comment from Yingzhen Li on in-between uncertainty! Let’s take a look.\n\nnum_features = 100\nn_train = 200\ndr = 0.05\n\nmodel = torch.nn.Sequential(\n    torch.nn.Linear(1, num_features),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(dr),\n    torch.nn.Linear(num_features, num_features),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(dr),\n    torch.nn.Linear(num_features, num_features),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(dr),\n    torch.nn.Linear(num_features, 1),\n)\nlog_sigma = torch.nn.Parameter(-2 * torch.ones(1))\nds = Simulated(n=n_train, in_between=True)\ndl = torch.utils.data.DataLoader(\n    ds,\n    batch_size=32,\n    shuffle=True,\n    drop_last=True\n)\noptimizer = torch.optim.AdamW(\n    [\n        \n        {\n            \"params\": model.parameters(),\n            \"lr\": 1e-3,\n            \"weight_decay\": (1 - dr)\n            / (2 * len(ds)),\n        },\n        {\n            \"params\": log_sigma,\n            \"lr\": 1e-2,\n            \"weight_decay\": 1e-6,\n        },\n    ]\n)\n\n\nmodel.train()\nfor epoch in range(500):\n  train_loss = []\n  for batch in dl:\n    x, y = batch\n    mu = model(x)\n    dist = torch.distributions.Normal(mu, softplus(log_sigma))\n    loss = -dist.log_prob(y.unsqueeze(-1)).mean()\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    train_loss.append(loss.item())\n  if epoch % 20 == 0:\n    print(f\"Epoch {epoch}, loss: {np.mean(train_loss):.02f}\")\n\nEpoch 0, loss: 13.52\nEpoch 20, loss: 0.87\nEpoch 40, loss: 0.26\nEpoch 60, loss: -0.04\nEpoch 80, loss: -0.14\nEpoch 100, loss: -0.13\nEpoch 120, loss: -0.25\nEpoch 140, loss: -0.03\nEpoch 160, loss: -0.42\nEpoch 180, loss: -0.35\nEpoch 200, loss: -0.41\nEpoch 220, loss: -0.47\nEpoch 240, loss: -0.36\nEpoch 260, loss: -0.41\nEpoch 280, loss: -0.44\nEpoch 300, loss: -0.54\nEpoch 320, loss: -0.48\nEpoch 340, loss: -0.55\nEpoch 360, loss: -0.55\nEpoch 380, loss: -0.57\nEpoch 400, loss: -0.46\nEpoch 420, loss: -0.52\nEpoch 440, loss: -0.44\nEpoch 460, loss: -0.60\nEpoch 480, loss: -0.52\n\n\n\nx_test = torch.linspace(-4, 4, 150).unsqueeze(-1)\nmodel.eval()\nwith torch.no_grad():\n    mu_pred = model(x_test)\n    phi_test = model[:-1](x_test)\n    phi_train = model[:-1](ds.data)\n\nI = torch.eye(num_features)\nA = phi_train.T @ phi_train / torch.square(softplus(log_sigma).detach())  + I\n\nL = torch.linalg.cholesky(A)\nv = torch.linalg.solve_triangular(L, phi_test.T, upper=False)\ncov = v.T @ v + 1e-5 * torch.eye(len(phi_test))\nf_stddev = torch.sqrt(torch.diag(cov))\n\n\n_ = plt.figure(figsize=(12,9))\n_ = sns.scatterplot(x=ds.data.ravel(), y=ds.targets.ravel())\n_ = sns.lineplot(x=x_test.ravel(), y=mu_pred.ravel())\n_ = plt.fill_between(\n    x=x_test.ravel(), \n    y1=mu_pred.ravel() + 1.96 * f_stddev, \n    y2=mu_pred.ravel() - 1.96 * f_stddev,\n    alpha=0.3,\n)\n\n\n\n\n\ndist = torch.distributions.MultivariateNormal(loc=mu_pred.ravel(), covariance_matrix=cov)\nf_samples = dist.sample(torch.Size([50]))\n\n\n_ = sns.scatterplot(x=ds.data.ravel(), y=ds.targets.ravel())\nfor func in f_samples:\n    _ = sns.lineplot(x=x_test.ravel(), y=func.to(\"cpu\"), color=\"C0\", alpha=0.1)\n_ = plt.ylim(-2, 2)"
  },
  {
    "objectID": "posts/notebooks/2023-03-09-Neural-Link-Model-Uncertainty-Estimation.html#with-outliers",
    "href": "posts/notebooks/2023-03-09-Neural-Link-Model-Uncertainty-Estimation.html#with-outliers",
    "title": "Neural Linear Model (aka Gaussian Process)",
    "section": "",
    "text": "Adding 5% outliers : The loss increases from -0.89 to 1.27 .\n\nnum_features = 100\nn_train = 200\ndr = 0.05\n\nmodel = torch.nn.Sequential(\n    torch.nn.Linear(1, num_features),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(dr),\n    torch.nn.Linear(num_features, num_features),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(dr),\n    torch.nn.Linear(num_features, num_features),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(dr),\n    torch.nn.Linear(num_features, 1),\n)\nlog_sigma = torch.nn.Parameter(-2 * torch.ones(1))\nds = Simulated(n=n_train, outliers_percentage=5)\ndl = torch.utils.data.DataLoader(\n    ds,\n    batch_size=32,\n    shuffle=True,\n    drop_last=True\n)\noptimizer = torch.optim.AdamW(\n    [\n        \n        {\n            \"params\": model.parameters(),\n            \"lr\": 1e-3,\n            \"weight_decay\": (1 - dr)\n            / (2 * len(ds)),\n        },\n        {\n            \"params\": log_sigma,\n            \"lr\": 1e-2,\n            \"weight_decay\": 1e-6,\n        },\n    ]\n)\n\nmodel.train()\nfor epoch in range(500):\n  train_loss = []\n  for batch in dl:\n    x, y = batch\n    mu = model(x)\n    dist = torch.distributions.Normal(mu, softplus(log_sigma))\n    loss = -dist.log_prob(y.unsqueeze(-1)).mean()\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    train_loss.append(loss.item())\n  if epoch % 20 == 0:\n    print(f\"Epoch {epoch}, loss: {np.mean(train_loss):.02f}\")\n\nx_test = torch.linspace(-4, 4, 150).unsqueeze(-1)\nmodel.eval()\nwith torch.no_grad():\n    mu_pred = model(x_test)\n    phi_test = model[:-1](x_test)\n    phi_train = model[:-1](ds.data)\nprint(phi_train.shape, phi_test.shape)\n\nI = torch.eye(num_features)\nA = phi_train.T @ phi_train / torch.square(softplus(log_sigma).detach())  + I\n\nL = torch.linalg.cholesky(A)\nprint(L.shape)\nv = torch.linalg.solve_triangular(L, phi_test.T, upper=False)\ncov = v.T @ v + 1e-5 * torch.eye(len(phi_test))\nf_stddev = torch.sqrt(torch.diag(cov))\n\n_ = plt.figure(figsize=(12,9))\n_ = sns.scatterplot(x=ds.data.ravel(), y=ds.targets.ravel())\n_ = sns.lineplot(x=x_test.ravel(), y=mu_pred.ravel())\n_ = plt.fill_between(\n    x=x_test.ravel(), \n    y1=mu_pred.ravel() + 1.96 * f_stddev, \n    y2=mu_pred.ravel() - 1.96 * f_stddev,\n    alpha=0.3,\n)\n_ = plt.ylim(-2, 2)\n\nEpoch 0, loss: 25.33\nEpoch 20, loss: 5.53\nEpoch 40, loss: 3.51\nEpoch 60, loss: 2.53\nEpoch 80, loss: 2.00\nEpoch 100, loss: 1.35\nEpoch 120, loss: 1.61\nEpoch 140, loss: 1.49\nEpoch 160, loss: 1.43\nEpoch 180, loss: 1.39\nEpoch 200, loss: 1.33\nEpoch 220, loss: 1.34\nEpoch 240, loss: 1.23\nEpoch 260, loss: 1.27\nEpoch 280, loss: 1.21\nEpoch 300, loss: 1.32\nEpoch 320, loss: 1.29\nEpoch 340, loss: 1.27\nEpoch 360, loss: 1.29\nEpoch 380, loss: 1.28\nEpoch 400, loss: 1.29\nEpoch 420, loss: 1.28\nEpoch 440, loss: 1.22\nEpoch 460, loss: 1.17\nEpoch 480, loss: 1.27\ntorch.Size([200, 100]) torch.Size([150, 100])\ntorch.Size([100, 100])"
  },
  {
    "objectID": "posts/notebooks/2020-01-01-template-notebook.html",
    "href": "posts/notebooks/2020-01-01-template-notebook.html",
    "title": "Template",
    "section": "",
    "text": "Template\n\n# T"
  },
  {
    "objectID": "posts/notebooks/2022-01-11-pytroch-embedding-2d-visualization.html#embedding-and-regression",
    "href": "posts/notebooks/2022-01-11-pytroch-embedding-2d-visualization.html#embedding-and-regression",
    "title": "Embedding output for Multi-class classification",
    "section": "Embedding and Regression",
    "text": "Embedding and Regression\n\n\n\nclass Net(nn.Module):\n    # define nn\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(4, 100)\n        self.fc2 = nn.Linear(100, 100)\n        self.fc3 = nn.Linear(100, 2)\n        #self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, X):\n        X = F.relu(self.fc1(X))\n        X = self.fc2(X)\n        X = self.fc3(X)\n        return X\n\n\nembed = torch.nn.Embedding(3,2)\nembed_train_y = Variable(embed(train_y))\nembed_test_y = Variable(embed(test_y))\ntrue_embed = embed(torch.LongTensor([0,1,2]))\ntrue_embed = pd.DataFrame(true_embed.tolist())\ntrue_embed['y'] = [0, 1, 2]\nsns.scatterplot(data=true_embed, x=0, y=1, hue='y')\n\n&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f44369e5940&gt;\n\n\n\n\n\n\n\nnet = Net()\n\ncriterion = nn.MSELoss()# cross entropy loss\n\noptimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n\nfor epoch in range(1000):\n    optimizer.zero_grad()\n    out = net(train_X)\n    loss = criterion(out, embed_train_y)\n    loss.backward()\n    optimizer.step()\n    \n    if epoch % 100 == 0:\n        print ('number of epoch {} loss {} '.format(epoch, loss))\n\npredict_out = net(test_X)\nprint (' Test MSE ', torch.abs(predict_out - embed_test_y).mean())\n\nnumber of epoch 0 loss 0.3358815610408783 \nnumber of epoch 100 loss 0.042973946779966354 \nnumber of epoch 200 loss 0.036721814423799515 \nnumber of epoch 300 loss 0.03191041201353073 \nnumber of epoch 400 loss 0.027886144816875458 \nnumber of epoch 500 loss 0.024619022384285927 \nnumber of epoch 600 loss 0.021988747641444206 \nnumber of epoch 700 loss 0.01982944831252098 \nnumber of epoch 800 loss 0.018047431483864784 \nnumber of epoch 900 loss 0.02423388510942459 \n Test MSE  tensor(0.0877, grad_fn=&lt;MeanBackward0&gt;)\n\n\n\nembed_output = pd.DataFrame(predict_out.tolist())\nembed_output['y'] = test_y.tolist()\nsns.scatterplot(data=embed_output, x=0, y=1, hue='y')\n\n&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f4436964520&gt;"
  },
  {
    "objectID": "posts/notebooks/2022-01-11-pytroch-embedding-2d-visualization.html#gaussian-regression",
    "href": "posts/notebooks/2022-01-11-pytroch-embedding-2d-visualization.html#gaussian-regression",
    "title": "Embedding output for Multi-class classification",
    "section": "Gaussian Regression",
    "text": "Gaussian Regression\n\n\n\nclass GaussianNet(nn.Module):\n    # define nn\n    def __init__(self):\n        super(GaussianNet, self).__init__()\n        self.fc1 = nn.Linear(4, 100)\n        self.fc2 = nn.Linear(100, 100)\n        self.fc3 = nn.Linear(100, 2)\n        self.variance = nn.Linear(100, 2)\n        #self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, X):\n        X = F.relu(self.fc1(X))\n        X = self.fc2(X)\n        out = self.fc3(X)\n        var = F.softplus(self.variance(X))\n        return out, var\n\n\n\n\nnet = GaussianNet()\n\ncriterion = nn.GaussianNLLLoss()# Gaussian NLL loss\n#criterion = nn.MSELoss()# Gaussian NLL loss\n\n#optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\noptimizer = torch.optim.AdamW(net.parameters(), lr=0.001)\n\nfor epoch in range(1000):\n    optimizer.zero_grad()\n    out, var = net(train_X)\n    \n    loss = criterion(out, embed_train_y, var)\n    loss.backward()\n    optimizer.step()\n    \n    if epoch % 100 == 0:\n        print (\"out \" , out[0])\n        print (\"var \" , var[0])\n        print ('number of epoch {} loss {} '.format(epoch, loss))\n\npredict_out, predict_var = net(test_X)\nprint (' Test MSE ', torch.abs(predict_out - embed_test_y).mean())\n\nout  tensor([ 1.2781, -0.3668], grad_fn=&lt;SelectBackward0&gt;)\nvar  tensor([0.5012, 0.6097], grad_fn=&lt;SelectBackward0&gt;)\nnumber of epoch 0 loss 0.41761282086372375 \nout  tensor([ 6.1669e-01, -5.4980e-04], grad_fn=&lt;SelectBackward0&gt;)\nvar  tensor([0.0310, 0.0035], grad_fn=&lt;SelectBackward0&gt;)\nnumber of epoch 100 loss -1.5372980833053589 \nout  tensor([ 0.5606, -0.0783], grad_fn=&lt;SelectBackward0&gt;)\nvar  tensor([0.0197, 0.0022], grad_fn=&lt;SelectBackward0&gt;)\nnumber of epoch 200 loss -2.0017826557159424 \nout  tensor([ 0.5585, -0.0794], grad_fn=&lt;SelectBackward0&gt;)\nvar  tensor([0.0341, 0.0144], grad_fn=&lt;SelectBackward0&gt;)\nnumber of epoch 300 loss -1.6041406393051147 \nout  tensor([ 0.6390, -0.1252], grad_fn=&lt;SelectBackward0&gt;)\nvar  tensor([0.0173, 0.0026], grad_fn=&lt;SelectBackward0&gt;)\nnumber of epoch 400 loss -2.2373907566070557 \nout  tensor([ 0.6222, -0.0581], grad_fn=&lt;SelectBackward0&gt;)\nvar  tensor([0.0159, 0.0107], grad_fn=&lt;SelectBackward0&gt;)\nnumber of epoch 500 loss -2.0754570960998535 \nout  tensor([ 0.6291, -0.0862], grad_fn=&lt;SelectBackward0&gt;)\nvar  tensor([0.0069, 0.0005], grad_fn=&lt;SelectBackward0&gt;)\nnumber of epoch 600 loss -2.6287074089050293 \nout  tensor([ 0.6051, -0.0870], grad_fn=&lt;SelectBackward0&gt;)\nvar  tensor([0.0062, 0.0011], grad_fn=&lt;SelectBackward0&gt;)\nnumber of epoch 700 loss -2.4698598384857178 \nout  tensor([ 0.6261, -0.0507], grad_fn=&lt;SelectBackward0&gt;)\nvar  tensor([0.0120, 0.0603], grad_fn=&lt;SelectBackward0&gt;)\nnumber of epoch 800 loss -1.6372172832489014 \nout  tensor([ 0.6267, -0.0832], grad_fn=&lt;SelectBackward0&gt;)\nvar  tensor([0.0051, 0.0049], grad_fn=&lt;SelectBackward0&gt;)\nnumber of epoch 900 loss -2.361809015274048 \n Test MSE  tensor(0.0631, grad_fn=&lt;MeanBackward0&gt;)\n\n\n\nembed_output = pd.DataFrame(predict_out.tolist())\nembed_output['y'] = test_y.tolist()\nembed_output[['var_0', 'var_1']] = predict_var.tolist()\nembed_output['combined_var'] = embed_output['var_0'] + embed_output['var_1']\nsns.scatterplot(data=embed_output, x=0, y=1, hue='y', size='combined_var',\n                sizes=(4, 400), alpha=.5, palette=\"muted\")\n\n&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f44368c7640&gt;\n\n\n\n\n\n\nsns.scatterplot(data=embed_output, x='var_0', y='var_1', hue='y')\n\n&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f44369e5280&gt;\n\n\n\n\n\n\nembed_output.describe()\n\n\n  \n    \n      \n\n\n\n\n\n\n0\n1\ny\nvar_0\nvar_1\ncombined_var\n\n\n\n\ncount\n120.000000\n120.000000\n120.000000\n120.000000\n120.000000\n120.000000\n\n\nmean\n0.327190\n0.036141\n0.966667\n0.010574\n0.000746\n0.011319\n\n\nstd\n0.291685\n0.104080\n0.819237\n0.007504\n0.000511\n0.007713\n\n\nmin\n-0.689349\n-0.107067\n0.000000\n0.000642\n0.000074\n0.000841\n\n\n25%\n0.145816\n-0.073233\n0.000000\n0.003095\n0.000380\n0.004076\n\n\n50%\n0.418697\n0.028199\n1.000000\n0.011524\n0.000624\n0.012242\n\n\n75%\n0.534689\n0.135289\n2.000000\n0.015900\n0.000967\n0.016656\n\n\nmax\n0.673590\n0.237829\n2.000000\n0.035810\n0.002695\n0.037705"
  },
  {
    "objectID": "posts/notebooks/2022-01-11-pytroch-embedding-2d-visualization.html#learning-embedding-while-training",
    "href": "posts/notebooks/2022-01-11-pytroch-embedding-2d-visualization.html#learning-embedding-while-training",
    "title": "Embedding output for Multi-class classification",
    "section": "Learning Embedding while training",
    "text": "Learning Embedding while training\n\nMillion dollar question will the network converge while training\n\n\n\nclass Net(nn.Module):\n    # define nn\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(4, 100)\n        self.fc2 = nn.Linear(100, 100)\n        self.fc3 = nn.Linear(100, 2)\n        #self.softmax = nn.Softmax(dim=1)\n        self.embed = nn.Embedding(3,2,max_norm=True)\n        self.embed.weight = nn.Parameter(torch.normal(0, 5, size=(3, 2)))\n\n    def embed_label(self, Y):\n        return self.embed(Y)\n\n    def forward(self, X, Y):\n        X = F.relu(self.fc1(X))\n        X = self.fc2(X)\n        return self.fc3(X), self.embed(Y)\n\n\n#embed = torch.nn.Embedding(3,2)\nnet = Net()\n\nembed_train_y = Variable(net.embed_label(train_y))\nembed_test_y = Variable(net.embed_label(test_y))\ntrue_embed = net.embed_label(torch.LongTensor([0,1,2]))\ntrue_embed = pd.DataFrame(true_embed.tolist())\ntrue_embed['y'] = [0, 1, 2]\nsns.scatterplot(data=true_embed, x=0, y=1, hue='y')\n\n&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f44359ea490&gt;\n\n\n\n\n\n\nfor name, param in net.named_parameters():\n    if param.requires_grad:\n        print (name, param.shape)\n\nfc1.weight torch.Size([100, 4])\nfc1.bias torch.Size([100])\nfc2.weight torch.Size([100, 100])\nfc2.bias torch.Size([100])\nfc3.weight torch.Size([2, 100])\nfc3.bias torch.Size([2])\nembed.weight torch.Size([3, 2])\n\n\n\n\n\ncriterion = nn.MSELoss()# cross entropy loss\n\noptimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n#embed_optimizer= torch.optim.SGD(embed.parameters(), lr=1e-1)\nbefore = torch.zeros_like(net.embed.weight)\nbefore_fc3 = torch.zeros_like(net.fc3.weight)\nfor epoch in range(1000):\n    net.zero_grad()\n    \n    #embed_optimizer.zero_grad()\n    out, embed_train_y = net(train_X, train_y)\n    embed_train_y = Variable(embed_train_y)\n    loss = criterion(out, embed_train_y)\n    loss.backward()\n    optimizer.step()\n    #embed_optimizer.step()\n    \n    if epoch % 100 == 0:\n        \n        print ('number of epoch {} loss {} '.format(epoch, loss))\n        after = net.embed.weight\n        after_fc3 = net.fc3.weight\n\n        # calculate the diff between the weights before an update and after the update**\n        print ('After update : embed equal', torch.equal(before.data, after.data))\n        before = net.embed.weight.clone()\n\n        print (\"fc3 equal \", torch.equal(before_fc3.data, after_fc3.data))\n        before_fc3 = net.fc3.weight.clone()\n        \n\n\n        \n        \n\npredict_out,embed_test_y = net(test_X, test_y)\nprint (' Test MSE ', torch.abs(predict_out - embed_test_y).mean())\n\nnumber of epoch 0 loss 0.7351046800613403 \nAfter update : embed equal False\nfc3 equal  False\nnumber of epoch 100 loss 0.2303016483783722 \nAfter update : embed equal True\nfc3 equal  False\nnumber of epoch 200 loss 0.17618589103221893 \nAfter update : embed equal True\nfc3 equal  False\nnumber of epoch 300 loss 0.1351977288722992 \nAfter update : embed equal True\nfc3 equal  False\nnumber of epoch 400 loss 0.11154220253229141 \nAfter update : embed equal True\nfc3 equal  False\nnumber of epoch 500 loss 0.09350577741861343 \nAfter update : embed equal True\nfc3 equal  False\nnumber of epoch 600 loss 0.0817851573228836 \nAfter update : embed equal True\nfc3 equal  False\nnumber of epoch 700 loss 0.08192727714776993 \nAfter update : embed equal True\nfc3 equal  False\nnumber of epoch 800 loss 0.14396952092647552 \nAfter update : embed equal True\nfc3 equal  False\nnumber of epoch 900 loss 0.1144104152917862 \nAfter update : embed equal True\nfc3 equal  False\n Test MSE  tensor(0.2455, grad_fn=&lt;MeanBackward0&gt;)\n\n\n\ntrue_embed = net.embed_label(torch.LongTensor([0,1,2]))\ntrue_embed = pd.DataFrame(true_embed.tolist())\ntrue_embed['y'] = [0, 1, 2]\nsns.scatterplot(data=true_embed, x=0, y=1, hue='y')\n\n&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f4435975310&gt;\n\n\n\n\n\n\nf, ax = plt.subplots(1,1,\n                      figsize=(5,5))\nembed_output = pd.DataFrame(predict_out.tolist())\nembed_output['y'] = test_y.tolist()\nsns.scatterplot(data=embed_output, x=0, y=1, hue='y',\n                 alpha=.5, palette=\"muted\", ax=ax)\n\nsns.scatterplot(data=true_embed, x=0, y=1, style='y', ax=ax, color='r')\n\n&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f44357dedc0&gt;"
  },
  {
    "objectID": "posts/notebooks/2023-02-28-bhattacharya-distance-dirichlet-multinomial-distributions.html#equation-from-1",
    "href": "posts/notebooks/2023-02-28-bhattacharya-distance-dirichlet-multinomial-distributions.html#equation-from-1",
    "title": "Bhattacharya Distance: Dirichlet and Multinomial distribution",
    "section": "Equation from [1]",
    "text": "Equation from [1]\n\\[\n\\eqalignno{\n  & \\qquad B(\\alpha_{a},\\alpha_{b}) = -ln\\rho(\\alpha_{a},\\alpha_{b})\\cr\n  & \\quad=- ln\\Gamma( \\sum_{k=1}^{d}{\\alpha_{ak}+\\alpha_{bk}\\over 2})\n   + {1\\over 2}\\{\\sum_{k=1}^{d}ln \\Gamma(\\alpha_{ak})+ \\sum_{k=1}^{d}ln \\Gamma(\\alpha_{bk})\\}\n   - \\sum_{k=1}^{d}ln \\Gamma({\\alpha_{ak}+\\alpha_{bk}\\over 2})\n   - {1\\over 2} \\{ ln \\Gamma(\\vert \\alpha_{a}\\vert)+ln\\Gamma(\\vert\\alpha_{b}\\vert \\}\n}\n\\]"
  },
  {
    "objectID": "posts/notebooks/2023-02-28-bhattacharya-distance-dirichlet-multinomial-distributions.html#same-equation-from-2",
    "href": "posts/notebooks/2023-02-28-bhattacharya-distance-dirichlet-multinomial-distributions.html#same-equation-from-2",
    "title": "Bhattacharya Distance: Dirichlet and Multinomial distribution",
    "section": "Same Equation from [2]",
    "text": "Same Equation from [2]\n\\[\nB(\\alpha,\\beta) = B(\\alpha) + B(\\beta) - B(\\alpha+\\beta)\n\\] where \\[\nB(\\alpha) = \\sum\\log\\Gamma{\\alpha} - \\log \\Gamma{\\sum(\\alpha)}\n\\]\nEquation from [2] is easy to code and debung than [1] so we implemented it\n\nimport numpy as np\nfrom scipy.special import gammaln\nfrom scipy.special import digamma\n\ndef logBalpha(alpha: np.ndarray):\n  return gammaln(alpha).sum() - gammaln(alpha.sum())\n\ndef bhattacharya_distance_dirichlet(alpha: np.ndarray, beta: np.ndarray):\n  #todo check if values are positive and above 1\n  return logBalpha(alpha) + logBalpha(beta) - logBalpha(alpha+beta)\n\n\nfor i in range(10): print (logBalpha(np.ones(i))) \n\n-inf\n0.0\n0.0\n-0.6931471805599453\n-1.791759469228055\n-3.1780538303479458\n-4.787491742782046\n-6.579251212010101\n-8.525161361065415\n-10.60460290274525"
  },
  {
    "objectID": "posts/notebooks/2023-02-28-bhattacharya-distance-dirichlet-multinomial-distributions.html#test-1-minimum-distance-for-different-number-of-alphas",
    "href": "posts/notebooks/2023-02-28-bhattacharya-distance-dirichlet-multinomial-distributions.html#test-1-minimum-distance-for-different-number-of-alphas",
    "title": "Bhattacharya Distance: Dirichlet and Multinomial distribution",
    "section": "Test 1: Minimum distance for different number of alphas",
    "text": "Test 1: Minimum distance for different number of alphas\nThe minimum distance starts from 0 and reduces as number of classes increases.\nIf one class is confident then the distance between them will get lower than the no information class distance . See test 4 where for 5 classes the distance goes lower than 6.45 as seen below.\n\nfor i in range(1, 10): \n  print (i, np.ones(i), bhattacharya_distance_dirichlet(np.ones(i), np.ones(i))) \n\n1 [1.] 0.0\n2 [1. 1.] 1.791759469228055\n3 [1. 1. 1.] 3.401197381662155\n4 [1. 1. 1. 1.] 4.941642422609305\n5 [1. 1. 1. 1. 1.] 6.445719819385578\n6 [1. 1. 1. 1. 1. 1.] 7.927324360309795\n7 [1. 1. 1. 1. 1. 1. 1.] 9.393661429103219\n8 [1. 1. 1. 1. 1. 1. 1. 1.] 10.848948661710065\n9 [1. 1. 1. 1. 1. 1. 1. 1. 1.] 12.295867644646389"
  },
  {
    "objectID": "posts/notebooks/2023-02-28-bhattacharya-distance-dirichlet-multinomial-distributions.html#test-2-with-high-values-of-alpha-effect-on-distance",
    "href": "posts/notebooks/2023-02-28-bhattacharya-distance-dirichlet-multinomial-distributions.html#test-2-with-high-values-of-alpha-effect-on-distance",
    "title": "Bhattacharya Distance: Dirichlet and Multinomial distribution",
    "section": "Test 2: With high values of alpha effect on distance",
    "text": "Test 2: With high values of alpha effect on distance\nHere we observe that the distance between same alphas keeps on decreasing as the value of alphas keep increasing.\nHigher the alpha lower the distance . Also negative distance\n\nfor i in range(1,100, 10):\n  print (i, np.ones(5)*i, bhattacharya_distance_dirichlet(np.ones(5)*i, np.ones(5)*i))\n\n1 [1. 1. 1. 1. 1.] 6.445719819385578\n11 [11. 11. 11. 11. 11.] 1.1255028731251286\n21 [21. 21. 21. 21. 21.] -0.19370880228223086\n31 [31. 31. 31. 31. 31.] -0.9818529925794337\n41 [41. 41. 41. 41. 41.] -1.5457429140878958\n51 [51. 51. 51. 51. 51.] -1.9851193053912084\n61 [61. 61. 61. 61. 61.] -2.3451443271551398\n71 [71. 71. 71. 71. 71.] -2.650141672341306\n81 [81. 81. 81. 81. 81.] -2.914723500702621\n91 [91. 91. 91. 91. 91.] -3.1483581907859843"
  },
  {
    "objectID": "posts/notebooks/2023-02-28-bhattacharya-distance-dirichlet-multinomial-distributions.html#test-3-more-confident-value-distance-increases",
    "href": "posts/notebooks/2023-02-28-bhattacharya-distance-dirichlet-multinomial-distributions.html#test-3-more-confident-value-distance-increases",
    "title": "Bhattacharya Distance: Dirichlet and Multinomial distribution",
    "section": "Test 3: More confident value distance increases",
    "text": "Test 3: More confident value distance increases\nWhen 1 valu of alpha is increases to show confidence increase on 1 class the distance with respect to no information keeps increasing\n\nfor i in range(1,100, 10):\n  p1 = np.ones(5)\n  p2 = p1.copy()\n  p2[0] = i\n  print (i, p1, p2, bhattacharya_distance_dirichlet(p1, p2))\n\n1 [1. 1. 1. 1. 1.] [1. 1. 1. 1. 1.] 6.445719819385578\n11 [1. 1. 1. 1. 1.] [11.  1.  1.  1.  1.] 8.572713901314495\n21 [1. 1. 1. 1. 1.] [21.  1.  1.  1.  1.] 10.249733300984314\n31 [1. 1. 1. 1. 1.] [31.  1.  1.  1.  1.] 11.438891683612685\n41 [1. 1. 1. 1. 1.] [41.  1.  1.  1.  1.] 12.356846899935736\n51 [1. 1. 1. 1. 1.] [51.  1.  1.  1.  1.] 13.10383713518198\n61 [1. 1. 1. 1. 1.] [61.  1.  1.  1.  1.] 13.733421146565181\n71 [1. 1. 1. 1. 1.] [71.  1.  1.  1.  1.] 14.277449847443624\n81 [1. 1. 1. 1. 1.] [81.  1.  1.  1.  1.] 14.75637687058833\n91 [1. 1. 1. 1. 1.] [91.  1.  1.  1.  1.] 15.18411005351209"
  },
  {
    "objectID": "posts/notebooks/2023-02-28-bhattacharya-distance-dirichlet-multinomial-distributions.html#test-4-distance-between-single-confident-class",
    "href": "posts/notebooks/2023-02-28-bhattacharya-distance-dirichlet-multinomial-distributions.html#test-4-distance-between-single-confident-class",
    "title": "Bhattacharya Distance: Dirichlet and Multinomial distribution",
    "section": "Test 4: Distance between single confident class",
    "text": "Test 4: Distance between single confident class\nAs both the classes converge to same alpha values the distance reduces.\n\nfor i in range(1,100, 10):\n  p1 = np.ones(5)\n  p2 = p1.copy()\n  p2[0] = i\n  p1[0] = 91\n  print (i, p1, p2, bhattacharya_distance_dirichlet(p1, p2))\n\n1 [91.  1.  1.  1.  1.] [1. 1. 1. 1. 1.] 15.18411005351209\n11 [91.  1.  1.  1.  1.] [11.  1.  1.  1.  1.] 9.072449120087896\n21 [91.  1.  1.  1.  1.] [21.  1.  1.  1.  1.] 7.434934213898558\n31 [91.  1.  1.  1.  1.] [31.  1.  1.  1.  1.] 6.625978812347682\n41 [91.  1.  1.  1.  1.] [41.  1.  1.  1.  1.] 6.165455265460906\n51 [91.  1.  1.  1.  1.] [51.  1.  1.  1.  1.] 5.889528847642993\n61 [91.  1.  1.  1.  1.] [61.  1.  1.  1.  1.] 5.7237287914577735\n71 [91.  1.  1.  1.  1.] [71.  1.  1.  1.  1.] 5.628589843464567\n81 [91.  1.  1.  1.  1.] [81.  1.  1.  1.  1.] 5.581062260628471\n91 [91.  1.  1.  1.  1.] [91.  1.  1.  1.  1.] 5.566743973084726"
  }
]